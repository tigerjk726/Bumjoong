{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPQp+mATWycb7chmEx/G3q0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tigerjk726/Bumjoong/blob/main/machine_learning_application_intensity(added_month).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CpbByZRippYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49b2827-cbc6-4de1-873b-5fde8ec05cfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')             "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/2022.10.10 typhoon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5TfSj0PfYtT",
        "outputId": "05297e3a-9762-4886-e3cf-143cec3b7dc2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/2022.10.10 typhoon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('summary2.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "iVlFBZkefbk2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "badb54d1-d80d-42b3-dc88-ed1f629c2624"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       DATE  MON        AAO    AMO         AO    EMI    GMT  NINO3  NINO4  \\\n",
              "0    198001    1   2468.847 -0.251 -13914.348  0.468 -0.008  0.362  0.318   \n",
              "1    198002    2   5287.235 -0.265  -7920.162  0.573  0.048  0.025  0.311   \n",
              "2    198003    3  18067.714 -0.343  -9798.327  0.417  0.005 -0.153  0.166   \n",
              "3    198004    4  23780.651 -0.064  -4271.158  0.394  0.035 -0.189  0.107   \n",
              "4    198005    5   3995.642  0.046  -8602.326  0.369  0.072 -0.155  0.201   \n",
              "..      ...  ...        ...    ...        ...    ...    ...    ...    ...   \n",
              "487  202008    8   8954.542  0.263  -1599.950 -0.229  0.320 -0.558 -0.237   \n",
              "488  202009    9   4960.132  0.135   4138.498 -0.207  0.435 -0.918 -0.463   \n",
              "489  202010   10 -10689.321  0.129    662.580 -0.377  0.416 -1.043 -0.695   \n",
              "490  202011   11 -13940.175  0.026  16778.709 -0.441  0.519 -1.136 -0.792   \n",
              "491  202012   12 -17119.479  0.039 -10766.470 -0.641  0.307 -0.805 -0.898   \n",
              "\n",
              "       PDO    PNA     QBO  FREG  INTEN  \n",
              "0    0.688 -0.787  -1.147     0    0.0  \n",
              "1    1.233  1.002   3.094     0    0.0  \n",
              "2    1.107 -0.539   5.553     0    0.0  \n",
              "3    1.255  1.457  11.231     0    0.0  \n",
              "4    1.204  0.377  18.477     0    0.0  \n",
              "..     ...    ...     ...   ...    ...  \n",
              "487 -1.413 -0.156  20.514     2   67.5  \n",
              "488 -1.137  0.402  20.357     2   90.0  \n",
              "489 -0.612 -0.943  19.270     0    0.0  \n",
              "490 -1.451 -0.402  18.811     0    0.0  \n",
              "491 -0.919  0.988  16.446     0    0.0  \n",
              "\n",
              "[492 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2d6a90ac-5b12-4cee-b11e-3f7dd355e4e5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATE</th>\n",
              "      <th>MON</th>\n",
              "      <th>AAO</th>\n",
              "      <th>AMO</th>\n",
              "      <th>AO</th>\n",
              "      <th>EMI</th>\n",
              "      <th>GMT</th>\n",
              "      <th>NINO3</th>\n",
              "      <th>NINO4</th>\n",
              "      <th>PDO</th>\n",
              "      <th>PNA</th>\n",
              "      <th>QBO</th>\n",
              "      <th>FREG</th>\n",
              "      <th>INTEN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>198001</td>\n",
              "      <td>1</td>\n",
              "      <td>2468.847</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>-13914.348</td>\n",
              "      <td>0.468</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.362</td>\n",
              "      <td>0.318</td>\n",
              "      <td>0.688</td>\n",
              "      <td>-0.787</td>\n",
              "      <td>-1.147</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>198002</td>\n",
              "      <td>2</td>\n",
              "      <td>5287.235</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>-7920.162</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.311</td>\n",
              "      <td>1.233</td>\n",
              "      <td>1.002</td>\n",
              "      <td>3.094</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>198003</td>\n",
              "      <td>3</td>\n",
              "      <td>18067.714</td>\n",
              "      <td>-0.343</td>\n",
              "      <td>-9798.327</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.153</td>\n",
              "      <td>0.166</td>\n",
              "      <td>1.107</td>\n",
              "      <td>-0.539</td>\n",
              "      <td>5.553</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>198004</td>\n",
              "      <td>4</td>\n",
              "      <td>23780.651</td>\n",
              "      <td>-0.064</td>\n",
              "      <td>-4271.158</td>\n",
              "      <td>0.394</td>\n",
              "      <td>0.035</td>\n",
              "      <td>-0.189</td>\n",
              "      <td>0.107</td>\n",
              "      <td>1.255</td>\n",
              "      <td>1.457</td>\n",
              "      <td>11.231</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198005</td>\n",
              "      <td>5</td>\n",
              "      <td>3995.642</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-8602.326</td>\n",
              "      <td>0.369</td>\n",
              "      <td>0.072</td>\n",
              "      <td>-0.155</td>\n",
              "      <td>0.201</td>\n",
              "      <td>1.204</td>\n",
              "      <td>0.377</td>\n",
              "      <td>18.477</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>202008</td>\n",
              "      <td>8</td>\n",
              "      <td>8954.542</td>\n",
              "      <td>0.263</td>\n",
              "      <td>-1599.950</td>\n",
              "      <td>-0.229</td>\n",
              "      <td>0.320</td>\n",
              "      <td>-0.558</td>\n",
              "      <td>-0.237</td>\n",
              "      <td>-1.413</td>\n",
              "      <td>-0.156</td>\n",
              "      <td>20.514</td>\n",
              "      <td>2</td>\n",
              "      <td>67.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>202009</td>\n",
              "      <td>9</td>\n",
              "      <td>4960.132</td>\n",
              "      <td>0.135</td>\n",
              "      <td>4138.498</td>\n",
              "      <td>-0.207</td>\n",
              "      <td>0.435</td>\n",
              "      <td>-0.918</td>\n",
              "      <td>-0.463</td>\n",
              "      <td>-1.137</td>\n",
              "      <td>0.402</td>\n",
              "      <td>20.357</td>\n",
              "      <td>2</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>202010</td>\n",
              "      <td>10</td>\n",
              "      <td>-10689.321</td>\n",
              "      <td>0.129</td>\n",
              "      <td>662.580</td>\n",
              "      <td>-0.377</td>\n",
              "      <td>0.416</td>\n",
              "      <td>-1.043</td>\n",
              "      <td>-0.695</td>\n",
              "      <td>-0.612</td>\n",
              "      <td>-0.943</td>\n",
              "      <td>19.270</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>202011</td>\n",
              "      <td>11</td>\n",
              "      <td>-13940.175</td>\n",
              "      <td>0.026</td>\n",
              "      <td>16778.709</td>\n",
              "      <td>-0.441</td>\n",
              "      <td>0.519</td>\n",
              "      <td>-1.136</td>\n",
              "      <td>-0.792</td>\n",
              "      <td>-1.451</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>18.811</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>202012</td>\n",
              "      <td>12</td>\n",
              "      <td>-17119.479</td>\n",
              "      <td>0.039</td>\n",
              "      <td>-10766.470</td>\n",
              "      <td>-0.641</td>\n",
              "      <td>0.307</td>\n",
              "      <td>-0.805</td>\n",
              "      <td>-0.898</td>\n",
              "      <td>-0.919</td>\n",
              "      <td>0.988</td>\n",
              "      <td>16.446</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>492 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d6a90ac-5b12-4cee-b11e-3f7dd355e4e5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2d6a90ac-5b12-4cee-b11e-3f7dd355e4e5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2d6a90ac-5b12-4cee-b11e-3f7dd355e4e5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "glKsDQFEf1Xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec08de76-3195-4a36-c9be-9eb9c9854f7d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['DATE', 'MON', 'AAO', 'AMO', 'AO', 'EMI', 'GMT', 'NINO3', 'NINO4',\n",
              "       'PDO', 'PNA', 'QBO', 'FREG', 'INTEN'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns = ['DATE','FREG','INTEN']) # \"X\"라는 변수에 날짜, 횟수와 강도를 제외하고 지정\n",
        "y = df['FREG']\n",
        "y2 = df['INTEN']\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "twU6qwFEHhP5",
        "outputId": "2d71434b-b4dc-45ca-be87-065b53ed8d3b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     MON        AAO    AMO         AO    EMI    GMT  NINO3  NINO4    PDO  \\\n",
              "0      1   2468.847 -0.251 -13914.348  0.468 -0.008  0.362  0.318  0.688   \n",
              "1      2   5287.235 -0.265  -7920.162  0.573  0.048  0.025  0.311  1.233   \n",
              "2      3  18067.714 -0.343  -9798.327  0.417  0.005 -0.153  0.166  1.107   \n",
              "3      4  23780.651 -0.064  -4271.158  0.394  0.035 -0.189  0.107  1.255   \n",
              "4      5   3995.642  0.046  -8602.326  0.369  0.072 -0.155  0.201  1.204   \n",
              "..   ...        ...    ...        ...    ...    ...    ...    ...    ...   \n",
              "487    8   8954.542  0.263  -1599.950 -0.229  0.320 -0.558 -0.237 -1.413   \n",
              "488    9   4960.132  0.135   4138.498 -0.207  0.435 -0.918 -0.463 -1.137   \n",
              "489   10 -10689.321  0.129    662.580 -0.377  0.416 -1.043 -0.695 -0.612   \n",
              "490   11 -13940.175  0.026  16778.709 -0.441  0.519 -1.136 -0.792 -1.451   \n",
              "491   12 -17119.479  0.039 -10766.470 -0.641  0.307 -0.805 -0.898 -0.919   \n",
              "\n",
              "       PNA     QBO  \n",
              "0   -0.787  -1.147  \n",
              "1    1.002   3.094  \n",
              "2   -0.539   5.553  \n",
              "3    1.457  11.231  \n",
              "4    0.377  18.477  \n",
              "..     ...     ...  \n",
              "487 -0.156  20.514  \n",
              "488  0.402  20.357  \n",
              "489 -0.943  19.270  \n",
              "490 -0.402  18.811  \n",
              "491  0.988  16.446  \n",
              "\n",
              "[492 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c84a637d-d773-45c7-81f9-023aebb89dbc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MON</th>\n",
              "      <th>AAO</th>\n",
              "      <th>AMO</th>\n",
              "      <th>AO</th>\n",
              "      <th>EMI</th>\n",
              "      <th>GMT</th>\n",
              "      <th>NINO3</th>\n",
              "      <th>NINO4</th>\n",
              "      <th>PDO</th>\n",
              "      <th>PNA</th>\n",
              "      <th>QBO</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2468.847</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>-13914.348</td>\n",
              "      <td>0.468</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.362</td>\n",
              "      <td>0.318</td>\n",
              "      <td>0.688</td>\n",
              "      <td>-0.787</td>\n",
              "      <td>-1.147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5287.235</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>-7920.162</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.311</td>\n",
              "      <td>1.233</td>\n",
              "      <td>1.002</td>\n",
              "      <td>3.094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>18067.714</td>\n",
              "      <td>-0.343</td>\n",
              "      <td>-9798.327</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.153</td>\n",
              "      <td>0.166</td>\n",
              "      <td>1.107</td>\n",
              "      <td>-0.539</td>\n",
              "      <td>5.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>23780.651</td>\n",
              "      <td>-0.064</td>\n",
              "      <td>-4271.158</td>\n",
              "      <td>0.394</td>\n",
              "      <td>0.035</td>\n",
              "      <td>-0.189</td>\n",
              "      <td>0.107</td>\n",
              "      <td>1.255</td>\n",
              "      <td>1.457</td>\n",
              "      <td>11.231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3995.642</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-8602.326</td>\n",
              "      <td>0.369</td>\n",
              "      <td>0.072</td>\n",
              "      <td>-0.155</td>\n",
              "      <td>0.201</td>\n",
              "      <td>1.204</td>\n",
              "      <td>0.377</td>\n",
              "      <td>18.477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>8</td>\n",
              "      <td>8954.542</td>\n",
              "      <td>0.263</td>\n",
              "      <td>-1599.950</td>\n",
              "      <td>-0.229</td>\n",
              "      <td>0.320</td>\n",
              "      <td>-0.558</td>\n",
              "      <td>-0.237</td>\n",
              "      <td>-1.413</td>\n",
              "      <td>-0.156</td>\n",
              "      <td>20.514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>9</td>\n",
              "      <td>4960.132</td>\n",
              "      <td>0.135</td>\n",
              "      <td>4138.498</td>\n",
              "      <td>-0.207</td>\n",
              "      <td>0.435</td>\n",
              "      <td>-0.918</td>\n",
              "      <td>-0.463</td>\n",
              "      <td>-1.137</td>\n",
              "      <td>0.402</td>\n",
              "      <td>20.357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>10</td>\n",
              "      <td>-10689.321</td>\n",
              "      <td>0.129</td>\n",
              "      <td>662.580</td>\n",
              "      <td>-0.377</td>\n",
              "      <td>0.416</td>\n",
              "      <td>-1.043</td>\n",
              "      <td>-0.695</td>\n",
              "      <td>-0.612</td>\n",
              "      <td>-0.943</td>\n",
              "      <td>19.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>11</td>\n",
              "      <td>-13940.175</td>\n",
              "      <td>0.026</td>\n",
              "      <td>16778.709</td>\n",
              "      <td>-0.441</td>\n",
              "      <td>0.519</td>\n",
              "      <td>-1.136</td>\n",
              "      <td>-0.792</td>\n",
              "      <td>-1.451</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>18.811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>12</td>\n",
              "      <td>-17119.479</td>\n",
              "      <td>0.039</td>\n",
              "      <td>-10766.470</td>\n",
              "      <td>-0.641</td>\n",
              "      <td>0.307</td>\n",
              "      <td>-0.805</td>\n",
              "      <td>-0.898</td>\n",
              "      <td>-0.919</td>\n",
              "      <td>0.988</td>\n",
              "      <td>16.446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>492 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c84a637d-d773-45c7-81f9-023aebb89dbc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c84a637d-d773-45c7-81f9-023aebb89dbc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c84a637d-d773-45c7-81f9-023aebb89dbc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['INTEN'] = df['INTEN'].astype(int)\n",
        "y2 = df['INTEN']\n",
        "y2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cwI7DXz1WuR",
        "outputId": "a51bce2f-14dd-48c0-8928-254b23c7d48f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "487    67\n",
              "488    90\n",
              "489     0\n",
              "490     0\n",
              "491     0\n",
              "Name: INTEN, Length: 492, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "machine learning application"
      ],
      "metadata": {
        "id": "mfyTOpZh2Smj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y2,test_size=0.3)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "eNB5zQbP2kJy"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "#Fit the model\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "mylist = []\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "# accuracy score\n",
        "acc_logreg = accuracy_score(y_test, y_pred)\n",
        "\n",
        "mylist.append(acc_logreg)\n",
        "print(cm)\n",
        "print(acc_logreg,'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9K3AH-k2Qw1",
        "outputId": "744d7dcd-2f3b-48ab-dba9-0161c5f17675"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[128   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8648648648648649 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "list1 = []\n",
        "for neighbors in range(1,5):\n",
        "    classifier = KNeighborsClassifier(n_neighbors=neighbors, metric='minkowski')\n",
        "    classifier.fit(x_train, y_train)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    list1.append(accuracy_score(y_test,y_pred))\n",
        "plt.plot(list(range(1,5)), list1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "S0nQeVDy29x9",
        "outputId": "11b4e648-b163-4d80-8edf-9029d50e3acb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc_knn = accuracy_score(y_test, y_pred)\n",
        "mylist.append(acc_knn)\n",
        "print(cm)\n",
        "print(acc_knn,'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP35Xt253QPP",
        "outputId": "5623b44a-38fc-4d00-dd2e-57a9452b3b46"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[125   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8445945945945946 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DecisionTreeClassifier\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "list1 = []\n",
        "for leaves in range(2,15):\n",
        "    classifier = DecisionTreeClassifier(max_leaf_nodes = leaves, random_state=0, criterion='entropy')\n",
        "    classifier.fit(x_train, y_train)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    list1.append(accuracy_score(y_test,y_pred))\n",
        "#print(mylist)\n",
        "plt.plot(list(range(2,15)), list1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4oBDcwbR3cF2",
        "outputId": "a0e47dda-68b3-4c9c-e2ec-62452ba1c055"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DecisionTreeClassifier(max_leaf_nodes = 5, random_state=0, criterion='entropy')\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc_decisiontree = accuracy_score(y_test, y_pred)\n",
        "print(cm)\n",
        "print(acc_decisiontree, '%')\n",
        "mylist.append(acc_decisiontree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRrsyBWB3vyj",
        "outputId": "c6aae531-6a7a-40ec-f3ff-3ca6b617d177"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[128   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8648648648648649 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RANDOM FOREST CLASSIFCATION\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "list1 = []\n",
        "for estimators in range(10,30):\n",
        "    classifier = RandomForestClassifier(n_estimators = estimators, random_state=0, criterion='entropy')\n",
        "    classifier.fit(x_train, y_train)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    list1.append(accuracy_score(y_test,y_pred))\n",
        "#print(mylist)\n",
        "plt.plot(list(range(10,30)), list1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "heShbmey31ga",
        "outputId": "8f416845-8c94-48c2-b036-0b65c939c851"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 15, criterion='entropy', random_state=0)\n",
        "classifier.fit(x_train,y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc_randomforest = accuracy_score(y_test, y_pred)\n",
        "mylist.append(acc_randomforest)\n",
        "print(cm)\n",
        "print(acc_randomforest,'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R0MMG4M3-uX",
        "outputId": "729f7d4e-5552-43cb-d45b-c441224b3882"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[128   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8648648648648649 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN (neural network )\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y2,test_size=0.3)\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, BatchNormalization, Dropout, LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
        "from keras import callbacks\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.1, # minimium amount of change to count as an improvement\n",
        "    patience=10, # how many epochs to wait before stopping\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "# Initialising the NN\n",
        "model = Sequential()\n",
        "\n",
        "# layers\n",
        "\n",
        "model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
        "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Compiling the ANN\n",
        "opt = Adam(learning_rate=0.01)\n",
        "model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Train the ANN\n",
        "model.fit(x_train, y_train, batch_size = 32, epochs = 100, callbacks=[early_stopping], validation_split=0.3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgELIKES4DLo",
        "outputId": "6944331e-5f14-4b08-d4b5-c59dbd2909d4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 2s 61ms/step - loss: -15.7780 - accuracy: 0.1250 - val_loss: -42.3395 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 20ms/step - loss: -194.8091 - accuracy: 0.0000e+00 - val_loss: -569.5696 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 11ms/step - loss: -3971.0703 - accuracy: 0.0000e+00 - val_loss: -2940.3398 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: -6852.9482 - accuracy: 0.0000e+00 - val_loss: -9670.2744 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -34496.3164 - accuracy: 0.0000e+00 - val_loss: -27757.7207 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -78249.9062 - accuracy: 0.0000e+00 - val_loss: -70524.7969 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -217594.2344 - accuracy: 0.0000e+00 - val_loss: -156029.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -398327.9062 - accuracy: 0.0000e+00 - val_loss: -305594.4688 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -646545.6250 - accuracy: 0.0000e+00 - val_loss: -534865.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -1240513.1250 - accuracy: 0.0000e+00 - val_loss: -915363.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -1361910.6250 - accuracy: 0.0000e+00 - val_loss: -1402127.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -2259192.0000 - accuracy: 0.0000e+00 - val_loss: -2093352.1250 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -4845837.0000 - accuracy: 0.0000e+00 - val_loss: -3207518.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -6256824.5000 - accuracy: 0.0000e+00 - val_loss: -4825539.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -9288902.0000 - accuracy: 0.0000e+00 - val_loss: -7168895.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -17293736.0000 - accuracy: 0.0000e+00 - val_loss: -10607920.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -29422556.0000 - accuracy: 0.0000e+00 - val_loss: -15495516.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -38584180.0000 - accuracy: 0.0000e+00 - val_loss: -21895204.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -34960812.0000 - accuracy: 0.0000e+00 - val_loss: -29513220.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -59532544.0000 - accuracy: 0.0000e+00 - val_loss: -39262524.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -50193436.0000 - accuracy: 0.0000e+00 - val_loss: -49463472.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -112775320.0000 - accuracy: 0.0000e+00 - val_loss: -64115028.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -125386064.0000 - accuracy: 0.0000e+00 - val_loss: -79613224.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -134089832.0000 - accuracy: 0.0000e+00 - val_loss: -98503904.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -108843488.0000 - accuracy: 0.0000e+00 - val_loss: -117936728.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: -244210448.0000 - accuracy: 0.0000e+00 - val_loss: -141347312.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -301882784.0000 - accuracy: 0.0000e+00 - val_loss: -170731792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -400976480.0000 - accuracy: 0.0000e+00 - val_loss: -204134912.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: -518832992.0000 - accuracy: 0.0000e+00 - val_loss: -242445824.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -511494144.0000 - accuracy: 0.0000e+00 - val_loss: -286660320.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -519051360.0000 - accuracy: 0.0000e+00 - val_loss: -332545600.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -391956544.0000 - accuracy: 0.0000e+00 - val_loss: -374310528.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -896758336.0000 - accuracy: 0.0000e+00 - val_loss: -431699616.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -472099264.0000 - accuracy: 0.0000e+00 - val_loss: -486370592.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -942032192.0000 - accuracy: 0.0000e+00 - val_loss: -541777856.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -921402944.0000 - accuracy: 0.0000e+00 - val_loss: -616220160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -1555295616.0000 - accuracy: 0.0000e+00 - val_loss: -703958720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -920334976.0000 - accuracy: 0.0000e+00 - val_loss: -791010688.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -1472336384.0000 - accuracy: 0.0000e+00 - val_loss: -884202240.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -1729368576.0000 - accuracy: 0.0000e+00 - val_loss: -989912384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -2544459008.0000 - accuracy: 0.0000e+00 - val_loss: -1103331456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -2437240064.0000 - accuracy: 0.0000e+00 - val_loss: -1253629952.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -1143482880.0000 - accuracy: 0.0000e+00 - val_loss: -1372058240.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -3424622336.0000 - accuracy: 0.0000e+00 - val_loss: -1520777984.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -2705253120.0000 - accuracy: 0.0000e+00 - val_loss: -1672432768.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -2814549248.0000 - accuracy: 0.0000e+00 - val_loss: -1848168960.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -2587686656.0000 - accuracy: 0.0000e+00 - val_loss: -2023211776.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -2788965888.0000 - accuracy: 0.0000e+00 - val_loss: -2193730304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -4256825600.0000 - accuracy: 0.0000e+00 - val_loss: -2373650944.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: -4074590464.0000 - accuracy: 0.0000e+00 - val_loss: -2583262208.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -3233674752.0000 - accuracy: 0.0000e+00 - val_loss: -2827220736.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -4574040064.0000 - accuracy: 0.0000e+00 - val_loss: -3060779520.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -4431129088.0000 - accuracy: 0.0000e+00 - val_loss: -3297635328.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -4483628032.0000 - accuracy: 0.0000e+00 - val_loss: -3532739840.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -8371032576.0000 - accuracy: 0.0000e+00 - val_loss: -3827580928.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -5931822592.0000 - accuracy: 0.0000e+00 - val_loss: -4145192448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -7775499776.0000 - accuracy: 0.0000e+00 - val_loss: -4457790464.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -11183837184.0000 - accuracy: 0.0000e+00 - val_loss: -4911988224.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -8620476416.0000 - accuracy: 0.0000e+00 - val_loss: -5329056256.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -4628699136.0000 - accuracy: 0.0000e+00 - val_loss: -5667324416.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -8636103680.0000 - accuracy: 0.0000e+00 - val_loss: -6005478400.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -6913415168.0000 - accuracy: 0.0000e+00 - val_loss: -6342468608.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -13630139392.0000 - accuracy: 0.0000e+00 - val_loss: -6751209984.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -8982219776.0000 - accuracy: 0.0000e+00 - val_loss: -7230984704.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -12912393216.0000 - accuracy: 0.0000e+00 - val_loss: -7683066880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -11615484928.0000 - accuracy: 0.0000e+00 - val_loss: -8215780352.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -9233071104.0000 - accuracy: 0.0000e+00 - val_loss: -8689938432.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -17797511168.0000 - accuracy: 0.0000e+00 - val_loss: -9155017728.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -7987074560.0000 - accuracy: 0.0000e+00 - val_loss: -9625874432.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -8016631296.0000 - accuracy: 0.0000e+00 - val_loss: -10018243584.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -10398093312.0000 - accuracy: 0.0000e+00 - val_loss: -10477370368.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -12060071936.0000 - accuracy: 0.0000e+00 - val_loss: -10928476160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -12111860736.0000 - accuracy: 0.0000e+00 - val_loss: -11404673024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -20716150784.0000 - accuracy: 0.0000e+00 - val_loss: -12077372416.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -13151263744.0000 - accuracy: 0.0000e+00 - val_loss: -12691932160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -23922487296.0000 - accuracy: 0.0000e+00 - val_loss: -13421117440.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -19373006848.0000 - accuracy: 0.0000e+00 - val_loss: -14155486208.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -16255237120.0000 - accuracy: 0.0000e+00 - val_loss: -14773200896.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -22757134336.0000 - accuracy: 0.0000e+00 - val_loss: -15512316928.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -30028451840.0000 - accuracy: 0.0000e+00 - val_loss: -16372508672.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -37015576576.0000 - accuracy: 0.0000e+00 - val_loss: -17477885952.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -43727482880.0000 - accuracy: 0.0000e+00 - val_loss: -18715389952.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -25430210560.0000 - accuracy: 0.0000e+00 - val_loss: -19896707072.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -42692894720.0000 - accuracy: 0.0000e+00 - val_loss: -21002713088.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -38477844480.0000 - accuracy: 0.0000e+00 - val_loss: -22281814016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -22663784448.0000 - accuracy: 0.0000e+00 - val_loss: -23438903296.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -52076453888.0000 - accuracy: 0.0000e+00 - val_loss: -24627095552.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 10ms/step - loss: -61803831296.0000 - accuracy: 0.0000e+00 - val_loss: -26078947328.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -39705858048.0000 - accuracy: 0.0000e+00 - val_loss: -27596675072.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -51276177408.0000 - accuracy: 0.0000e+00 - val_loss: -28941684736.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -54239281152.0000 - accuracy: 0.0000e+00 - val_loss: -30499344384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -67215073280.0000 - accuracy: 0.0000e+00 - val_loss: -32279322624.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -63272005632.0000 - accuracy: 0.0000e+00 - val_loss: -33929048064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -50410668032.0000 - accuracy: 0.0000e+00 - val_loss: -35598114816.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -56214032384.0000 - accuracy: 0.0000e+00 - val_loss: -37232877568.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 8ms/step - loss: -74473758720.0000 - accuracy: 0.0000e+00 - val_loss: -38763708416.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -78021402624.0000 - accuracy: 0.0000e+00 - val_loss: -40703639552.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 6ms/step - loss: -77823901696.0000 - accuracy: 0.0000e+00 - val_loss: -42508984320.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 9ms/step - loss: -71478288384.0000 - accuracy: 0.0000e+00 - val_loss: -44440580096.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 7ms/step - loss: -78049484800.0000 - accuracy: 0.0000e+00 - val_loss: -46275682304.0000 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f36640d77d0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.9)\n",
        "np.set_printoptions()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# confusion matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(\"Confusion Matrix\")\n",
        "print(cm)\n",
        "print()\n",
        "\n",
        "# accuracy\n",
        "ac_ann = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy\")\n",
        "print(ac_ann)\n",
        "mylist.append(ac_ann)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE6FGlfE4Ole",
        "outputId": "9505967f-9057-4df8-977e-a8a9931e9490"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n",
            "Confusion Matrix\n",
            "[[  0 125   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "\n",
            "Accuracy\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DNN\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Dense, Input\n",
        "\n",
        "i = Input(shape=(None, 455, 11))\n",
        "\n",
        "x = Dense(16, activation='relu')(i)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(32, activation='relu')(i)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(16, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "y = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "dnn_adam = Model(inputs=i, outputs=y)\n",
        "\n",
        "dnn_adam.compile(optimizer='adam', \n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "dnn_adam.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X80mrY3B7iHB",
        "outputId": "ca90ea5d-ff58-4df8-85af-8c60993c2b21"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None, 455, 11)]   0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, None, 455, 32)     384       \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, None, 455, 32)     0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, None, 455, 64)     2112      \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, None, 455, 64)     0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, None, 455, 32)     2080      \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, None, 455, 32)     0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, None, 455, 16)     528       \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, None, 455, 16)     0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, None, 455, 1)      17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25)\n",
        "\n",
        "history_adam = dnn_adam.fit(x=x_train, y=y_train,\n",
        "                             validation_data=(x_test, y_test),\n",
        "                             epochs=100,\n",
        "                             callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vf3qKXM7vc1",
        "outputId": "44d867f0-d0b0-4b8e-98c2-b067aba3b8a4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 0s 10ms/step - loss: -27017145745408.0000 - accuracy: 0.0000e+00 - val_loss: -20008656699392.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -29771301912576.0000 - accuracy: 0.0000e+00 - val_loss: -20274948866048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -26683277049856.0000 - accuracy: 0.0000e+00 - val_loss: -20551538049024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -24597932015616.0000 - accuracy: 0.0000e+00 - val_loss: -20792016371712.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -28102346407936.0000 - accuracy: 0.0000e+00 - val_loss: -21051901739008.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -24715114577920.0000 - accuracy: 0.0000e+00 - val_loss: -21304212193280.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -24779792842752.0000 - accuracy: 0.0000e+00 - val_loss: -21527728750592.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -30388432928768.0000 - accuracy: 0.0000e+00 - val_loss: -21786964000768.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -28893956276224.0000 - accuracy: 0.0000e+00 - val_loss: -22071763533824.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -30857804906496.0000 - accuracy: 0.0000e+00 - val_loss: -22367734595584.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -34336302694400.0000 - accuracy: 0.0000e+00 - val_loss: -22666784276480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -26116477681664.0000 - accuracy: 0.0000e+00 - val_loss: -22932667498496.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -30582379642880.0000 - accuracy: 0.0000e+00 - val_loss: -23202329788416.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -35271336787968.0000 - accuracy: 0.0000e+00 - val_loss: -23542867427328.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -35936263995392.0000 - accuracy: 0.0000e+00 - val_loss: -23858300059648.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -34544279355392.0000 - accuracy: 0.0000e+00 - val_loss: -24187865399296.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -29514138648576.0000 - accuracy: 0.0000e+00 - val_loss: -24481791737856.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -33508254810112.0000 - accuracy: 0.0000e+00 - val_loss: -24795099955200.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -32455029424128.0000 - accuracy: 0.0000e+00 - val_loss: -25104543121408.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -29598851006464.0000 - accuracy: 0.0000e+00 - val_loss: -25378068365312.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -42647142006784.0000 - accuracy: 0.0000e+00 - val_loss: -25698186035200.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -33708138561536.0000 - accuracy: 0.0000e+00 - val_loss: -26009403392000.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -31966638374912.0000 - accuracy: 0.0000e+00 - val_loss: -26328195661824.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -39196827844608.0000 - accuracy: 0.0000e+00 - val_loss: -26655955353600.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -35901715513344.0000 - accuracy: 0.0000e+00 - val_loss: -26955344773120.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -43679175671808.0000 - accuracy: 0.0000e+00 - val_loss: -27293076422656.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -35939527163904.0000 - accuracy: 0.0000e+00 - val_loss: -27617505837056.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -42457320390656.0000 - accuracy: 0.0000e+00 - val_loss: -27985449058304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -37794651045888.0000 - accuracy: 0.0000e+00 - val_loss: -28328882864128.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -41178393214976.0000 - accuracy: 0.0000e+00 - val_loss: -28702775705600.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -41171711688704.0000 - accuracy: 0.0000e+00 - val_loss: -29046830268416.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -35350248423424.0000 - accuracy: 0.0000e+00 - val_loss: -29379170140160.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -42406539952128.0000 - accuracy: 0.0000e+00 - val_loss: -29697423441920.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -35798573383680.0000 - accuracy: 0.0000e+00 - val_loss: -30071024779264.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -49133335347200.0000 - accuracy: 0.0000e+00 - val_loss: -30468955176960.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -49811826933760.0000 - accuracy: 0.0000e+00 - val_loss: -30852559929344.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -49486973894656.0000 - accuracy: 0.0000e+00 - val_loss: -31266860695552.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -47299946348544.0000 - accuracy: 0.0000e+00 - val_loss: -31684743397376.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -46460225716224.0000 - accuracy: 0.0000e+00 - val_loss: -32087627268096.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -46402738585600.0000 - accuracy: 0.0000e+00 - val_loss: -32502328590336.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -46714627031040.0000 - accuracy: 0.0000e+00 - val_loss: -32888944852992.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -43896952324096.0000 - accuracy: 0.0000e+00 - val_loss: -33255120175104.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -42192085188608.0000 - accuracy: 0.0000e+00 - val_loss: -33604451172352.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -41432643534848.0000 - accuracy: 0.0000e+00 - val_loss: -33947327135744.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -51492211916800.0000 - accuracy: 0.0000e+00 - val_loss: -34361447546880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -45511029555200.0000 - accuracy: 0.0000e+00 - val_loss: -34769951784960.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -43649932984320.0000 - accuracy: 0.0000e+00 - val_loss: -35122541756416.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -39041407909888.0000 - accuracy: 0.0000e+00 - val_loss: -35468464881664.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -47909559074816.0000 - accuracy: 0.0000e+00 - val_loss: -35838855479296.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -38569984917504.0000 - accuracy: 0.0000e+00 - val_loss: -36184461934592.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -49696366133248.0000 - accuracy: 0.0000e+00 - val_loss: -36584736948224.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -55536879927296.0000 - accuracy: 0.0000e+00 - val_loss: -37028104241152.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -57591585570816.0000 - accuracy: 0.0000e+00 - val_loss: -37463779180544.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -57393891246080.0000 - accuracy: 0.0000e+00 - val_loss: -37956618289152.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -58955917164544.0000 - accuracy: 0.0000e+00 - val_loss: -38386173739008.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -59530327097344.0000 - accuracy: 0.0000e+00 - val_loss: -38896012361728.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -58839495868416.0000 - accuracy: 0.0000e+00 - val_loss: -39343091613696.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -56060190654464.0000 - accuracy: 0.0000e+00 - val_loss: -39814615269376.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -51723645222912.0000 - accuracy: 0.0000e+00 - val_loss: -40256913014784.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -58541385711616.0000 - accuracy: 0.0000e+00 - val_loss: -40705674182656.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -50697634578432.0000 - accuracy: 0.0000e+00 - val_loss: -41148806594560.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -46306483503104.0000 - accuracy: 0.0000e+00 - val_loss: -41527862624256.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -54437812895744.0000 - accuracy: 0.0000e+00 - val_loss: -41937780342784.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -67062126870528.0000 - accuracy: 0.0000e+00 - val_loss: -42399829065728.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -57609096790016.0000 - accuracy: 0.0000e+00 - val_loss: -42879045074944.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -61603038887936.0000 - accuracy: 0.0000e+00 - val_loss: -43362711240704.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -67238925172736.0000 - accuracy: 0.0000e+00 - val_loss: -43829788934144.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -65940003749888.0000 - accuracy: 0.0000e+00 - val_loss: -44314075856896.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -60025850560512.0000 - accuracy: 0.0000e+00 - val_loss: -44849134829568.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -61947810676736.0000 - accuracy: 0.0000e+00 - val_loss: -45334919118848.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -61232669261824.0000 - accuracy: 0.0000e+00 - val_loss: -45820820848640.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -62077397893120.0000 - accuracy: 0.0000e+00 - val_loss: -46348422348800.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -70483819102208.0000 - accuracy: 0.0000e+00 - val_loss: -46839692787712.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -64850310987776.0000 - accuracy: 0.0000e+00 - val_loss: -47342765998080.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -64693725036544.0000 - accuracy: 0.0000e+00 - val_loss: -47891208994816.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -72096394772480.0000 - accuracy: 0.0000e+00 - val_loss: -48351412224000.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -71570093506560.0000 - accuracy: 0.0000e+00 - val_loss: -48934563086336.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -57795789455360.0000 - accuracy: 0.0000e+00 - val_loss: -49469345234944.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -68620080119808.0000 - accuracy: 0.0000e+00 - val_loss: -49970765889536.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -71331924148224.0000 - accuracy: 0.0000e+00 - val_loss: -50515547258880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -64663534436352.0000 - accuracy: 0.0000e+00 - val_loss: -51021615202304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -70993057939456.0000 - accuracy: 0.0000e+00 - val_loss: -51521731428352.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -79191328423936.0000 - accuracy: 0.0000e+00 - val_loss: -52089459834880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -68332367642624.0000 - accuracy: 0.0000e+00 - val_loss: -52590767243264.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -91483289944064.0000 - accuracy: 0.0000e+00 - val_loss: -53181237166080.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -74291693486080.0000 - accuracy: 0.0000e+00 - val_loss: -53787322482688.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -72489333948416.0000 - accuracy: 0.0000e+00 - val_loss: -54335727730688.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -66197894725632.0000 - accuracy: 0.0000e+00 - val_loss: -54902688579584.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -84402340102144.0000 - accuracy: 0.0000e+00 - val_loss: -55433440002048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -90780223930368.0000 - accuracy: 0.0000e+00 - val_loss: -56067375497216.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -78493270409216.0000 - accuracy: 0.0000e+00 - val_loss: -56635905015808.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -78952018214912.0000 - accuracy: 0.0000e+00 - val_loss: -57206569435136.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -84632104075264.0000 - accuracy: 0.0000e+00 - val_loss: -57797773361152.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -82057506062336.0000 - accuracy: 0.0000e+00 - val_loss: -58410103996416.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -84538076168192.0000 - accuracy: 0.0000e+00 - val_loss: -59002096451584.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -75595836817408.0000 - accuracy: 0.0000e+00 - val_loss: -59534080999424.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -82588672720896.0000 - accuracy: 0.0000e+00 - val_loss: -60111263367168.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -85311572934656.0000 - accuracy: 0.0000e+00 - val_loss: -60745777676288.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -76070648807424.0000 - accuracy: 0.0000e+00 - val_loss: -61281625178112.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -76675626827776.0000 - accuracy: 0.0000e+00 - val_loss: -61859927425024.0000 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred = dnn_adam.predict(x_test)\n",
        "y_pred = (y_pred > 0.9)\n",
        "np.set_printoptions()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# confusion matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(\"Confusion Matrix\")\n",
        "print(cm)\n",
        "print()\n",
        "\n",
        "# accuracy\n",
        "ac_dnn = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy\")\n",
        "print(ac_dnn)\n",
        "mylist.append(ac_dnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5myo79Qq70-T",
        "outputId": "08d74d92-c444-4600-ed64-a2324a04d754"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, None, 455, 11) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 455, 11), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (None, 11).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n",
            "Confusion Matrix\n",
            "[[  0 125   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "\n",
            "Accuracy\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "list1 = []\n",
        "for estimators in range(10,30,1):\n",
        "    classifier = XGBClassifier(n_estimators = estimators, max_depth=12, subsample=0.7)\n",
        "    classifier.fit(x_train, y_train)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    list1.append(accuracy_score(y_test,y_pred))\n",
        "#print(mylist)\n",
        "plt.plot(list(range(10,30,1)), list1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "0lfW_8c04q7w",
        "outputId": "4d104dc8-bf0e-47dc-baf1-988d0adca37c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier(n_estimators = 15, max_depth=12, subsample=0.7)\n",
        "classifier.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLGoO-g45JKR",
        "outputId": "2dc65e21-4907-4c61-a751-89e2de0ada22"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(max_depth=12, n_estimators=15, objective='multi:softprob',\n",
              "              subsample=0.7)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ac_xgboost = accuracy_score(y_test, y_pred)\n",
        "mylist.append(ac_xgboost)\n",
        "print(cm)\n",
        "print(ac_xgboost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k256gbxX5Lnu",
        "outputId": "ed27cae5-14f6-43e2-f3e6-639b96511c47"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[125   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  4   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8445945945945946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# catboost\n",
        "!pip install catboost\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "classifier = CatBoostClassifier()\n",
        "classifier.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBcsCzaQ5PNr",
        "outputId": "e29c62a9-462c-4d80-c00a-d7ba4a737995"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1-cp37-none-manylinux1_x86_64.whl (76.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.8 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.1.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1\n",
            "Learning rate set to 0.074936\n",
            "0:\tlearn: 2.9395288\ttotal: 105ms\tremaining: 1m 45s\n",
            "1:\tlearn: 2.6152022\ttotal: 144ms\tremaining: 1m 11s\n",
            "2:\tlearn: 2.3828970\ttotal: 182ms\tremaining: 1m\n",
            "3:\tlearn: 2.2065732\ttotal: 219ms\tremaining: 54.6s\n",
            "4:\tlearn: 2.0541801\ttotal: 257ms\tremaining: 51.2s\n",
            "5:\tlearn: 1.9436126\ttotal: 297ms\tremaining: 49.2s\n",
            "6:\tlearn: 1.8159913\ttotal: 343ms\tremaining: 48.6s\n",
            "7:\tlearn: 1.7139890\ttotal: 387ms\tremaining: 48s\n",
            "8:\tlearn: 1.6354483\ttotal: 426ms\tremaining: 46.9s\n",
            "9:\tlearn: 1.5699181\ttotal: 464ms\tremaining: 45.9s\n",
            "10:\tlearn: 1.5076605\ttotal: 504ms\tremaining: 45.3s\n",
            "11:\tlearn: 1.4536013\ttotal: 542ms\tremaining: 44.6s\n",
            "12:\tlearn: 1.4074502\ttotal: 580ms\tremaining: 44s\n",
            "13:\tlearn: 1.3536613\ttotal: 619ms\tremaining: 43.6s\n",
            "14:\tlearn: 1.3154277\ttotal: 656ms\tremaining: 43.1s\n",
            "15:\tlearn: 1.2788397\ttotal: 695ms\tremaining: 42.8s\n",
            "16:\tlearn: 1.2401523\ttotal: 733ms\tremaining: 42.4s\n",
            "17:\tlearn: 1.2082404\ttotal: 775ms\tremaining: 42.3s\n",
            "18:\tlearn: 1.1819893\ttotal: 816ms\tremaining: 42.1s\n",
            "19:\tlearn: 1.1560304\ttotal: 853ms\tremaining: 41.8s\n",
            "20:\tlearn: 1.1315346\ttotal: 891ms\tremaining: 41.5s\n",
            "21:\tlearn: 1.1108056\ttotal: 940ms\tremaining: 41.8s\n",
            "22:\tlearn: 1.0864529\ttotal: 987ms\tremaining: 41.9s\n",
            "23:\tlearn: 1.0634770\ttotal: 1.03s\tremaining: 42.1s\n",
            "24:\tlearn: 1.0462788\ttotal: 1.07s\tremaining: 41.8s\n",
            "25:\tlearn: 1.0290839\ttotal: 1.11s\tremaining: 41.6s\n",
            "26:\tlearn: 1.0153642\ttotal: 1.15s\tremaining: 41.5s\n",
            "27:\tlearn: 1.0002639\ttotal: 1.19s\tremaining: 41.4s\n",
            "28:\tlearn: 0.9806020\ttotal: 1.24s\tremaining: 41.5s\n",
            "29:\tlearn: 0.9673835\ttotal: 1.28s\tremaining: 41.5s\n",
            "30:\tlearn: 0.9553325\ttotal: 1.32s\tremaining: 41.2s\n",
            "31:\tlearn: 0.9421439\ttotal: 1.36s\tremaining: 41s\n",
            "32:\tlearn: 0.9293979\ttotal: 1.4s\tremaining: 41s\n",
            "33:\tlearn: 0.9171108\ttotal: 1.44s\tremaining: 40.8s\n",
            "34:\tlearn: 0.9061720\ttotal: 1.47s\tremaining: 40.7s\n",
            "35:\tlearn: 0.8956837\ttotal: 1.51s\tremaining: 40.5s\n",
            "36:\tlearn: 0.8857237\ttotal: 1.55s\tremaining: 40.3s\n",
            "37:\tlearn: 0.8763617\ttotal: 1.59s\tremaining: 40.4s\n",
            "38:\tlearn: 0.8605220\ttotal: 1.64s\tremaining: 40.3s\n",
            "39:\tlearn: 0.8519711\ttotal: 1.68s\tremaining: 40.2s\n",
            "40:\tlearn: 0.8432873\ttotal: 1.71s\tremaining: 40.1s\n",
            "41:\tlearn: 0.8344623\ttotal: 1.75s\tremaining: 40s\n",
            "42:\tlearn: 0.8262162\ttotal: 1.8s\tremaining: 40s\n",
            "43:\tlearn: 0.8182440\ttotal: 1.83s\tremaining: 39.9s\n",
            "44:\tlearn: 0.8099811\ttotal: 1.87s\tremaining: 39.7s\n",
            "45:\tlearn: 0.7993545\ttotal: 1.92s\tremaining: 39.7s\n",
            "46:\tlearn: 0.7911534\ttotal: 1.96s\tremaining: 39.7s\n",
            "47:\tlearn: 0.7834125\ttotal: 2.01s\tremaining: 39.8s\n",
            "48:\tlearn: 0.7761042\ttotal: 2.05s\tremaining: 39.7s\n",
            "49:\tlearn: 0.7685141\ttotal: 2.08s\tremaining: 39.6s\n",
            "50:\tlearn: 0.7615233\ttotal: 2.12s\tremaining: 39.5s\n",
            "51:\tlearn: 0.7517393\ttotal: 2.16s\tremaining: 39.4s\n",
            "52:\tlearn: 0.7456559\ttotal: 2.2s\tremaining: 39.2s\n",
            "53:\tlearn: 0.7397284\ttotal: 2.24s\tremaining: 39.3s\n",
            "54:\tlearn: 0.7343622\ttotal: 2.28s\tremaining: 39.2s\n",
            "55:\tlearn: 0.7289834\ttotal: 2.32s\tremaining: 39.1s\n",
            "56:\tlearn: 0.7200128\ttotal: 2.35s\tremaining: 39s\n",
            "57:\tlearn: 0.7094362\ttotal: 2.36s\tremaining: 38.3s\n",
            "58:\tlearn: 0.7031389\ttotal: 2.4s\tremaining: 38.3s\n",
            "59:\tlearn: 0.6941085\ttotal: 2.44s\tremaining: 38.3s\n",
            "60:\tlearn: 0.6880540\ttotal: 2.48s\tremaining: 38.2s\n",
            "61:\tlearn: 0.6799000\ttotal: 2.52s\tremaining: 38.1s\n",
            "62:\tlearn: 0.6739055\ttotal: 2.56s\tremaining: 38.1s\n",
            "63:\tlearn: 0.6690256\ttotal: 2.6s\tremaining: 38s\n",
            "64:\tlearn: 0.6636240\ttotal: 2.64s\tremaining: 38s\n",
            "65:\tlearn: 0.6586419\ttotal: 2.68s\tremaining: 37.9s\n",
            "66:\tlearn: 0.6528790\ttotal: 2.72s\tremaining: 37.9s\n",
            "67:\tlearn: 0.6451101\ttotal: 2.76s\tremaining: 37.8s\n",
            "68:\tlearn: 0.6403733\ttotal: 2.79s\tremaining: 37.7s\n",
            "69:\tlearn: 0.6367985\ttotal: 2.83s\tremaining: 37.6s\n",
            "70:\tlearn: 0.6321109\ttotal: 2.87s\tremaining: 37.6s\n",
            "71:\tlearn: 0.6267048\ttotal: 2.91s\tremaining: 37.6s\n",
            "72:\tlearn: 0.6225818\ttotal: 2.95s\tremaining: 37.5s\n",
            "73:\tlearn: 0.6178934\ttotal: 3s\tremaining: 37.5s\n",
            "74:\tlearn: 0.6137721\ttotal: 3.04s\tremaining: 37.5s\n",
            "75:\tlearn: 0.6097562\ttotal: 3.07s\tremaining: 37.4s\n",
            "76:\tlearn: 0.6051465\ttotal: 3.11s\tremaining: 37.3s\n",
            "77:\tlearn: 0.5998756\ttotal: 3.15s\tremaining: 37.3s\n",
            "78:\tlearn: 0.5956307\ttotal: 3.19s\tremaining: 37.2s\n",
            "79:\tlearn: 0.5906686\ttotal: 3.23s\tremaining: 37.1s\n",
            "80:\tlearn: 0.5850069\ttotal: 3.27s\tremaining: 37.1s\n",
            "81:\tlearn: 0.5807789\ttotal: 3.31s\tremaining: 37s\n",
            "82:\tlearn: 0.5771069\ttotal: 3.35s\tremaining: 37s\n",
            "83:\tlearn: 0.5728225\ttotal: 3.38s\tremaining: 36.9s\n",
            "84:\tlearn: 0.5689627\ttotal: 3.42s\tremaining: 36.8s\n",
            "85:\tlearn: 0.5648625\ttotal: 3.46s\tremaining: 36.8s\n",
            "86:\tlearn: 0.5589239\ttotal: 3.5s\tremaining: 36.7s\n",
            "87:\tlearn: 0.5548352\ttotal: 3.54s\tremaining: 36.7s\n",
            "88:\tlearn: 0.5503599\ttotal: 3.58s\tremaining: 36.6s\n",
            "89:\tlearn: 0.5474796\ttotal: 3.62s\tremaining: 36.6s\n",
            "90:\tlearn: 0.5416257\ttotal: 3.65s\tremaining: 36.5s\n",
            "91:\tlearn: 0.5382704\ttotal: 3.69s\tremaining: 36.4s\n",
            "92:\tlearn: 0.5351030\ttotal: 3.73s\tremaining: 36.4s\n",
            "93:\tlearn: 0.5316256\ttotal: 3.77s\tremaining: 36.3s\n",
            "94:\tlearn: 0.5275353\ttotal: 3.81s\tremaining: 36.3s\n",
            "95:\tlearn: 0.5225335\ttotal: 3.85s\tremaining: 36.2s\n",
            "96:\tlearn: 0.5186890\ttotal: 3.88s\tremaining: 36.2s\n",
            "97:\tlearn: 0.5152623\ttotal: 3.92s\tremaining: 36.1s\n",
            "98:\tlearn: 0.5125145\ttotal: 3.96s\tremaining: 36s\n",
            "99:\tlearn: 0.5093462\ttotal: 4.01s\tremaining: 36.1s\n",
            "100:\tlearn: 0.5073198\ttotal: 4.05s\tremaining: 36.1s\n",
            "101:\tlearn: 0.5048362\ttotal: 4.09s\tremaining: 36s\n",
            "102:\tlearn: 0.5027653\ttotal: 4.13s\tremaining: 36s\n",
            "103:\tlearn: 0.5006368\ttotal: 4.17s\tremaining: 35.9s\n",
            "104:\tlearn: 0.4977044\ttotal: 4.2s\tremaining: 35.8s\n",
            "105:\tlearn: 0.4951445\ttotal: 4.24s\tremaining: 35.8s\n",
            "106:\tlearn: 0.4911959\ttotal: 4.28s\tremaining: 35.7s\n",
            "107:\tlearn: 0.4870029\ttotal: 4.32s\tremaining: 35.7s\n",
            "108:\tlearn: 0.4842076\ttotal: 4.36s\tremaining: 35.6s\n",
            "109:\tlearn: 0.4818478\ttotal: 4.39s\tremaining: 35.6s\n",
            "110:\tlearn: 0.4796469\ttotal: 4.43s\tremaining: 35.5s\n",
            "111:\tlearn: 0.4765893\ttotal: 4.48s\tremaining: 35.5s\n",
            "112:\tlearn: 0.4737447\ttotal: 4.51s\tremaining: 35.4s\n",
            "113:\tlearn: 0.4719185\ttotal: 4.55s\tremaining: 35.4s\n",
            "114:\tlearn: 0.4682529\ttotal: 4.59s\tremaining: 35.3s\n",
            "115:\tlearn: 0.4660720\ttotal: 4.63s\tremaining: 35.3s\n",
            "116:\tlearn: 0.4643176\ttotal: 4.67s\tremaining: 35.2s\n",
            "117:\tlearn: 0.4616948\ttotal: 4.71s\tremaining: 35.2s\n",
            "118:\tlearn: 0.4584735\ttotal: 4.76s\tremaining: 35.2s\n",
            "119:\tlearn: 0.4538428\ttotal: 4.79s\tremaining: 35.2s\n",
            "120:\tlearn: 0.4518214\ttotal: 4.83s\tremaining: 35.1s\n",
            "121:\tlearn: 0.4488629\ttotal: 4.87s\tremaining: 35s\n",
            "122:\tlearn: 0.4464858\ttotal: 4.91s\tremaining: 35s\n",
            "123:\tlearn: 0.4436645\ttotal: 4.95s\tremaining: 35s\n",
            "124:\tlearn: 0.4410238\ttotal: 5s\tremaining: 35s\n",
            "125:\tlearn: 0.4380828\ttotal: 5.04s\tremaining: 34.9s\n",
            "126:\tlearn: 0.4353007\ttotal: 5.08s\tremaining: 34.9s\n",
            "127:\tlearn: 0.4308203\ttotal: 5.12s\tremaining: 34.9s\n",
            "128:\tlearn: 0.4293107\ttotal: 5.16s\tremaining: 34.8s\n",
            "129:\tlearn: 0.4265984\ttotal: 5.2s\tremaining: 34.8s\n",
            "130:\tlearn: 0.4243051\ttotal: 5.23s\tremaining: 34.7s\n",
            "131:\tlearn: 0.4219101\ttotal: 5.27s\tremaining: 34.7s\n",
            "132:\tlearn: 0.4203504\ttotal: 5.31s\tremaining: 34.6s\n",
            "133:\tlearn: 0.4165067\ttotal: 5.35s\tremaining: 34.6s\n",
            "134:\tlearn: 0.4132987\ttotal: 5.39s\tremaining: 34.6s\n",
            "135:\tlearn: 0.4109517\ttotal: 5.43s\tremaining: 34.5s\n",
            "136:\tlearn: 0.4077354\ttotal: 5.47s\tremaining: 34.4s\n",
            "137:\tlearn: 0.4061643\ttotal: 5.5s\tremaining: 34.4s\n",
            "138:\tlearn: 0.4048466\ttotal: 5.54s\tremaining: 34.3s\n",
            "139:\tlearn: 0.4008348\ttotal: 5.58s\tremaining: 34.3s\n",
            "140:\tlearn: 0.3982858\ttotal: 5.62s\tremaining: 34.3s\n",
            "141:\tlearn: 0.3961156\ttotal: 5.66s\tremaining: 34.2s\n",
            "142:\tlearn: 0.3937530\ttotal: 5.7s\tremaining: 34.2s\n",
            "143:\tlearn: 0.3919573\ttotal: 5.72s\tremaining: 34s\n",
            "144:\tlearn: 0.3907889\ttotal: 5.76s\tremaining: 34s\n",
            "145:\tlearn: 0.3886160\ttotal: 5.8s\tremaining: 33.9s\n",
            "146:\tlearn: 0.3875389\ttotal: 5.84s\tremaining: 33.9s\n",
            "147:\tlearn: 0.3861189\ttotal: 5.88s\tremaining: 33.8s\n",
            "148:\tlearn: 0.3845805\ttotal: 5.91s\tremaining: 33.8s\n",
            "149:\tlearn: 0.3830595\ttotal: 5.95s\tremaining: 33.7s\n",
            "150:\tlearn: 0.3814274\ttotal: 6s\tremaining: 33.7s\n",
            "151:\tlearn: 0.3782819\ttotal: 6.04s\tremaining: 33.7s\n",
            "152:\tlearn: 0.3764943\ttotal: 6.08s\tremaining: 33.7s\n",
            "153:\tlearn: 0.3743896\ttotal: 6.12s\tremaining: 33.6s\n",
            "154:\tlearn: 0.3709470\ttotal: 6.16s\tremaining: 33.6s\n",
            "155:\tlearn: 0.3690985\ttotal: 6.19s\tremaining: 33.5s\n",
            "156:\tlearn: 0.3664015\ttotal: 6.23s\tremaining: 33.5s\n",
            "157:\tlearn: 0.3646339\ttotal: 6.27s\tremaining: 33.4s\n",
            "158:\tlearn: 0.3627046\ttotal: 6.31s\tremaining: 33.4s\n",
            "159:\tlearn: 0.3614714\ttotal: 6.35s\tremaining: 33.3s\n",
            "160:\tlearn: 0.3591318\ttotal: 6.38s\tremaining: 33.3s\n",
            "161:\tlearn: 0.3580074\ttotal: 6.42s\tremaining: 33.2s\n",
            "162:\tlearn: 0.3556654\ttotal: 6.46s\tremaining: 33.2s\n",
            "163:\tlearn: 0.3540158\ttotal: 6.51s\tremaining: 33.2s\n",
            "164:\tlearn: 0.3521673\ttotal: 6.54s\tremaining: 33.1s\n",
            "165:\tlearn: 0.3504059\ttotal: 6.58s\tremaining: 33.1s\n",
            "166:\tlearn: 0.3480495\ttotal: 6.62s\tremaining: 33s\n",
            "167:\tlearn: 0.3467227\ttotal: 6.66s\tremaining: 33s\n",
            "168:\tlearn: 0.3439918\ttotal: 6.7s\tremaining: 32.9s\n",
            "169:\tlearn: 0.3425830\ttotal: 6.74s\tremaining: 32.9s\n",
            "170:\tlearn: 0.3406831\ttotal: 6.77s\tremaining: 32.8s\n",
            "171:\tlearn: 0.3383057\ttotal: 6.82s\tremaining: 32.8s\n",
            "172:\tlearn: 0.3369545\ttotal: 6.85s\tremaining: 32.8s\n",
            "173:\tlearn: 0.3344016\ttotal: 6.89s\tremaining: 32.7s\n",
            "174:\tlearn: 0.3335086\ttotal: 6.93s\tremaining: 32.7s\n",
            "175:\tlearn: 0.3318804\ttotal: 6.97s\tremaining: 32.6s\n",
            "176:\tlearn: 0.3306552\ttotal: 7.02s\tremaining: 32.6s\n",
            "177:\tlearn: 0.3288552\ttotal: 7.05s\tremaining: 32.6s\n",
            "178:\tlearn: 0.3268422\ttotal: 7.09s\tremaining: 32.5s\n",
            "179:\tlearn: 0.3257359\ttotal: 7.13s\tremaining: 32.5s\n",
            "180:\tlearn: 0.3238753\ttotal: 7.17s\tremaining: 32.4s\n",
            "181:\tlearn: 0.3216179\ttotal: 7.21s\tremaining: 32.4s\n",
            "182:\tlearn: 0.3200500\ttotal: 7.25s\tremaining: 32.4s\n",
            "183:\tlearn: 0.3185570\ttotal: 7.29s\tremaining: 32.3s\n",
            "184:\tlearn: 0.3179644\ttotal: 7.32s\tremaining: 32.3s\n",
            "185:\tlearn: 0.3161426\ttotal: 7.36s\tremaining: 32.2s\n",
            "186:\tlearn: 0.3145488\ttotal: 7.41s\tremaining: 32.2s\n",
            "187:\tlearn: 0.3130201\ttotal: 7.45s\tremaining: 32.2s\n",
            "188:\tlearn: 0.3114861\ttotal: 7.49s\tremaining: 32.1s\n",
            "189:\tlearn: 0.3097156\ttotal: 7.53s\tremaining: 32.1s\n",
            "190:\tlearn: 0.3072153\ttotal: 7.56s\tremaining: 32s\n",
            "191:\tlearn: 0.3061472\ttotal: 7.61s\tremaining: 32s\n",
            "192:\tlearn: 0.3044749\ttotal: 7.64s\tremaining: 32s\n",
            "193:\tlearn: 0.3030482\ttotal: 7.68s\tremaining: 31.9s\n",
            "194:\tlearn: 0.3016770\ttotal: 7.72s\tremaining: 31.9s\n",
            "195:\tlearn: 0.3003547\ttotal: 7.76s\tremaining: 31.8s\n",
            "196:\tlearn: 0.2995334\ttotal: 7.8s\tremaining: 31.8s\n",
            "197:\tlearn: 0.2980531\ttotal: 7.84s\tremaining: 31.8s\n",
            "198:\tlearn: 0.2963835\ttotal: 7.88s\tremaining: 31.7s\n",
            "199:\tlearn: 0.2949102\ttotal: 7.92s\tremaining: 31.7s\n",
            "200:\tlearn: 0.2939266\ttotal: 7.96s\tremaining: 31.6s\n",
            "201:\tlearn: 0.2927939\ttotal: 8.01s\tremaining: 31.6s\n",
            "202:\tlearn: 0.2914540\ttotal: 8.05s\tremaining: 31.6s\n",
            "203:\tlearn: 0.2898835\ttotal: 8.09s\tremaining: 31.6s\n",
            "204:\tlearn: 0.2882768\ttotal: 8.13s\tremaining: 31.5s\n",
            "205:\tlearn: 0.2864420\ttotal: 8.17s\tremaining: 31.5s\n",
            "206:\tlearn: 0.2854033\ttotal: 8.21s\tremaining: 31.4s\n",
            "207:\tlearn: 0.2840236\ttotal: 8.25s\tremaining: 31.4s\n",
            "208:\tlearn: 0.2816632\ttotal: 8.29s\tremaining: 31.4s\n",
            "209:\tlearn: 0.2796182\ttotal: 8.33s\tremaining: 31.3s\n",
            "210:\tlearn: 0.2773585\ttotal: 8.37s\tremaining: 31.3s\n",
            "211:\tlearn: 0.2758058\ttotal: 8.41s\tremaining: 31.3s\n",
            "212:\tlearn: 0.2742895\ttotal: 8.45s\tremaining: 31.2s\n",
            "213:\tlearn: 0.2724059\ttotal: 8.48s\tremaining: 31.2s\n",
            "214:\tlearn: 0.2709240\ttotal: 8.53s\tremaining: 31.1s\n",
            "215:\tlearn: 0.2693873\ttotal: 8.56s\tremaining: 31.1s\n",
            "216:\tlearn: 0.2679396\ttotal: 8.6s\tremaining: 31s\n",
            "217:\tlearn: 0.2671324\ttotal: 8.64s\tremaining: 31s\n",
            "218:\tlearn: 0.2660166\ttotal: 8.68s\tremaining: 30.9s\n",
            "219:\tlearn: 0.2644562\ttotal: 8.72s\tremaining: 30.9s\n",
            "220:\tlearn: 0.2629733\ttotal: 8.77s\tremaining: 30.9s\n",
            "221:\tlearn: 0.2613695\ttotal: 8.8s\tremaining: 30.8s\n",
            "222:\tlearn: 0.2602764\ttotal: 8.84s\tremaining: 30.8s\n",
            "223:\tlearn: 0.2594575\ttotal: 8.88s\tremaining: 30.8s\n",
            "224:\tlearn: 0.2581086\ttotal: 8.91s\tremaining: 30.7s\n",
            "225:\tlearn: 0.2572680\ttotal: 8.95s\tremaining: 30.7s\n",
            "226:\tlearn: 0.2559780\ttotal: 9s\tremaining: 30.7s\n",
            "227:\tlearn: 0.2547075\ttotal: 9.05s\tremaining: 30.6s\n",
            "228:\tlearn: 0.2541508\ttotal: 9.11s\tremaining: 30.7s\n",
            "229:\tlearn: 0.2534689\ttotal: 9.14s\tremaining: 30.6s\n",
            "230:\tlearn: 0.2521217\ttotal: 9.18s\tremaining: 30.6s\n",
            "231:\tlearn: 0.2509773\ttotal: 9.22s\tremaining: 30.5s\n",
            "232:\tlearn: 0.2497559\ttotal: 9.26s\tremaining: 30.5s\n",
            "233:\tlearn: 0.2483655\ttotal: 9.3s\tremaining: 30.4s\n",
            "234:\tlearn: 0.2463471\ttotal: 9.34s\tremaining: 30.4s\n",
            "235:\tlearn: 0.2449319\ttotal: 9.38s\tremaining: 30.4s\n",
            "236:\tlearn: 0.2438175\ttotal: 9.42s\tremaining: 30.3s\n",
            "237:\tlearn: 0.2426356\ttotal: 9.46s\tremaining: 30.3s\n",
            "238:\tlearn: 0.2417699\ttotal: 9.5s\tremaining: 30.2s\n",
            "239:\tlearn: 0.2406597\ttotal: 9.54s\tremaining: 30.2s\n",
            "240:\tlearn: 0.2393567\ttotal: 9.58s\tremaining: 30.2s\n",
            "241:\tlearn: 0.2379785\ttotal: 9.62s\tremaining: 30.1s\n",
            "242:\tlearn: 0.2363469\ttotal: 9.66s\tremaining: 30.1s\n",
            "243:\tlearn: 0.2352334\ttotal: 9.7s\tremaining: 30.1s\n",
            "244:\tlearn: 0.2336644\ttotal: 9.74s\tremaining: 30s\n",
            "245:\tlearn: 0.2331497\ttotal: 9.78s\tremaining: 30s\n",
            "246:\tlearn: 0.2315379\ttotal: 9.81s\tremaining: 29.9s\n",
            "247:\tlearn: 0.2300511\ttotal: 9.85s\tremaining: 29.9s\n",
            "248:\tlearn: 0.2289207\ttotal: 9.89s\tremaining: 29.8s\n",
            "249:\tlearn: 0.2279473\ttotal: 9.93s\tremaining: 29.8s\n",
            "250:\tlearn: 0.2261311\ttotal: 9.97s\tremaining: 29.8s\n",
            "251:\tlearn: 0.2250462\ttotal: 10s\tremaining: 29.7s\n",
            "252:\tlearn: 0.2237041\ttotal: 10.1s\tremaining: 29.7s\n",
            "253:\tlearn: 0.2225728\ttotal: 10.1s\tremaining: 29.7s\n",
            "254:\tlearn: 0.2209278\ttotal: 10.1s\tremaining: 29.6s\n",
            "255:\tlearn: 0.2201427\ttotal: 10.2s\tremaining: 29.6s\n",
            "256:\tlearn: 0.2193547\ttotal: 10.2s\tremaining: 29.5s\n",
            "257:\tlearn: 0.2183732\ttotal: 10.3s\tremaining: 29.5s\n",
            "258:\tlearn: 0.2171926\ttotal: 10.3s\tremaining: 29.4s\n",
            "259:\tlearn: 0.2158888\ttotal: 10.3s\tremaining: 29.4s\n",
            "260:\tlearn: 0.2148391\ttotal: 10.4s\tremaining: 29.4s\n",
            "261:\tlearn: 0.2139073\ttotal: 10.4s\tremaining: 29.3s\n",
            "262:\tlearn: 0.2131886\ttotal: 10.4s\tremaining: 29.3s\n",
            "263:\tlearn: 0.2123513\ttotal: 10.5s\tremaining: 29.2s\n",
            "264:\tlearn: 0.2119720\ttotal: 10.5s\tremaining: 29.2s\n",
            "265:\tlearn: 0.2109466\ttotal: 10.6s\tremaining: 29.2s\n",
            "266:\tlearn: 0.2104205\ttotal: 10.6s\tremaining: 29.1s\n",
            "267:\tlearn: 0.2090736\ttotal: 10.6s\tremaining: 29.1s\n",
            "268:\tlearn: 0.2075382\ttotal: 10.7s\tremaining: 29s\n",
            "269:\tlearn: 0.2067486\ttotal: 10.7s\tremaining: 29s\n",
            "270:\tlearn: 0.2059723\ttotal: 10.8s\tremaining: 29s\n",
            "271:\tlearn: 0.2054650\ttotal: 10.8s\tremaining: 28.9s\n",
            "272:\tlearn: 0.2046510\ttotal: 10.8s\tremaining: 28.9s\n",
            "273:\tlearn: 0.2033411\ttotal: 10.9s\tremaining: 28.8s\n",
            "274:\tlearn: 0.2026151\ttotal: 10.9s\tremaining: 28.8s\n",
            "275:\tlearn: 0.2018203\ttotal: 11s\tremaining: 28.8s\n",
            "276:\tlearn: 0.2002800\ttotal: 11s\tremaining: 28.7s\n",
            "277:\tlearn: 0.1992003\ttotal: 11.1s\tremaining: 28.7s\n",
            "278:\tlearn: 0.1983039\ttotal: 11.1s\tremaining: 28.7s\n",
            "279:\tlearn: 0.1970978\ttotal: 11.1s\tremaining: 28.6s\n",
            "280:\tlearn: 0.1963156\ttotal: 11.2s\tremaining: 28.6s\n",
            "281:\tlearn: 0.1953015\ttotal: 11.2s\tremaining: 28.5s\n",
            "282:\tlearn: 0.1940539\ttotal: 11.2s\tremaining: 28.5s\n",
            "283:\tlearn: 0.1932516\ttotal: 11.3s\tremaining: 28.4s\n",
            "284:\tlearn: 0.1921841\ttotal: 11.3s\tremaining: 28.4s\n",
            "285:\tlearn: 0.1911754\ttotal: 11.4s\tremaining: 28.4s\n",
            "286:\tlearn: 0.1903292\ttotal: 11.4s\tremaining: 28.3s\n",
            "287:\tlearn: 0.1895291\ttotal: 11.4s\tremaining: 28.3s\n",
            "288:\tlearn: 0.1880675\ttotal: 11.5s\tremaining: 28.2s\n",
            "289:\tlearn: 0.1872385\ttotal: 11.5s\tremaining: 28.2s\n",
            "290:\tlearn: 0.1867724\ttotal: 11.6s\tremaining: 28.2s\n",
            "291:\tlearn: 0.1861410\ttotal: 11.6s\tremaining: 28.1s\n",
            "292:\tlearn: 0.1850414\ttotal: 11.6s\tremaining: 28.1s\n",
            "293:\tlearn: 0.1843206\ttotal: 11.7s\tremaining: 28s\n",
            "294:\tlearn: 0.1833780\ttotal: 11.7s\tremaining: 28s\n",
            "295:\tlearn: 0.1828026\ttotal: 11.8s\tremaining: 27.9s\n",
            "296:\tlearn: 0.1821432\ttotal: 11.8s\tremaining: 27.9s\n",
            "297:\tlearn: 0.1815374\ttotal: 11.8s\tremaining: 27.9s\n",
            "298:\tlearn: 0.1808021\ttotal: 11.9s\tremaining: 27.8s\n",
            "299:\tlearn: 0.1798552\ttotal: 11.9s\tremaining: 27.8s\n",
            "300:\tlearn: 0.1787143\ttotal: 11.9s\tremaining: 27.7s\n",
            "301:\tlearn: 0.1781721\ttotal: 12s\tremaining: 27.7s\n",
            "302:\tlearn: 0.1775469\ttotal: 12s\tremaining: 27.7s\n",
            "303:\tlearn: 0.1771237\ttotal: 12.1s\tremaining: 27.6s\n",
            "304:\tlearn: 0.1759443\ttotal: 12.1s\tremaining: 27.6s\n",
            "305:\tlearn: 0.1755688\ttotal: 12.1s\tremaining: 27.6s\n",
            "306:\tlearn: 0.1749716\ttotal: 12.2s\tremaining: 27.5s\n",
            "307:\tlearn: 0.1745338\ttotal: 12.2s\tremaining: 27.5s\n",
            "308:\tlearn: 0.1738667\ttotal: 12.3s\tremaining: 27.4s\n",
            "309:\tlearn: 0.1728155\ttotal: 12.3s\tremaining: 27.4s\n",
            "310:\tlearn: 0.1718642\ttotal: 12.3s\tremaining: 27.4s\n",
            "311:\tlearn: 0.1711045\ttotal: 12.4s\tremaining: 27.3s\n",
            "312:\tlearn: 0.1701180\ttotal: 12.4s\tremaining: 27.3s\n",
            "313:\tlearn: 0.1693082\ttotal: 12.5s\tremaining: 27.2s\n",
            "314:\tlearn: 0.1684939\ttotal: 12.5s\tremaining: 27.2s\n",
            "315:\tlearn: 0.1677682\ttotal: 12.6s\tremaining: 27.2s\n",
            "316:\tlearn: 0.1667883\ttotal: 12.6s\tremaining: 27.1s\n",
            "317:\tlearn: 0.1664006\ttotal: 12.6s\tremaining: 27.1s\n",
            "318:\tlearn: 0.1658319\ttotal: 12.7s\tremaining: 27s\n",
            "319:\tlearn: 0.1649359\ttotal: 12.7s\tremaining: 27s\n",
            "320:\tlearn: 0.1646194\ttotal: 12.7s\tremaining: 27s\n",
            "321:\tlearn: 0.1639207\ttotal: 12.8s\tremaining: 26.9s\n",
            "322:\tlearn: 0.1631449\ttotal: 12.8s\tremaining: 26.9s\n",
            "323:\tlearn: 0.1624598\ttotal: 12.9s\tremaining: 26.8s\n",
            "324:\tlearn: 0.1616101\ttotal: 12.9s\tremaining: 26.8s\n",
            "325:\tlearn: 0.1607826\ttotal: 12.9s\tremaining: 26.7s\n",
            "326:\tlearn: 0.1599665\ttotal: 13s\tremaining: 26.7s\n",
            "327:\tlearn: 0.1594821\ttotal: 13s\tremaining: 26.7s\n",
            "328:\tlearn: 0.1589024\ttotal: 13.1s\tremaining: 26.6s\n",
            "329:\tlearn: 0.1584827\ttotal: 13.1s\tremaining: 26.6s\n",
            "330:\tlearn: 0.1579700\ttotal: 13.1s\tremaining: 26.6s\n",
            "331:\tlearn: 0.1571790\ttotal: 13.2s\tremaining: 26.5s\n",
            "332:\tlearn: 0.1565773\ttotal: 13.2s\tremaining: 26.5s\n",
            "333:\tlearn: 0.1560623\ttotal: 13.3s\tremaining: 26.4s\n",
            "334:\tlearn: 0.1554634\ttotal: 13.3s\tremaining: 26.4s\n",
            "335:\tlearn: 0.1547134\ttotal: 13.3s\tremaining: 26.4s\n",
            "336:\tlearn: 0.1537965\ttotal: 13.4s\tremaining: 26.3s\n",
            "337:\tlearn: 0.1531121\ttotal: 13.4s\tremaining: 26.3s\n",
            "338:\tlearn: 0.1524852\ttotal: 13.4s\tremaining: 26.2s\n",
            "339:\tlearn: 0.1517564\ttotal: 13.5s\tremaining: 26.2s\n",
            "340:\tlearn: 0.1511070\ttotal: 13.5s\tremaining: 26.2s\n",
            "341:\tlearn: 0.1504688\ttotal: 13.6s\tremaining: 26.1s\n",
            "342:\tlearn: 0.1501370\ttotal: 13.6s\tremaining: 26.1s\n",
            "343:\tlearn: 0.1495271\ttotal: 13.6s\tremaining: 26s\n",
            "344:\tlearn: 0.1491645\ttotal: 13.7s\tremaining: 26s\n",
            "345:\tlearn: 0.1487433\ttotal: 13.7s\tremaining: 25.9s\n",
            "346:\tlearn: 0.1480698\ttotal: 13.8s\tremaining: 25.9s\n",
            "347:\tlearn: 0.1475638\ttotal: 13.8s\tremaining: 25.9s\n",
            "348:\tlearn: 0.1468348\ttotal: 13.8s\tremaining: 25.8s\n",
            "349:\tlearn: 0.1461495\ttotal: 13.9s\tremaining: 25.8s\n",
            "350:\tlearn: 0.1456295\ttotal: 13.9s\tremaining: 25.7s\n",
            "351:\tlearn: 0.1450004\ttotal: 13.9s\tremaining: 25.7s\n",
            "352:\tlearn: 0.1444502\ttotal: 14s\tremaining: 25.6s\n",
            "353:\tlearn: 0.1440369\ttotal: 14s\tremaining: 25.6s\n",
            "354:\tlearn: 0.1433424\ttotal: 14.1s\tremaining: 25.6s\n",
            "355:\tlearn: 0.1425147\ttotal: 14.1s\tremaining: 25.5s\n",
            "356:\tlearn: 0.1421441\ttotal: 14.2s\tremaining: 25.5s\n",
            "357:\tlearn: 0.1414149\ttotal: 14.2s\tremaining: 25.4s\n",
            "358:\tlearn: 0.1405963\ttotal: 14.2s\tremaining: 25.4s\n",
            "359:\tlearn: 0.1402296\ttotal: 14.3s\tremaining: 25.4s\n",
            "360:\tlearn: 0.1397822\ttotal: 14.3s\tremaining: 25.3s\n",
            "361:\tlearn: 0.1390809\ttotal: 14.3s\tremaining: 25.3s\n",
            "362:\tlearn: 0.1384786\ttotal: 14.4s\tremaining: 25.2s\n",
            "363:\tlearn: 0.1379705\ttotal: 14.4s\tremaining: 25.2s\n",
            "364:\tlearn: 0.1374331\ttotal: 14.5s\tremaining: 25.2s\n",
            "365:\tlearn: 0.1369035\ttotal: 14.5s\tremaining: 25.1s\n",
            "366:\tlearn: 0.1367679\ttotal: 14.5s\tremaining: 25s\n",
            "367:\tlearn: 0.1363568\ttotal: 14.6s\tremaining: 25s\n",
            "368:\tlearn: 0.1356938\ttotal: 14.6s\tremaining: 25s\n",
            "369:\tlearn: 0.1350234\ttotal: 14.6s\tremaining: 24.9s\n",
            "370:\tlearn: 0.1345176\ttotal: 14.7s\tremaining: 24.9s\n",
            "371:\tlearn: 0.1342041\ttotal: 14.7s\tremaining: 24.8s\n",
            "372:\tlearn: 0.1337627\ttotal: 14.7s\tremaining: 24.8s\n",
            "373:\tlearn: 0.1331963\ttotal: 14.8s\tremaining: 24.8s\n",
            "374:\tlearn: 0.1327547\ttotal: 14.8s\tremaining: 24.7s\n",
            "375:\tlearn: 0.1320655\ttotal: 14.9s\tremaining: 24.7s\n",
            "376:\tlearn: 0.1314688\ttotal: 14.9s\tremaining: 24.6s\n",
            "377:\tlearn: 0.1307295\ttotal: 14.9s\tremaining: 24.6s\n",
            "378:\tlearn: 0.1304434\ttotal: 15s\tremaining: 24.6s\n",
            "379:\tlearn: 0.1298308\ttotal: 15s\tremaining: 24.5s\n",
            "380:\tlearn: 0.1290686\ttotal: 15.1s\tremaining: 24.5s\n",
            "381:\tlearn: 0.1285579\ttotal: 15.1s\tremaining: 24.4s\n",
            "382:\tlearn: 0.1278309\ttotal: 15.2s\tremaining: 24.4s\n",
            "383:\tlearn: 0.1276853\ttotal: 15.2s\tremaining: 24.4s\n",
            "384:\tlearn: 0.1272344\ttotal: 15.2s\tremaining: 24.3s\n",
            "385:\tlearn: 0.1270236\ttotal: 15.3s\tremaining: 24.3s\n",
            "386:\tlearn: 0.1267056\ttotal: 15.3s\tremaining: 24.3s\n",
            "387:\tlearn: 0.1261946\ttotal: 15.4s\tremaining: 24.2s\n",
            "388:\tlearn: 0.1256120\ttotal: 15.4s\tremaining: 24.2s\n",
            "389:\tlearn: 0.1249739\ttotal: 15.4s\tremaining: 24.1s\n",
            "390:\tlearn: 0.1242908\ttotal: 15.5s\tremaining: 24.1s\n",
            "391:\tlearn: 0.1237689\ttotal: 15.5s\tremaining: 24s\n",
            "392:\tlearn: 0.1235334\ttotal: 15.5s\tremaining: 24s\n",
            "393:\tlearn: 0.1231059\ttotal: 15.6s\tremaining: 24s\n",
            "394:\tlearn: 0.1226034\ttotal: 15.6s\tremaining: 23.9s\n",
            "395:\tlearn: 0.1222788\ttotal: 15.7s\tremaining: 23.9s\n",
            "396:\tlearn: 0.1215711\ttotal: 15.7s\tremaining: 23.9s\n",
            "397:\tlearn: 0.1207669\ttotal: 15.7s\tremaining: 23.8s\n",
            "398:\tlearn: 0.1203596\ttotal: 15.8s\tremaining: 23.8s\n",
            "399:\tlearn: 0.1198017\ttotal: 15.8s\tremaining: 23.7s\n",
            "400:\tlearn: 0.1193739\ttotal: 15.9s\tremaining: 23.7s\n",
            "401:\tlearn: 0.1191678\ttotal: 15.9s\tremaining: 23.6s\n",
            "402:\tlearn: 0.1187218\ttotal: 15.9s\tremaining: 23.6s\n",
            "403:\tlearn: 0.1180939\ttotal: 16s\tremaining: 23.6s\n",
            "404:\tlearn: 0.1176742\ttotal: 16s\tremaining: 23.5s\n",
            "405:\tlearn: 0.1174853\ttotal: 16.1s\tremaining: 23.5s\n",
            "406:\tlearn: 0.1170776\ttotal: 16.1s\tremaining: 23.5s\n",
            "407:\tlearn: 0.1167270\ttotal: 16.1s\tremaining: 23.4s\n",
            "408:\tlearn: 0.1160978\ttotal: 16.2s\tremaining: 23.4s\n",
            "409:\tlearn: 0.1155400\ttotal: 16.2s\tremaining: 23.3s\n",
            "410:\tlearn: 0.1153810\ttotal: 16.3s\tremaining: 23.3s\n",
            "411:\tlearn: 0.1151157\ttotal: 16.3s\tremaining: 23.3s\n",
            "412:\tlearn: 0.1146370\ttotal: 16.3s\tremaining: 23.2s\n",
            "413:\tlearn: 0.1141297\ttotal: 16.4s\tremaining: 23.2s\n",
            "414:\tlearn: 0.1138410\ttotal: 16.4s\tremaining: 23.1s\n",
            "415:\tlearn: 0.1133895\ttotal: 16.5s\tremaining: 23.1s\n",
            "416:\tlearn: 0.1128309\ttotal: 16.5s\tremaining: 23.1s\n",
            "417:\tlearn: 0.1123038\ttotal: 16.5s\tremaining: 23s\n",
            "418:\tlearn: 0.1119618\ttotal: 16.6s\tremaining: 23s\n",
            "419:\tlearn: 0.1117050\ttotal: 16.6s\tremaining: 22.9s\n",
            "420:\tlearn: 0.1111157\ttotal: 16.6s\tremaining: 22.9s\n",
            "421:\tlearn: 0.1107898\ttotal: 16.7s\tremaining: 22.9s\n",
            "422:\tlearn: 0.1104312\ttotal: 16.7s\tremaining: 22.8s\n",
            "423:\tlearn: 0.1100480\ttotal: 16.8s\tremaining: 22.8s\n",
            "424:\tlearn: 0.1095992\ttotal: 16.8s\tremaining: 22.7s\n",
            "425:\tlearn: 0.1093439\ttotal: 16.8s\tremaining: 22.7s\n",
            "426:\tlearn: 0.1088991\ttotal: 16.9s\tremaining: 22.7s\n",
            "427:\tlearn: 0.1083913\ttotal: 16.9s\tremaining: 22.6s\n",
            "428:\tlearn: 0.1080092\ttotal: 17s\tremaining: 22.6s\n",
            "429:\tlearn: 0.1076982\ttotal: 17s\tremaining: 22.5s\n",
            "430:\tlearn: 0.1072849\ttotal: 17s\tremaining: 22.5s\n",
            "431:\tlearn: 0.1068665\ttotal: 17.1s\tremaining: 22.5s\n",
            "432:\tlearn: 0.1065768\ttotal: 17.1s\tremaining: 22.4s\n",
            "433:\tlearn: 0.1062144\ttotal: 17.2s\tremaining: 22.4s\n",
            "434:\tlearn: 0.1058687\ttotal: 17.2s\tremaining: 22.4s\n",
            "435:\tlearn: 0.1055510\ttotal: 17.2s\tremaining: 22.3s\n",
            "436:\tlearn: 0.1053313\ttotal: 17.3s\tremaining: 22.3s\n",
            "437:\tlearn: 0.1049117\ttotal: 17.3s\tremaining: 22.2s\n",
            "438:\tlearn: 0.1046273\ttotal: 17.4s\tremaining: 22.2s\n",
            "439:\tlearn: 0.1042678\ttotal: 17.4s\tremaining: 22.2s\n",
            "440:\tlearn: 0.1036761\ttotal: 17.4s\tremaining: 22.1s\n",
            "441:\tlearn: 0.1034300\ttotal: 17.5s\tremaining: 22.1s\n",
            "442:\tlearn: 0.1031310\ttotal: 17.5s\tremaining: 22s\n",
            "443:\tlearn: 0.1027816\ttotal: 17.6s\tremaining: 22s\n",
            "444:\tlearn: 0.1024467\ttotal: 17.6s\tremaining: 21.9s\n",
            "445:\tlearn: 0.1019777\ttotal: 17.6s\tremaining: 21.9s\n",
            "446:\tlearn: 0.1017394\ttotal: 17.7s\tremaining: 21.9s\n",
            "447:\tlearn: 0.1013584\ttotal: 17.7s\tremaining: 21.8s\n",
            "448:\tlearn: 0.1011845\ttotal: 17.8s\tremaining: 21.8s\n",
            "449:\tlearn: 0.1007494\ttotal: 17.8s\tremaining: 21.7s\n",
            "450:\tlearn: 0.1004565\ttotal: 17.8s\tremaining: 21.7s\n",
            "451:\tlearn: 0.0998459\ttotal: 17.9s\tremaining: 21.7s\n",
            "452:\tlearn: 0.0994845\ttotal: 17.9s\tremaining: 21.6s\n",
            "453:\tlearn: 0.0990908\ttotal: 17.9s\tremaining: 21.6s\n",
            "454:\tlearn: 0.0987903\ttotal: 18s\tremaining: 21.6s\n",
            "455:\tlearn: 0.0983536\ttotal: 18s\tremaining: 21.5s\n",
            "456:\tlearn: 0.0980560\ttotal: 18.1s\tremaining: 21.5s\n",
            "457:\tlearn: 0.0978548\ttotal: 18.1s\tremaining: 21.4s\n",
            "458:\tlearn: 0.0976169\ttotal: 18.2s\tremaining: 21.4s\n",
            "459:\tlearn: 0.0971194\ttotal: 18.2s\tremaining: 21.4s\n",
            "460:\tlearn: 0.0969254\ttotal: 18.2s\tremaining: 21.3s\n",
            "461:\tlearn: 0.0966786\ttotal: 18.3s\tremaining: 21.3s\n",
            "462:\tlearn: 0.0963574\ttotal: 18.3s\tremaining: 21.2s\n",
            "463:\tlearn: 0.0961436\ttotal: 18.3s\tremaining: 21.2s\n",
            "464:\tlearn: 0.0958389\ttotal: 18.4s\tremaining: 21.1s\n",
            "465:\tlearn: 0.0955129\ttotal: 18.4s\tremaining: 21.1s\n",
            "466:\tlearn: 0.0952645\ttotal: 18.5s\tremaining: 21.1s\n",
            "467:\tlearn: 0.0950281\ttotal: 18.5s\tremaining: 21s\n",
            "468:\tlearn: 0.0947919\ttotal: 18.6s\tremaining: 21s\n",
            "469:\tlearn: 0.0944589\ttotal: 18.6s\tremaining: 21s\n",
            "470:\tlearn: 0.0941534\ttotal: 18.6s\tremaining: 20.9s\n",
            "471:\tlearn: 0.0938737\ttotal: 18.7s\tremaining: 20.9s\n",
            "472:\tlearn: 0.0933683\ttotal: 18.7s\tremaining: 20.8s\n",
            "473:\tlearn: 0.0930052\ttotal: 18.7s\tremaining: 20.8s\n",
            "474:\tlearn: 0.0925917\ttotal: 18.8s\tremaining: 20.8s\n",
            "475:\tlearn: 0.0923140\ttotal: 18.8s\tremaining: 20.7s\n",
            "476:\tlearn: 0.0920359\ttotal: 18.9s\tremaining: 20.7s\n",
            "477:\tlearn: 0.0919487\ttotal: 18.9s\tremaining: 20.6s\n",
            "478:\tlearn: 0.0916869\ttotal: 18.9s\tremaining: 20.6s\n",
            "479:\tlearn: 0.0914034\ttotal: 19s\tremaining: 20.6s\n",
            "480:\tlearn: 0.0911415\ttotal: 19s\tremaining: 20.5s\n",
            "481:\tlearn: 0.0909515\ttotal: 19.1s\tremaining: 20.5s\n",
            "482:\tlearn: 0.0905669\ttotal: 19.1s\tremaining: 20.4s\n",
            "483:\tlearn: 0.0902653\ttotal: 19.1s\tremaining: 20.4s\n",
            "484:\tlearn: 0.0899730\ttotal: 19.2s\tremaining: 20.4s\n",
            "485:\tlearn: 0.0896446\ttotal: 19.2s\tremaining: 20.4s\n",
            "486:\tlearn: 0.0894988\ttotal: 19.3s\tremaining: 20.3s\n",
            "487:\tlearn: 0.0893006\ttotal: 19.3s\tremaining: 20.3s\n",
            "488:\tlearn: 0.0891669\ttotal: 19.4s\tremaining: 20.2s\n",
            "489:\tlearn: 0.0888707\ttotal: 19.4s\tremaining: 20.2s\n",
            "490:\tlearn: 0.0886986\ttotal: 19.4s\tremaining: 20.2s\n",
            "491:\tlearn: 0.0884763\ttotal: 19.5s\tremaining: 20.1s\n",
            "492:\tlearn: 0.0882088\ttotal: 19.5s\tremaining: 20.1s\n",
            "493:\tlearn: 0.0880851\ttotal: 19.6s\tremaining: 20s\n",
            "494:\tlearn: 0.0876551\ttotal: 19.6s\tremaining: 20s\n",
            "495:\tlearn: 0.0875265\ttotal: 19.6s\tremaining: 20s\n",
            "496:\tlearn: 0.0871110\ttotal: 19.7s\tremaining: 19.9s\n",
            "497:\tlearn: 0.0869169\ttotal: 19.7s\tremaining: 19.9s\n",
            "498:\tlearn: 0.0866396\ttotal: 19.7s\tremaining: 19.8s\n",
            "499:\tlearn: 0.0863825\ttotal: 19.8s\tremaining: 19.8s\n",
            "500:\tlearn: 0.0861090\ttotal: 19.8s\tremaining: 19.8s\n",
            "501:\tlearn: 0.0858791\ttotal: 19.9s\tremaining: 19.7s\n",
            "502:\tlearn: 0.0855655\ttotal: 19.9s\tremaining: 19.7s\n",
            "503:\tlearn: 0.0854126\ttotal: 19.9s\tremaining: 19.6s\n",
            "504:\tlearn: 0.0851992\ttotal: 20s\tremaining: 19.6s\n",
            "505:\tlearn: 0.0850078\ttotal: 20s\tremaining: 19.6s\n",
            "506:\tlearn: 0.0846029\ttotal: 20.1s\tremaining: 19.5s\n",
            "507:\tlearn: 0.0843931\ttotal: 20.1s\tremaining: 19.5s\n",
            "508:\tlearn: 0.0841123\ttotal: 20.2s\tremaining: 19.4s\n",
            "509:\tlearn: 0.0838758\ttotal: 20.2s\tremaining: 19.4s\n",
            "510:\tlearn: 0.0837248\ttotal: 20.2s\tremaining: 19.4s\n",
            "511:\tlearn: 0.0835795\ttotal: 20.3s\tremaining: 19.3s\n",
            "512:\tlearn: 0.0834421\ttotal: 20.3s\tremaining: 19.3s\n",
            "513:\tlearn: 0.0831982\ttotal: 20.4s\tremaining: 19.2s\n",
            "514:\tlearn: 0.0828356\ttotal: 20.4s\tremaining: 19.2s\n",
            "515:\tlearn: 0.0825572\ttotal: 20.4s\tremaining: 19.2s\n",
            "516:\tlearn: 0.0823373\ttotal: 20.5s\tremaining: 19.1s\n",
            "517:\tlearn: 0.0821481\ttotal: 20.5s\tremaining: 19.1s\n",
            "518:\tlearn: 0.0819595\ttotal: 20.6s\tremaining: 19s\n",
            "519:\tlearn: 0.0817252\ttotal: 20.6s\tremaining: 19s\n",
            "520:\tlearn: 0.0813680\ttotal: 20.6s\tremaining: 19s\n",
            "521:\tlearn: 0.0811331\ttotal: 20.7s\tremaining: 18.9s\n",
            "522:\tlearn: 0.0810097\ttotal: 20.7s\tremaining: 18.9s\n",
            "523:\tlearn: 0.0807819\ttotal: 20.7s\tremaining: 18.8s\n",
            "524:\tlearn: 0.0805088\ttotal: 20.8s\tremaining: 18.8s\n",
            "525:\tlearn: 0.0803049\ttotal: 20.8s\tremaining: 18.8s\n",
            "526:\tlearn: 0.0800739\ttotal: 20.9s\tremaining: 18.7s\n",
            "527:\tlearn: 0.0799082\ttotal: 20.9s\tremaining: 18.7s\n",
            "528:\tlearn: 0.0796776\ttotal: 20.9s\tremaining: 18.6s\n",
            "529:\tlearn: 0.0794701\ttotal: 21s\tremaining: 18.6s\n",
            "530:\tlearn: 0.0792822\ttotal: 21s\tremaining: 18.6s\n",
            "531:\tlearn: 0.0791237\ttotal: 21.1s\tremaining: 18.5s\n",
            "532:\tlearn: 0.0789542\ttotal: 21.1s\tremaining: 18.5s\n",
            "533:\tlearn: 0.0786826\ttotal: 21.1s\tremaining: 18.5s\n",
            "534:\tlearn: 0.0785157\ttotal: 21.2s\tremaining: 18.4s\n",
            "535:\tlearn: 0.0782944\ttotal: 21.2s\tremaining: 18.4s\n",
            "536:\tlearn: 0.0780280\ttotal: 21.3s\tremaining: 18.3s\n",
            "537:\tlearn: 0.0777742\ttotal: 21.3s\tremaining: 18.3s\n",
            "538:\tlearn: 0.0776681\ttotal: 21.3s\tremaining: 18.3s\n",
            "539:\tlearn: 0.0773944\ttotal: 21.4s\tremaining: 18.2s\n",
            "540:\tlearn: 0.0771613\ttotal: 21.4s\tremaining: 18.2s\n",
            "541:\tlearn: 0.0769568\ttotal: 21.5s\tremaining: 18.1s\n",
            "542:\tlearn: 0.0766198\ttotal: 21.5s\tremaining: 18.1s\n",
            "543:\tlearn: 0.0764196\ttotal: 21.5s\tremaining: 18.1s\n",
            "544:\tlearn: 0.0761944\ttotal: 21.6s\tremaining: 18s\n",
            "545:\tlearn: 0.0760439\ttotal: 21.6s\tremaining: 18s\n",
            "546:\tlearn: 0.0759470\ttotal: 21.7s\tremaining: 17.9s\n",
            "547:\tlearn: 0.0757434\ttotal: 21.7s\tremaining: 17.9s\n",
            "548:\tlearn: 0.0754878\ttotal: 21.7s\tremaining: 17.9s\n",
            "549:\tlearn: 0.0753558\ttotal: 21.8s\tremaining: 17.8s\n",
            "550:\tlearn: 0.0750453\ttotal: 21.8s\tremaining: 17.8s\n",
            "551:\tlearn: 0.0749141\ttotal: 21.8s\tremaining: 17.7s\n",
            "552:\tlearn: 0.0747098\ttotal: 21.9s\tremaining: 17.7s\n",
            "553:\tlearn: 0.0744740\ttotal: 21.9s\tremaining: 17.7s\n",
            "554:\tlearn: 0.0742087\ttotal: 22s\tremaining: 17.6s\n",
            "555:\tlearn: 0.0739258\ttotal: 22s\tremaining: 17.6s\n",
            "556:\tlearn: 0.0737505\ttotal: 22.1s\tremaining: 17.5s\n",
            "557:\tlearn: 0.0734814\ttotal: 22.1s\tremaining: 17.5s\n",
            "558:\tlearn: 0.0732301\ttotal: 22.1s\tremaining: 17.5s\n",
            "559:\tlearn: 0.0729824\ttotal: 22.2s\tremaining: 17.4s\n",
            "560:\tlearn: 0.0728787\ttotal: 22.2s\tremaining: 17.4s\n",
            "561:\tlearn: 0.0726143\ttotal: 22.3s\tremaining: 17.3s\n",
            "562:\tlearn: 0.0723138\ttotal: 22.3s\tremaining: 17.3s\n",
            "563:\tlearn: 0.0721241\ttotal: 22.3s\tremaining: 17.3s\n",
            "564:\tlearn: 0.0719695\ttotal: 22.4s\tremaining: 17.2s\n",
            "565:\tlearn: 0.0717451\ttotal: 22.4s\tremaining: 17.2s\n",
            "566:\tlearn: 0.0715664\ttotal: 22.5s\tremaining: 17.1s\n",
            "567:\tlearn: 0.0713592\ttotal: 22.5s\tremaining: 17.1s\n",
            "568:\tlearn: 0.0710456\ttotal: 22.5s\tremaining: 17.1s\n",
            "569:\tlearn: 0.0707851\ttotal: 22.6s\tremaining: 17s\n",
            "570:\tlearn: 0.0705106\ttotal: 22.6s\tremaining: 17s\n",
            "571:\tlearn: 0.0703872\ttotal: 22.6s\tremaining: 16.9s\n",
            "572:\tlearn: 0.0701830\ttotal: 22.7s\tremaining: 16.9s\n",
            "573:\tlearn: 0.0700980\ttotal: 22.7s\tremaining: 16.9s\n",
            "574:\tlearn: 0.0699275\ttotal: 22.8s\tremaining: 16.8s\n",
            "575:\tlearn: 0.0698281\ttotal: 22.8s\tremaining: 16.8s\n",
            "576:\tlearn: 0.0696083\ttotal: 22.8s\tremaining: 16.7s\n",
            "577:\tlearn: 0.0693829\ttotal: 22.9s\tremaining: 16.7s\n",
            "578:\tlearn: 0.0692207\ttotal: 22.9s\tremaining: 16.7s\n",
            "579:\tlearn: 0.0690003\ttotal: 23s\tremaining: 16.6s\n",
            "580:\tlearn: 0.0688055\ttotal: 23s\tremaining: 16.6s\n",
            "581:\tlearn: 0.0686361\ttotal: 23.1s\tremaining: 16.6s\n",
            "582:\tlearn: 0.0685321\ttotal: 23.1s\tremaining: 16.5s\n",
            "583:\tlearn: 0.0682977\ttotal: 23.1s\tremaining: 16.5s\n",
            "584:\tlearn: 0.0682024\ttotal: 23.2s\tremaining: 16.4s\n",
            "585:\tlearn: 0.0679386\ttotal: 23.2s\tremaining: 16.4s\n",
            "586:\tlearn: 0.0678140\ttotal: 23.2s\tremaining: 16.4s\n",
            "587:\tlearn: 0.0676561\ttotal: 23.3s\tremaining: 16.3s\n",
            "588:\tlearn: 0.0674529\ttotal: 23.3s\tremaining: 16.3s\n",
            "589:\tlearn: 0.0673301\ttotal: 23.4s\tremaining: 16.2s\n",
            "590:\tlearn: 0.0671551\ttotal: 23.4s\tremaining: 16.2s\n",
            "591:\tlearn: 0.0669802\ttotal: 23.4s\tremaining: 16.2s\n",
            "592:\tlearn: 0.0668183\ttotal: 23.5s\tremaining: 16.1s\n",
            "593:\tlearn: 0.0666554\ttotal: 23.5s\tremaining: 16.1s\n",
            "594:\tlearn: 0.0665300\ttotal: 23.6s\tremaining: 16s\n",
            "595:\tlearn: 0.0664365\ttotal: 23.6s\tremaining: 16s\n",
            "596:\tlearn: 0.0662502\ttotal: 23.6s\tremaining: 16s\n",
            "597:\tlearn: 0.0659730\ttotal: 23.7s\tremaining: 15.9s\n",
            "598:\tlearn: 0.0658402\ttotal: 23.7s\tremaining: 15.9s\n",
            "599:\tlearn: 0.0657690\ttotal: 23.8s\tremaining: 15.8s\n",
            "600:\tlearn: 0.0656182\ttotal: 23.8s\tremaining: 15.8s\n",
            "601:\tlearn: 0.0654734\ttotal: 23.8s\tremaining: 15.8s\n",
            "602:\tlearn: 0.0652416\ttotal: 23.9s\tremaining: 15.7s\n",
            "603:\tlearn: 0.0650917\ttotal: 23.9s\tremaining: 15.7s\n",
            "604:\tlearn: 0.0649906\ttotal: 24s\tremaining: 15.6s\n",
            "605:\tlearn: 0.0647719\ttotal: 24s\tremaining: 15.6s\n",
            "606:\tlearn: 0.0645823\ttotal: 24.1s\tremaining: 15.6s\n",
            "607:\tlearn: 0.0643395\ttotal: 24.1s\tremaining: 15.5s\n",
            "608:\tlearn: 0.0640909\ttotal: 24.1s\tremaining: 15.5s\n",
            "609:\tlearn: 0.0638160\ttotal: 24.2s\tremaining: 15.5s\n",
            "610:\tlearn: 0.0637045\ttotal: 24.2s\tremaining: 15.4s\n",
            "611:\tlearn: 0.0636098\ttotal: 24.3s\tremaining: 15.4s\n",
            "612:\tlearn: 0.0634803\ttotal: 24.3s\tremaining: 15.3s\n",
            "613:\tlearn: 0.0633577\ttotal: 24.3s\tremaining: 15.3s\n",
            "614:\tlearn: 0.0632293\ttotal: 24.4s\tremaining: 15.3s\n",
            "615:\tlearn: 0.0630502\ttotal: 24.4s\tremaining: 15.2s\n",
            "616:\tlearn: 0.0628306\ttotal: 24.4s\tremaining: 15.2s\n",
            "617:\tlearn: 0.0626631\ttotal: 24.5s\tremaining: 15.1s\n",
            "618:\tlearn: 0.0625335\ttotal: 24.5s\tremaining: 15.1s\n",
            "619:\tlearn: 0.0624044\ttotal: 24.6s\tremaining: 15.1s\n",
            "620:\tlearn: 0.0621573\ttotal: 24.6s\tremaining: 15s\n",
            "621:\tlearn: 0.0620523\ttotal: 24.6s\tremaining: 15s\n",
            "622:\tlearn: 0.0618202\ttotal: 24.7s\tremaining: 14.9s\n",
            "623:\tlearn: 0.0617445\ttotal: 24.7s\tremaining: 14.9s\n",
            "624:\tlearn: 0.0616444\ttotal: 24.8s\tremaining: 14.9s\n",
            "625:\tlearn: 0.0615014\ttotal: 24.8s\tremaining: 14.8s\n",
            "626:\tlearn: 0.0613534\ttotal: 24.8s\tremaining: 14.8s\n",
            "627:\tlearn: 0.0611695\ttotal: 24.9s\tremaining: 14.7s\n",
            "628:\tlearn: 0.0610201\ttotal: 24.9s\tremaining: 14.7s\n",
            "629:\tlearn: 0.0609368\ttotal: 25s\tremaining: 14.7s\n",
            "630:\tlearn: 0.0608062\ttotal: 25s\tremaining: 14.6s\n",
            "631:\tlearn: 0.0606805\ttotal: 25.1s\tremaining: 14.6s\n",
            "632:\tlearn: 0.0605821\ttotal: 25.1s\tremaining: 14.6s\n",
            "633:\tlearn: 0.0603933\ttotal: 25.1s\tremaining: 14.5s\n",
            "634:\tlearn: 0.0602435\ttotal: 25.2s\tremaining: 14.5s\n",
            "635:\tlearn: 0.0600727\ttotal: 25.2s\tremaining: 14.4s\n",
            "636:\tlearn: 0.0599131\ttotal: 25.3s\tremaining: 14.4s\n",
            "637:\tlearn: 0.0598557\ttotal: 25.3s\tremaining: 14.4s\n",
            "638:\tlearn: 0.0596955\ttotal: 25.3s\tremaining: 14.3s\n",
            "639:\tlearn: 0.0595033\ttotal: 25.4s\tremaining: 14.3s\n",
            "640:\tlearn: 0.0593792\ttotal: 25.4s\tremaining: 14.2s\n",
            "641:\tlearn: 0.0592688\ttotal: 25.5s\tremaining: 14.2s\n",
            "642:\tlearn: 0.0591176\ttotal: 25.5s\tremaining: 14.2s\n",
            "643:\tlearn: 0.0589446\ttotal: 25.5s\tremaining: 14.1s\n",
            "644:\tlearn: 0.0587923\ttotal: 25.6s\tremaining: 14.1s\n",
            "645:\tlearn: 0.0586787\ttotal: 25.6s\tremaining: 14s\n",
            "646:\tlearn: 0.0584334\ttotal: 25.6s\tremaining: 14s\n",
            "647:\tlearn: 0.0582769\ttotal: 25.7s\tremaining: 14s\n",
            "648:\tlearn: 0.0581487\ttotal: 25.7s\tremaining: 13.9s\n",
            "649:\tlearn: 0.0579288\ttotal: 25.8s\tremaining: 13.9s\n",
            "650:\tlearn: 0.0577815\ttotal: 25.8s\tremaining: 13.8s\n",
            "651:\tlearn: 0.0575935\ttotal: 25.8s\tremaining: 13.8s\n",
            "652:\tlearn: 0.0575019\ttotal: 25.9s\tremaining: 13.8s\n",
            "653:\tlearn: 0.0573773\ttotal: 25.9s\tremaining: 13.7s\n",
            "654:\tlearn: 0.0572381\ttotal: 26s\tremaining: 13.7s\n",
            "655:\tlearn: 0.0571979\ttotal: 26s\tremaining: 13.6s\n",
            "656:\tlearn: 0.0570983\ttotal: 26.1s\tremaining: 13.6s\n",
            "657:\tlearn: 0.0569966\ttotal: 26.1s\tremaining: 13.6s\n",
            "658:\tlearn: 0.0568308\ttotal: 26.1s\tremaining: 13.5s\n",
            "659:\tlearn: 0.0567320\ttotal: 26.2s\tremaining: 13.5s\n",
            "660:\tlearn: 0.0565713\ttotal: 26.2s\tremaining: 13.4s\n",
            "661:\tlearn: 0.0563832\ttotal: 26.3s\tremaining: 13.4s\n",
            "662:\tlearn: 0.0562291\ttotal: 26.3s\tremaining: 13.4s\n",
            "663:\tlearn: 0.0561088\ttotal: 26.3s\tremaining: 13.3s\n",
            "664:\tlearn: 0.0559827\ttotal: 26.4s\tremaining: 13.3s\n",
            "665:\tlearn: 0.0557840\ttotal: 26.4s\tremaining: 13.2s\n",
            "666:\tlearn: 0.0556508\ttotal: 26.5s\tremaining: 13.2s\n",
            "667:\tlearn: 0.0555119\ttotal: 26.5s\tremaining: 13.2s\n",
            "668:\tlearn: 0.0554056\ttotal: 26.5s\tremaining: 13.1s\n",
            "669:\tlearn: 0.0552174\ttotal: 26.6s\tremaining: 13.1s\n",
            "670:\tlearn: 0.0551298\ttotal: 26.6s\tremaining: 13s\n",
            "671:\tlearn: 0.0550155\ttotal: 26.7s\tremaining: 13s\n",
            "672:\tlearn: 0.0548628\ttotal: 26.7s\tremaining: 13s\n",
            "673:\tlearn: 0.0547534\ttotal: 26.7s\tremaining: 12.9s\n",
            "674:\tlearn: 0.0545979\ttotal: 26.8s\tremaining: 12.9s\n",
            "675:\tlearn: 0.0545228\ttotal: 26.8s\tremaining: 12.8s\n",
            "676:\tlearn: 0.0544293\ttotal: 26.8s\tremaining: 12.8s\n",
            "677:\tlearn: 0.0543357\ttotal: 26.9s\tremaining: 12.8s\n",
            "678:\tlearn: 0.0542606\ttotal: 26.9s\tremaining: 12.7s\n",
            "679:\tlearn: 0.0541316\ttotal: 27s\tremaining: 12.7s\n",
            "680:\tlearn: 0.0539752\ttotal: 27s\tremaining: 12.7s\n",
            "681:\tlearn: 0.0538891\ttotal: 27.1s\tremaining: 12.6s\n",
            "682:\tlearn: 0.0537500\ttotal: 27.1s\tremaining: 12.6s\n",
            "683:\tlearn: 0.0536254\ttotal: 27.1s\tremaining: 12.5s\n",
            "684:\tlearn: 0.0535510\ttotal: 27.2s\tremaining: 12.5s\n",
            "685:\tlearn: 0.0534346\ttotal: 27.2s\tremaining: 12.5s\n",
            "686:\tlearn: 0.0533030\ttotal: 27.3s\tremaining: 12.4s\n",
            "687:\tlearn: 0.0531902\ttotal: 27.3s\tremaining: 12.4s\n",
            "688:\tlearn: 0.0531337\ttotal: 27.3s\tremaining: 12.3s\n",
            "689:\tlearn: 0.0530451\ttotal: 27.4s\tremaining: 12.3s\n",
            "690:\tlearn: 0.0528969\ttotal: 27.4s\tremaining: 12.3s\n",
            "691:\tlearn: 0.0528250\ttotal: 27.4s\tremaining: 12.2s\n",
            "692:\tlearn: 0.0527170\ttotal: 27.5s\tremaining: 12.2s\n",
            "693:\tlearn: 0.0526060\ttotal: 27.5s\tremaining: 12.1s\n",
            "694:\tlearn: 0.0524731\ttotal: 27.6s\tremaining: 12.1s\n",
            "695:\tlearn: 0.0523336\ttotal: 27.6s\tremaining: 12.1s\n",
            "696:\tlearn: 0.0521376\ttotal: 27.6s\tremaining: 12s\n",
            "697:\tlearn: 0.0520202\ttotal: 27.7s\tremaining: 12s\n",
            "698:\tlearn: 0.0518658\ttotal: 27.7s\tremaining: 11.9s\n",
            "699:\tlearn: 0.0517427\ttotal: 27.8s\tremaining: 11.9s\n",
            "700:\tlearn: 0.0516959\ttotal: 27.8s\tremaining: 11.9s\n",
            "701:\tlearn: 0.0515366\ttotal: 27.8s\tremaining: 11.8s\n",
            "702:\tlearn: 0.0514812\ttotal: 27.9s\tremaining: 11.8s\n",
            "703:\tlearn: 0.0513869\ttotal: 27.9s\tremaining: 11.7s\n",
            "704:\tlearn: 0.0512198\ttotal: 28s\tremaining: 11.7s\n",
            "705:\tlearn: 0.0511619\ttotal: 28s\tremaining: 11.7s\n",
            "706:\tlearn: 0.0510306\ttotal: 28s\tremaining: 11.6s\n",
            "707:\tlearn: 0.0509104\ttotal: 28.1s\tremaining: 11.6s\n",
            "708:\tlearn: 0.0508534\ttotal: 28.1s\tremaining: 11.5s\n",
            "709:\tlearn: 0.0507613\ttotal: 28.2s\tremaining: 11.5s\n",
            "710:\tlearn: 0.0506887\ttotal: 28.2s\tremaining: 11.5s\n",
            "711:\tlearn: 0.0505444\ttotal: 28.2s\tremaining: 11.4s\n",
            "712:\tlearn: 0.0504753\ttotal: 28.3s\tremaining: 11.4s\n",
            "713:\tlearn: 0.0504124\ttotal: 28.3s\tremaining: 11.3s\n",
            "714:\tlearn: 0.0503473\ttotal: 28.4s\tremaining: 11.3s\n",
            "715:\tlearn: 0.0502501\ttotal: 28.4s\tremaining: 11.3s\n",
            "716:\tlearn: 0.0501755\ttotal: 28.4s\tremaining: 11.2s\n",
            "717:\tlearn: 0.0501094\ttotal: 28.5s\tremaining: 11.2s\n",
            "718:\tlearn: 0.0500082\ttotal: 28.5s\tremaining: 11.1s\n",
            "719:\tlearn: 0.0498682\ttotal: 28.6s\tremaining: 11.1s\n",
            "720:\tlearn: 0.0497886\ttotal: 28.6s\tremaining: 11.1s\n",
            "721:\tlearn: 0.0497033\ttotal: 28.6s\tremaining: 11s\n",
            "722:\tlearn: 0.0496014\ttotal: 28.7s\tremaining: 11s\n",
            "723:\tlearn: 0.0495639\ttotal: 28.7s\tremaining: 10.9s\n",
            "724:\tlearn: 0.0495462\ttotal: 28.7s\tremaining: 10.9s\n",
            "725:\tlearn: 0.0494473\ttotal: 28.8s\tremaining: 10.9s\n",
            "726:\tlearn: 0.0493017\ttotal: 28.8s\tremaining: 10.8s\n",
            "727:\tlearn: 0.0492535\ttotal: 28.9s\tremaining: 10.8s\n",
            "728:\tlearn: 0.0491601\ttotal: 28.9s\tremaining: 10.7s\n",
            "729:\tlearn: 0.0490535\ttotal: 28.9s\tremaining: 10.7s\n",
            "730:\tlearn: 0.0489608\ttotal: 29s\tremaining: 10.7s\n",
            "731:\tlearn: 0.0488794\ttotal: 29s\tremaining: 10.6s\n",
            "732:\tlearn: 0.0487787\ttotal: 29.1s\tremaining: 10.6s\n",
            "733:\tlearn: 0.0487426\ttotal: 29.1s\tremaining: 10.6s\n",
            "734:\tlearn: 0.0486915\ttotal: 29.2s\tremaining: 10.5s\n",
            "735:\tlearn: 0.0486466\ttotal: 29.2s\tremaining: 10.5s\n",
            "736:\tlearn: 0.0485795\ttotal: 29.2s\tremaining: 10.4s\n",
            "737:\tlearn: 0.0484834\ttotal: 29.3s\tremaining: 10.4s\n",
            "738:\tlearn: 0.0483727\ttotal: 29.3s\tremaining: 10.4s\n",
            "739:\tlearn: 0.0482722\ttotal: 29.4s\tremaining: 10.3s\n",
            "740:\tlearn: 0.0481734\ttotal: 29.4s\tremaining: 10.3s\n",
            "741:\tlearn: 0.0481099\ttotal: 29.4s\tremaining: 10.2s\n",
            "742:\tlearn: 0.0479673\ttotal: 29.5s\tremaining: 10.2s\n",
            "743:\tlearn: 0.0478994\ttotal: 29.5s\tremaining: 10.2s\n",
            "744:\tlearn: 0.0478265\ttotal: 29.6s\tremaining: 10.1s\n",
            "745:\tlearn: 0.0477663\ttotal: 29.6s\tremaining: 10.1s\n",
            "746:\tlearn: 0.0476858\ttotal: 29.6s\tremaining: 10s\n",
            "747:\tlearn: 0.0476384\ttotal: 29.7s\tremaining: 10s\n",
            "748:\tlearn: 0.0475722\ttotal: 29.7s\tremaining: 9.96s\n",
            "749:\tlearn: 0.0474641\ttotal: 29.8s\tremaining: 9.92s\n",
            "750:\tlearn: 0.0473439\ttotal: 29.8s\tremaining: 9.88s\n",
            "751:\tlearn: 0.0472586\ttotal: 29.8s\tremaining: 9.84s\n",
            "752:\tlearn: 0.0471778\ttotal: 29.9s\tremaining: 9.8s\n",
            "753:\tlearn: 0.0470817\ttotal: 29.9s\tremaining: 9.76s\n",
            "754:\tlearn: 0.0469966\ttotal: 30s\tremaining: 9.72s\n",
            "755:\tlearn: 0.0468512\ttotal: 30s\tremaining: 9.69s\n",
            "756:\tlearn: 0.0467588\ttotal: 30.1s\tremaining: 9.65s\n",
            "757:\tlearn: 0.0466975\ttotal: 30.1s\tremaining: 9.61s\n",
            "758:\tlearn: 0.0466413\ttotal: 30.1s\tremaining: 9.57s\n",
            "759:\tlearn: 0.0464941\ttotal: 30.2s\tremaining: 9.53s\n",
            "760:\tlearn: 0.0463804\ttotal: 30.2s\tremaining: 9.49s\n",
            "761:\tlearn: 0.0462844\ttotal: 30.3s\tremaining: 9.45s\n",
            "762:\tlearn: 0.0461636\ttotal: 30.3s\tremaining: 9.41s\n",
            "763:\tlearn: 0.0460314\ttotal: 30.3s\tremaining: 9.37s\n",
            "764:\tlearn: 0.0459363\ttotal: 30.4s\tremaining: 9.33s\n",
            "765:\tlearn: 0.0458511\ttotal: 30.4s\tremaining: 9.29s\n",
            "766:\tlearn: 0.0457926\ttotal: 30.5s\tremaining: 9.25s\n",
            "767:\tlearn: 0.0456975\ttotal: 30.5s\tremaining: 9.21s\n",
            "768:\tlearn: 0.0455765\ttotal: 30.5s\tremaining: 9.17s\n",
            "769:\tlearn: 0.0454714\ttotal: 30.6s\tremaining: 9.13s\n",
            "770:\tlearn: 0.0454019\ttotal: 30.6s\tremaining: 9.09s\n",
            "771:\tlearn: 0.0453626\ttotal: 30.6s\tremaining: 9.05s\n",
            "772:\tlearn: 0.0453155\ttotal: 30.7s\tremaining: 9.01s\n",
            "773:\tlearn: 0.0452431\ttotal: 30.7s\tremaining: 8.97s\n",
            "774:\tlearn: 0.0451597\ttotal: 30.8s\tremaining: 8.93s\n",
            "775:\tlearn: 0.0451044\ttotal: 30.8s\tremaining: 8.89s\n",
            "776:\tlearn: 0.0450700\ttotal: 30.8s\tremaining: 8.85s\n",
            "777:\tlearn: 0.0449966\ttotal: 30.9s\tremaining: 8.81s\n",
            "778:\tlearn: 0.0449050\ttotal: 30.9s\tremaining: 8.78s\n",
            "779:\tlearn: 0.0448492\ttotal: 31s\tremaining: 8.74s\n",
            "780:\tlearn: 0.0448144\ttotal: 31s\tremaining: 8.69s\n",
            "781:\tlearn: 0.0447534\ttotal: 31s\tremaining: 8.65s\n",
            "782:\tlearn: 0.0446801\ttotal: 31.1s\tremaining: 8.61s\n",
            "783:\tlearn: 0.0445872\ttotal: 31.1s\tremaining: 8.57s\n",
            "784:\tlearn: 0.0445231\ttotal: 31.2s\tremaining: 8.54s\n",
            "785:\tlearn: 0.0444279\ttotal: 31.2s\tremaining: 8.5s\n",
            "786:\tlearn: 0.0443608\ttotal: 31.2s\tremaining: 8.46s\n",
            "787:\tlearn: 0.0442891\ttotal: 31.3s\tremaining: 8.42s\n",
            "788:\tlearn: 0.0441947\ttotal: 31.3s\tremaining: 8.38s\n",
            "789:\tlearn: 0.0441279\ttotal: 31.4s\tremaining: 8.34s\n",
            "790:\tlearn: 0.0440269\ttotal: 31.4s\tremaining: 8.3s\n",
            "791:\tlearn: 0.0439531\ttotal: 31.4s\tremaining: 8.26s\n",
            "792:\tlearn: 0.0438533\ttotal: 31.5s\tremaining: 8.22s\n",
            "793:\tlearn: 0.0437330\ttotal: 31.5s\tremaining: 8.18s\n",
            "794:\tlearn: 0.0436651\ttotal: 31.6s\tremaining: 8.14s\n",
            "795:\tlearn: 0.0435938\ttotal: 31.6s\tremaining: 8.1s\n",
            "796:\tlearn: 0.0435224\ttotal: 31.6s\tremaining: 8.06s\n",
            "797:\tlearn: 0.0434699\ttotal: 31.7s\tremaining: 8.02s\n",
            "798:\tlearn: 0.0433899\ttotal: 31.7s\tremaining: 7.98s\n",
            "799:\tlearn: 0.0433388\ttotal: 31.8s\tremaining: 7.94s\n",
            "800:\tlearn: 0.0432700\ttotal: 31.8s\tremaining: 7.9s\n",
            "801:\tlearn: 0.0431959\ttotal: 31.8s\tremaining: 7.86s\n",
            "802:\tlearn: 0.0431411\ttotal: 31.9s\tremaining: 7.82s\n",
            "803:\tlearn: 0.0430841\ttotal: 31.9s\tremaining: 7.78s\n",
            "804:\tlearn: 0.0429663\ttotal: 32s\tremaining: 7.74s\n",
            "805:\tlearn: 0.0429058\ttotal: 32s\tremaining: 7.7s\n",
            "806:\tlearn: 0.0428218\ttotal: 32s\tremaining: 7.66s\n",
            "807:\tlearn: 0.0427497\ttotal: 32.1s\tremaining: 7.62s\n",
            "808:\tlearn: 0.0426969\ttotal: 32.1s\tremaining: 7.58s\n",
            "809:\tlearn: 0.0426353\ttotal: 32.2s\tremaining: 7.54s\n",
            "810:\tlearn: 0.0425674\ttotal: 32.2s\tremaining: 7.5s\n",
            "811:\tlearn: 0.0424896\ttotal: 32.2s\tremaining: 7.46s\n",
            "812:\tlearn: 0.0424505\ttotal: 32.3s\tremaining: 7.42s\n",
            "813:\tlearn: 0.0423878\ttotal: 32.3s\tremaining: 7.38s\n",
            "814:\tlearn: 0.0423166\ttotal: 32.4s\tremaining: 7.34s\n",
            "815:\tlearn: 0.0422334\ttotal: 32.4s\tremaining: 7.3s\n",
            "816:\tlearn: 0.0421624\ttotal: 32.4s\tremaining: 7.26s\n",
            "817:\tlearn: 0.0420967\ttotal: 32.5s\tremaining: 7.22s\n",
            "818:\tlearn: 0.0420191\ttotal: 32.5s\tremaining: 7.19s\n",
            "819:\tlearn: 0.0419456\ttotal: 32.6s\tremaining: 7.15s\n",
            "820:\tlearn: 0.0418865\ttotal: 32.6s\tremaining: 7.11s\n",
            "821:\tlearn: 0.0418253\ttotal: 32.6s\tremaining: 7.07s\n",
            "822:\tlearn: 0.0417556\ttotal: 32.7s\tremaining: 7.03s\n",
            "823:\tlearn: 0.0416837\ttotal: 32.7s\tremaining: 6.99s\n",
            "824:\tlearn: 0.0415902\ttotal: 32.8s\tremaining: 6.95s\n",
            "825:\tlearn: 0.0415067\ttotal: 32.8s\tremaining: 6.91s\n",
            "826:\tlearn: 0.0413674\ttotal: 32.8s\tremaining: 6.87s\n",
            "827:\tlearn: 0.0412689\ttotal: 32.9s\tremaining: 6.83s\n",
            "828:\tlearn: 0.0411775\ttotal: 32.9s\tremaining: 6.79s\n",
            "829:\tlearn: 0.0411102\ttotal: 32.9s\tremaining: 6.75s\n",
            "830:\tlearn: 0.0410629\ttotal: 33s\tremaining: 6.71s\n",
            "831:\tlearn: 0.0410090\ttotal: 33s\tremaining: 6.67s\n",
            "832:\tlearn: 0.0409648\ttotal: 33.1s\tremaining: 6.63s\n",
            "833:\tlearn: 0.0409106\ttotal: 33.1s\tremaining: 6.59s\n",
            "834:\tlearn: 0.0408226\ttotal: 33.2s\tremaining: 6.55s\n",
            "835:\tlearn: 0.0407472\ttotal: 33.2s\tremaining: 6.51s\n",
            "836:\tlearn: 0.0406499\ttotal: 33.2s\tremaining: 6.47s\n",
            "837:\tlearn: 0.0406070\ttotal: 33.3s\tremaining: 6.43s\n",
            "838:\tlearn: 0.0405343\ttotal: 33.3s\tremaining: 6.39s\n",
            "839:\tlearn: 0.0404560\ttotal: 33.3s\tremaining: 6.35s\n",
            "840:\tlearn: 0.0403913\ttotal: 33.4s\tremaining: 6.31s\n",
            "841:\tlearn: 0.0403484\ttotal: 33.4s\tremaining: 6.27s\n",
            "842:\tlearn: 0.0403013\ttotal: 33.5s\tremaining: 6.23s\n",
            "843:\tlearn: 0.0402453\ttotal: 33.5s\tremaining: 6.19s\n",
            "844:\tlearn: 0.0401937\ttotal: 33.5s\tremaining: 6.15s\n",
            "845:\tlearn: 0.0401392\ttotal: 33.6s\tremaining: 6.11s\n",
            "846:\tlearn: 0.0401067\ttotal: 33.6s\tremaining: 6.07s\n",
            "847:\tlearn: 0.0400650\ttotal: 33.7s\tremaining: 6.03s\n",
            "848:\tlearn: 0.0399804\ttotal: 33.7s\tremaining: 5.99s\n",
            "849:\tlearn: 0.0399209\ttotal: 33.7s\tremaining: 5.95s\n",
            "850:\tlearn: 0.0398335\ttotal: 33.8s\tremaining: 5.91s\n",
            "851:\tlearn: 0.0397650\ttotal: 33.8s\tremaining: 5.87s\n",
            "852:\tlearn: 0.0396932\ttotal: 33.9s\tremaining: 5.83s\n",
            "853:\tlearn: 0.0396278\ttotal: 33.9s\tremaining: 5.79s\n",
            "854:\tlearn: 0.0395597\ttotal: 33.9s\tremaining: 5.76s\n",
            "855:\tlearn: 0.0394923\ttotal: 34s\tremaining: 5.72s\n",
            "856:\tlearn: 0.0394295\ttotal: 34s\tremaining: 5.68s\n",
            "857:\tlearn: 0.0393612\ttotal: 34.1s\tremaining: 5.64s\n",
            "858:\tlearn: 0.0393315\ttotal: 34.1s\tremaining: 5.6s\n",
            "859:\tlearn: 0.0392376\ttotal: 34.2s\tremaining: 5.56s\n",
            "860:\tlearn: 0.0391841\ttotal: 34.2s\tremaining: 5.52s\n",
            "861:\tlearn: 0.0391392\ttotal: 34.2s\tremaining: 5.48s\n",
            "862:\tlearn: 0.0390109\ttotal: 34.3s\tremaining: 5.44s\n",
            "863:\tlearn: 0.0389351\ttotal: 34.3s\tremaining: 5.4s\n",
            "864:\tlearn: 0.0389012\ttotal: 34.4s\tremaining: 5.36s\n",
            "865:\tlearn: 0.0388431\ttotal: 34.4s\tremaining: 5.32s\n",
            "866:\tlearn: 0.0387857\ttotal: 34.4s\tremaining: 5.28s\n",
            "867:\tlearn: 0.0387206\ttotal: 34.5s\tremaining: 5.24s\n",
            "868:\tlearn: 0.0386500\ttotal: 34.5s\tremaining: 5.2s\n",
            "869:\tlearn: 0.0386246\ttotal: 34.5s\tremaining: 5.16s\n",
            "870:\tlearn: 0.0385654\ttotal: 34.6s\tremaining: 5.12s\n",
            "871:\tlearn: 0.0384984\ttotal: 34.6s\tremaining: 5.08s\n",
            "872:\tlearn: 0.0384375\ttotal: 34.7s\tremaining: 5.04s\n",
            "873:\tlearn: 0.0383443\ttotal: 34.7s\tremaining: 5s\n",
            "874:\tlearn: 0.0382855\ttotal: 34.7s\tremaining: 4.96s\n",
            "875:\tlearn: 0.0382064\ttotal: 34.8s\tremaining: 4.92s\n",
            "876:\tlearn: 0.0381354\ttotal: 34.8s\tremaining: 4.88s\n",
            "877:\tlearn: 0.0380293\ttotal: 34.9s\tremaining: 4.84s\n",
            "878:\tlearn: 0.0379637\ttotal: 34.9s\tremaining: 4.8s\n",
            "879:\tlearn: 0.0378702\ttotal: 34.9s\tremaining: 4.76s\n",
            "880:\tlearn: 0.0377955\ttotal: 35s\tremaining: 4.72s\n",
            "881:\tlearn: 0.0377541\ttotal: 35s\tremaining: 4.69s\n",
            "882:\tlearn: 0.0376979\ttotal: 35.1s\tremaining: 4.65s\n",
            "883:\tlearn: 0.0376567\ttotal: 35.1s\tremaining: 4.61s\n",
            "884:\tlearn: 0.0376053\ttotal: 35.1s\tremaining: 4.57s\n",
            "885:\tlearn: 0.0375702\ttotal: 35.2s\tremaining: 4.53s\n",
            "886:\tlearn: 0.0375277\ttotal: 35.2s\tremaining: 4.49s\n",
            "887:\tlearn: 0.0374903\ttotal: 35.3s\tremaining: 4.45s\n",
            "888:\tlearn: 0.0374394\ttotal: 35.3s\tremaining: 4.41s\n",
            "889:\tlearn: 0.0374041\ttotal: 35.3s\tremaining: 4.37s\n",
            "890:\tlearn: 0.0373286\ttotal: 35.4s\tremaining: 4.33s\n",
            "891:\tlearn: 0.0372367\ttotal: 35.4s\tremaining: 4.29s\n",
            "892:\tlearn: 0.0371784\ttotal: 35.5s\tremaining: 4.25s\n",
            "893:\tlearn: 0.0371052\ttotal: 35.5s\tremaining: 4.21s\n",
            "894:\tlearn: 0.0370508\ttotal: 35.5s\tremaining: 4.17s\n",
            "895:\tlearn: 0.0369961\ttotal: 35.6s\tremaining: 4.13s\n",
            "896:\tlearn: 0.0369586\ttotal: 35.6s\tremaining: 4.09s\n",
            "897:\tlearn: 0.0369245\ttotal: 35.7s\tremaining: 4.05s\n",
            "898:\tlearn: 0.0368564\ttotal: 35.7s\tremaining: 4.01s\n",
            "899:\tlearn: 0.0367726\ttotal: 35.7s\tremaining: 3.97s\n",
            "900:\tlearn: 0.0366946\ttotal: 35.8s\tremaining: 3.93s\n",
            "901:\tlearn: 0.0366353\ttotal: 35.8s\tremaining: 3.89s\n",
            "902:\tlearn: 0.0365490\ttotal: 35.9s\tremaining: 3.85s\n",
            "903:\tlearn: 0.0364831\ttotal: 35.9s\tremaining: 3.81s\n",
            "904:\tlearn: 0.0364454\ttotal: 35.9s\tremaining: 3.77s\n",
            "905:\tlearn: 0.0364296\ttotal: 36s\tremaining: 3.73s\n",
            "906:\tlearn: 0.0363626\ttotal: 36s\tremaining: 3.69s\n",
            "907:\tlearn: 0.0363447\ttotal: 36.1s\tremaining: 3.65s\n",
            "908:\tlearn: 0.0362965\ttotal: 36.1s\tremaining: 3.62s\n",
            "909:\tlearn: 0.0362363\ttotal: 36.2s\tremaining: 3.58s\n",
            "910:\tlearn: 0.0361940\ttotal: 36.2s\tremaining: 3.54s\n",
            "911:\tlearn: 0.0361290\ttotal: 36.2s\tremaining: 3.5s\n",
            "912:\tlearn: 0.0360632\ttotal: 36.3s\tremaining: 3.46s\n",
            "913:\tlearn: 0.0360009\ttotal: 36.3s\tremaining: 3.42s\n",
            "914:\tlearn: 0.0359557\ttotal: 36.4s\tremaining: 3.38s\n",
            "915:\tlearn: 0.0359109\ttotal: 36.4s\tremaining: 3.34s\n",
            "916:\tlearn: 0.0358667\ttotal: 36.4s\tremaining: 3.3s\n",
            "917:\tlearn: 0.0358205\ttotal: 36.5s\tremaining: 3.26s\n",
            "918:\tlearn: 0.0357589\ttotal: 36.5s\tremaining: 3.22s\n",
            "919:\tlearn: 0.0357134\ttotal: 36.6s\tremaining: 3.18s\n",
            "920:\tlearn: 0.0356537\ttotal: 36.6s\tremaining: 3.14s\n",
            "921:\tlearn: 0.0356134\ttotal: 36.6s\tremaining: 3.1s\n",
            "922:\tlearn: 0.0354987\ttotal: 36.7s\tremaining: 3.06s\n",
            "923:\tlearn: 0.0354562\ttotal: 36.7s\tremaining: 3.02s\n",
            "924:\tlearn: 0.0354256\ttotal: 36.7s\tremaining: 2.98s\n",
            "925:\tlearn: 0.0353812\ttotal: 36.8s\tremaining: 2.94s\n",
            "926:\tlearn: 0.0353384\ttotal: 36.8s\tremaining: 2.9s\n",
            "927:\tlearn: 0.0352643\ttotal: 36.9s\tremaining: 2.86s\n",
            "928:\tlearn: 0.0352234\ttotal: 36.9s\tremaining: 2.82s\n",
            "929:\tlearn: 0.0351622\ttotal: 36.9s\tremaining: 2.78s\n",
            "930:\tlearn: 0.0351201\ttotal: 37s\tremaining: 2.74s\n",
            "931:\tlearn: 0.0350986\ttotal: 37s\tremaining: 2.7s\n",
            "932:\tlearn: 0.0350590\ttotal: 37.1s\tremaining: 2.66s\n",
            "933:\tlearn: 0.0350072\ttotal: 37.1s\tremaining: 2.62s\n",
            "934:\tlearn: 0.0349677\ttotal: 37.1s\tremaining: 2.58s\n",
            "935:\tlearn: 0.0349097\ttotal: 37.2s\tremaining: 2.54s\n",
            "936:\tlearn: 0.0348469\ttotal: 37.2s\tremaining: 2.5s\n",
            "937:\tlearn: 0.0348222\ttotal: 37.3s\tremaining: 2.46s\n",
            "938:\tlearn: 0.0347732\ttotal: 37.3s\tremaining: 2.42s\n",
            "939:\tlearn: 0.0347446\ttotal: 37.3s\tremaining: 2.38s\n",
            "940:\tlearn: 0.0347038\ttotal: 37.4s\tremaining: 2.34s\n",
            "941:\tlearn: 0.0346463\ttotal: 37.4s\tremaining: 2.3s\n",
            "942:\tlearn: 0.0345774\ttotal: 37.4s\tremaining: 2.26s\n",
            "943:\tlearn: 0.0345171\ttotal: 37.5s\tremaining: 2.22s\n",
            "944:\tlearn: 0.0344578\ttotal: 37.5s\tremaining: 2.18s\n",
            "945:\tlearn: 0.0344002\ttotal: 37.6s\tremaining: 2.14s\n",
            "946:\tlearn: 0.0343563\ttotal: 37.6s\tremaining: 2.1s\n",
            "947:\tlearn: 0.0342845\ttotal: 37.6s\tremaining: 2.06s\n",
            "948:\tlearn: 0.0342261\ttotal: 37.7s\tremaining: 2.02s\n",
            "949:\tlearn: 0.0341780\ttotal: 37.7s\tremaining: 1.99s\n",
            "950:\tlearn: 0.0341344\ttotal: 37.8s\tremaining: 1.95s\n",
            "951:\tlearn: 0.0340828\ttotal: 37.8s\tremaining: 1.91s\n",
            "952:\tlearn: 0.0340144\ttotal: 37.8s\tremaining: 1.87s\n",
            "953:\tlearn: 0.0339463\ttotal: 37.9s\tremaining: 1.83s\n",
            "954:\tlearn: 0.0338899\ttotal: 37.9s\tremaining: 1.79s\n",
            "955:\tlearn: 0.0338308\ttotal: 38s\tremaining: 1.75s\n",
            "956:\tlearn: 0.0337781\ttotal: 38s\tremaining: 1.71s\n",
            "957:\tlearn: 0.0337089\ttotal: 38s\tremaining: 1.67s\n",
            "958:\tlearn: 0.0336718\ttotal: 38.1s\tremaining: 1.63s\n",
            "959:\tlearn: 0.0336290\ttotal: 38.1s\tremaining: 1.59s\n",
            "960:\tlearn: 0.0335788\ttotal: 38.2s\tremaining: 1.55s\n",
            "961:\tlearn: 0.0335300\ttotal: 38.2s\tremaining: 1.51s\n",
            "962:\tlearn: 0.0335031\ttotal: 38.2s\tremaining: 1.47s\n",
            "963:\tlearn: 0.0334354\ttotal: 38.3s\tremaining: 1.43s\n",
            "964:\tlearn: 0.0333981\ttotal: 38.3s\tremaining: 1.39s\n",
            "965:\tlearn: 0.0332969\ttotal: 38.4s\tremaining: 1.35s\n",
            "966:\tlearn: 0.0332318\ttotal: 38.4s\tremaining: 1.31s\n",
            "967:\tlearn: 0.0331972\ttotal: 38.4s\tremaining: 1.27s\n",
            "968:\tlearn: 0.0331321\ttotal: 38.5s\tremaining: 1.23s\n",
            "969:\tlearn: 0.0330672\ttotal: 38.5s\tremaining: 1.19s\n",
            "970:\tlearn: 0.0330096\ttotal: 38.6s\tremaining: 1.15s\n",
            "971:\tlearn: 0.0329796\ttotal: 38.6s\tremaining: 1.11s\n",
            "972:\tlearn: 0.0329285\ttotal: 38.6s\tremaining: 1.07s\n",
            "973:\tlearn: 0.0328630\ttotal: 38.7s\tremaining: 1.03s\n",
            "974:\tlearn: 0.0328362\ttotal: 38.7s\tremaining: 993ms\n",
            "975:\tlearn: 0.0328072\ttotal: 38.8s\tremaining: 953ms\n",
            "976:\tlearn: 0.0327549\ttotal: 38.8s\tremaining: 913ms\n",
            "977:\tlearn: 0.0327097\ttotal: 38.8s\tremaining: 873ms\n",
            "978:\tlearn: 0.0326746\ttotal: 38.9s\tremaining: 834ms\n",
            "979:\tlearn: 0.0326226\ttotal: 38.9s\tremaining: 794ms\n",
            "980:\tlearn: 0.0325612\ttotal: 39s\tremaining: 754ms\n",
            "981:\tlearn: 0.0325306\ttotal: 39s\tremaining: 715ms\n",
            "982:\tlearn: 0.0324795\ttotal: 39s\tremaining: 675ms\n",
            "983:\tlearn: 0.0324069\ttotal: 39.1s\tremaining: 636ms\n",
            "984:\tlearn: 0.0323557\ttotal: 39.1s\tremaining: 596ms\n",
            "985:\tlearn: 0.0323031\ttotal: 39.2s\tremaining: 556ms\n",
            "986:\tlearn: 0.0322677\ttotal: 39.2s\tremaining: 516ms\n",
            "987:\tlearn: 0.0322365\ttotal: 39.2s\tremaining: 477ms\n",
            "988:\tlearn: 0.0321774\ttotal: 39.3s\tremaining: 437ms\n",
            "989:\tlearn: 0.0321174\ttotal: 39.3s\tremaining: 397ms\n",
            "990:\tlearn: 0.0320693\ttotal: 39.4s\tremaining: 358ms\n",
            "991:\tlearn: 0.0319907\ttotal: 39.4s\tremaining: 318ms\n",
            "992:\tlearn: 0.0319515\ttotal: 39.5s\tremaining: 278ms\n",
            "993:\tlearn: 0.0319109\ttotal: 39.5s\tremaining: 238ms\n",
            "994:\tlearn: 0.0318848\ttotal: 39.5s\tremaining: 199ms\n",
            "995:\tlearn: 0.0318516\ttotal: 39.6s\tremaining: 159ms\n",
            "996:\tlearn: 0.0317917\ttotal: 39.6s\tremaining: 119ms\n",
            "997:\tlearn: 0.0317626\ttotal: 39.6s\tremaining: 79.4ms\n",
            "998:\tlearn: 0.0317303\ttotal: 39.7s\tremaining: 39.7ms\n",
            "999:\tlearn: 0.0316647\ttotal: 39.7s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f36684ffa10>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ac_catboost = accuracy_score(y_test, y_pred)\n",
        "mylist.append(ac_catboost)\n",
        "print(cm)\n",
        "print(ac_catboost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQnqm4lq5Sbg",
        "outputId": "612c0744-13ab-44be-da6a-0e3cae37fed6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[125   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   1   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  4   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8445945945945946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['KNN', 'Logistic Regression', \n",
        "              'Random Forest', 'ANN', 'DNN',  \n",
        "              'Decision Tree','xgboost','catboost'],\n",
        "    'Score': [acc_knn, acc_logreg, \n",
        "              acc_randomforest, ac_ann, ac_dnn, acc_decisiontree,ac_xgboost,ac_catboost\n",
        "              ]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "27YU93DQ58w-",
        "outputId": "86fe1dde-350c-40c0-d113-b78ec1d948e4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Model     Score\n",
              "1  Logistic Regression  0.864865\n",
              "2        Random Forest  0.864865\n",
              "5        Decision Tree  0.864865\n",
              "0                  KNN  0.844595\n",
              "6              xgboost  0.844595\n",
              "7             catboost  0.844595\n",
              "3                  ANN  0.000000\n",
              "4                  DNN  0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d2248f4d-b133-4048-a9cb-57c58318e915\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.864865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.864865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.864865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.844595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>xgboost</td>\n",
              "      <td>0.844595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>catboost</td>\n",
              "      <td>0.844595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ANN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DNN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d2248f4d-b133-4048-a9cb-57c58318e915')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d2248f4d-b133-4048-a9cb-57c58318e915 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d2248f4d-b133-4048-a9cb-57c58318e915');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns \n",
        "plt.rcParams['figure.figsize']=15,6 \n",
        "sns.set_style(\"darkgrid\")\n",
        "ax = sns.barplot(x=models.Model, y=models.Score, palette = \"rocket\", saturation =1.5)\n",
        "plt.xlabel(\"Classifier Models\", fontsize = 20 )\n",
        "plt.ylabel(\"% of Accuracy\", fontsize = 20)\n",
        "plt.title(\"Accuracy of different Classifier Models\", fontsize = 20)\n",
        "plt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\n",
        "plt.yticks(fontsize = 13)\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy() \n",
        "    ax.annotate(f'{height:.2%}', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "d8onA3pt6Rbj",
        "outputId": "4b6b31d9-b0ab-4f2f-ea2f-d51755f28393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4YAAAGkCAYAAABtiDsZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXxM9/7H8XcWW0QQQomlqiZKbFE7tQupfUlbtdRSW1GtEtpeWtWLamlp7bSWWkJtFVqNPUrE0jbW1lJLiCCIiEgk8/vDL3NFFhNmkjCv5+PRRzvnfM85nznfM9O853zPOXZGo9EoAAAAAIDNss/qAgAAAAAAWYtgCAAAAAA2jmAIAAAAADaOYAgAAAAANo5gCAAAAAA2jmAIAAAAADaOYAgAMFtQUJBef/11vfzyy/Lw8NCgQYMee10XLlyQh4eHRo0alWz6qFGj5OHhoQsXLqRYZtGiRfLx8VHlypXl4eGhH374wTRvw4YNat++vapVqyYPDw99/vnnj12brQkODpaHh4emT5+e1aWk8DjHg4eHh7p3757JlWZv06dPl4eHh4KDg59oPen1B4Cnm2NWFwDAts2cOVNff/21JGnTpk164YUXsrgipOXChQsaNGiQXFxc1KlTJzk7O2dqfwUEBOjzzz9XhQoV1LNnT+XMmVNVq1aVJB06dEgffPCBSpYsqTfeeEN58uRRlSpVMq02S5s+fbq+/fZbLVq0SLVq1Xqsdfz1119avny5Dhw4oIiICMXHx8vNzU2VKlVSy5Yt5e3tLQcHBwtXnnnSOx6yWnBwsHr06CFJcnd315YtW2RnZ5ei3e3bt9WgQQPdvn1bkrRlyxaVKFEiU2sFgCQEQwBZxmg0auXKlbKzszP9t5+fX1aXhTTs2bNHd+/elZ+fn9q0aWO17bz//vt6++23VbRo0WTTt23bJkmaNWtWinnbt2+X0WjUpEmT5OXlZbXangbx8fEaP368li9fLgcHB9WoUUONGjVSzpw5FR4err179+rXX3+Vt7e3pk2bltXlPtLjHA8bN25Unjx5Mq3GtDg6OiosLEy7d+9W/fr1U8zfuHGjbt++LUdHR927dy8LKgSA/yEYAsgyQUFBCgsLU8eOHbVr1y6tWbNG7733nnLmzJnVpSEVly9fliQVKVLEqtspUqRIqtuIiIiQpBQh4MF51q7taTBu3Dj5+/vLYDDom2++SXFWNyEhQT///LO2bt2aRRVmzOMcD2XLlrV6XeaoU6eOgoOD5e/vn2ow9Pf3l5ubm4oXL64///wzCyoEgP8hGALIMitXrpQkdenSRQUKFNCCBQsUGBgoHx+fVNuHh4dr3rx52rlzp8LDw5U7d26VKlVKjRs31jvvvPNYbT08PFSzZk0tXrw4xfZGjRqlNWvWJBvedeHCBTVt2lQdOnRQ//799c033yg4OFjXr1/XwoULVatWLR0+fFhr167Vvn37FB4erjt37qhYsWJq0qSJBg4cqPz586f6/jZu3KgVK1bo2LFjunPnjtzc3FS1alX16tVLlSpV0vLlyzV27FgNGTJEgwcPTrH8lStX1KhRI73wwgv6+eefzeqDjRs36scff9Tx48cVHx+v0qVLq3Xr1urVq5cpoD84LE5Ssv82Z6hjdHS0pk+frk2bNun69etyd3fXa6+9pmbNmqXa/uH9njSsMomHh4fpvydMmKDRo0ebXjdt2tT03w/2W3h4uObMmaMdO3bo8uXLyps3r6pVq6ZBgwapcuXKybb/4DDOiIgILVq0SCdPnlTBggVNYerOnTtatGiRNm7cqLNnz8rOzk4Gg0Hdu3dX69atk60vaf8NHjxYzZo109SpU3Xw4EHFx8erUqVKev/995Od5WzSpInCwsJS7GtJOnHiRLr7+sCBA/L391eBAgU0f/78VAOVg4OD2rdvn+bn7EEZPZbj4uK0fPlyrVmzRhcuXFBcXJwKFSpkuuavbt26prb79+/XvHnzdPToUUVGRip//vxyd3fXK6+8kuz4zsjxkLR/0vpc37t3TytWrNC6det08uRJJSQkqEyZMurcubO6du0qe/v/3XrBnM/6oxQoUEAtWrTQr7/+qsjISLm6uprmHT9+XH/99ZcGDBigffv2pbmOPXv2aN68eQoNDVVMTIzc3d3VvHlz9e/fX/ny5UvR/vDhw6ZjzM7OTpUrV9a7776bbp2nTp3S3LlztWfPHl27dk0uLi6qU6eO3nnnHbOHi2/ZskWLFi3SqVOndOPGDRUoUEDPP/+8WrVqpTfffNOsdQDIWgRDAFni6tWr2rp1q55//nl5eXnJ2dlZCxYs0IoVK1L9gzU0NFR9+/bVjRs3VKNGDTVv3lyxsbE6efKkvv3222RhLyNtH9e5c+fk6+ur559/Xm3atFFsbKycnZ0l3T8LEBgYqBo1aqhu3bpKTEzUkSNH9P3332vnzp3y9/c3tZXuD6kdPXq01qxZo4IFC6p58+ZydXVVeHi4goODVaZMGVWqVElt2rTR5MmTtWrVKg0cODDF9WE//fST7t27p9dee82s9zBlyhTNnj1bBQsWVOvWreXk5KRdu3ZpypQpCgoK0vz585UzZ065u7tr8ODB2rdvn/bt26cOHTrI3d1dkkz/TktcXJzeeusthYaGqnz58mrTpo1u3bqlGTNmpPvH8INq1qypwYMHa82aNQoLC0sWGl566SUNHjxYgYGBOn78uHr06CEXFxdJMv37yJEj6t27t27evKn69eurRYsWun79ugIDA9W1a1d99913atiwYYrtfv/999q9e7caN26sWrVq6datW5KkqKgo9ezZU0ePHlXFihXVqVMnJSYmKigoSMOHD9c///yj9957L8X6Dh8+rHnz5qlq1arq0qWLLl68qM2bN+utt97S2rVrTX+A9+jRQ1u2bEmxr83h7+8vSfL19X3k2VNzzsxn9FgePXq0NmzYIIPBoHbt2il37tyKiIjQgQMHtGvXLlMw3Llzp/r37y9nZ2c1adJERYsW1Y0bN3T69GktXbo01R8+kqR3PKQnPj5eAwYMUFBQkMqUKaPWrVsrV65cCg4O1meffaY///xTkydPTrFcep91c3Tp0kUbNmzQmjVr1KdPH9P0pGH0nTt3TvOzsHz5cn3yySfKkyePWrZsqUKFCmnfvn2aO3eutm3bpmXLlpmOc0k6ePCgevXqpfj4eDVv3lylS5fWsWPH1L17d9WuXTvVbezcuVNDhgzRvXv31LhxY5UqVUqXL1/W5s2btX37di1atEgVK1ZM9z2uWLFCY8aMkZubmxo3bqyCBQvq2rVrOnHihFavXk0wBJ4WRgDIArNnzzYaDAbjrFmzTNM6dOhg9PDwMP7777/J2t69e9fYuHFjo8FgMK5fvz7Fui5duvRYbY1Go9FgMBi7deuWao1+fn5Gg8FgPH/+vGna+fPnjQaDwWgwGIxfffVVqstduHDBeO/evRTT/f39jQaDwTh79uxk05cvX240GAzGTp06GaOiopLNu3fvnvHy5cum159++qnRYDAYt27dmqxdYmKisUmTJsYqVaqkWEdqDh48aDQYDMaGDRsaIyIiTNPj4+ON/fv3NxoMBuPMmTOTLTNt2jSjwWAw7t2795HrTzJz5kyjwWAwDh482JiQkGCafu7cOWONGjWMBoPB6Ofnl2yZ1Pa70Wg0duvWzWgwGFLdTlrLxMfHG5s1a2b09PQ0BgcHJ5sXHh5urF+/vrFevXrGu3fvpnifVapUMR45ciTNbc2ZMyfZ9NjYWGPv3r2NHh4exqNHj5qm792713TM/PTTT8mWWbZsmdFgMBjHjh2bbPrj7Guj0Whs2rSp0WAwGHfv3p2h5ZJqnDZtWrLpGTmWo6KijB4eHsYOHTqkukxkZKTpvwcPHmw0GAzGY8eOpWh37dq1ZK8f53hI7XOdtE/HjRuXrL579+4ZR48ebTQYDMbffvvNNN2cz3pakvbn8OHDjYmJicbmzZsbvb29TfPv3LljfPnll41vvfWW0Wg0Gl9//fUU7/HChQvGihUrGqtVq2Y8efJksvWPHTvWaDAYjB9//LFpWmJiotHb2zvF+zAajcYffvjB9F4ePKZu3LhhfPnll401a9Y0/vPPP8mWOXHihLFq1arG9u3bJ5ueWn906NDBWLFiRePVq1dT7IuH+xNA9sXjKgBkOuP/32jG3t5e7du3N03v2LGjjEaj6axHkm3btiksLExNmjRJ9aYnzz333GO1fRKFCxdO80yFu7t7qnd77Ny5s5ydnRUUFJRs+pIlSyTdvzbs4aFhDg4Oyc78vPHGG5Lu/0L/oKCgIF24cEGtWrVKdXjZw3766SdJ0sCBA+Xm5maa7ujoKD8/P9nb25uG+j6J1atXy97eXiNGjEg2TK9kyZKZ8jiB7du369y5c+rWrZtq1qyZbF7RokXVt29fXblyRXv27EmxrK+vrypUqJBs2vXr17V+/Xp5enrq7bffTjYvV65cGjFihIxGY6pDeb28vNSxY8dk0zp16iRHR0f99ddfj/sWk7ly5Yqk1K+7exwZOZaTbiKVM2fOZH2dpGDBgimm5cqVK8W0B4dbWkpiYqKWLFkiNzc3jR49Otl7cnBw0KhRo2RnZ5dqv6X3WTdH0lnBM2fOKCQkRJL0yy+/KCoqSl26dElzufXr1ys+Pl7dunVLcc3ke++9p7x582rdunWKi4uTdP9s4ZkzZ1SjRo0Uw7S7deumUqVKpdjG2rVrFRUVpaFDh+rFF19MNs9gMKhLly46evSoTp48+cj36ejoKEfHlAPRrNGfAKyDoaQAMt3evXt17tw51a9fP9kfsK1bt9bEiRO1Zs0aDRs2TDly5JAk/fHHH5KkV1555ZHrzkjbJ1G+fPk0h+LFx8drxYoVCggI0KlTp3Tr1i0lJiaa5ifdxEWSYmJi9Pfff6tw4cIpQkhqypUrpxo1amjnzp26dOmSihUrJul/QwiTguOjHD16VJJSHV5WpkwZPffcc7pw4YJu3bplVtBMTXR0tM6ePatixYql+kfpw0HNGpKOh4sXL6b6jL5///1X0v1rrB4eTvrwtYfS/WHKCQkJsrOzS3V9SXeWPH36dIp5np6eKablyJFDhQoVUlRU1KPfTBbIyLHs7Oysxo0ba9u2bWrXrp1atGihl19+WVWqVElxh9A2bdpo8+bN8vX1VatWrVS7dm15eXlZ7Iebh505c0Y3btzQ888/r5kzZ6baJnfu3Kn2W3qfdXN17NhR06ZNk7+/v2rUqCF/f38VLFgwzetspfQ/o/nz51eFChUUEhKi06dPq3z58qb2NWrUSNHewcFB1atX17lz55JNT/p8HD9+/JGfj4eD44PatGmjiRMn6tVXX5WPj49q1qwpLy8vQiHwlCEYAsh0SWe7Hj57UqBAATVp0kS//vqrtmzZopYtW0qS6douc86CZKTtkyhcuHCa89577z399ttvKlmypJo2barChQub/rBcuHCh4uPjn6jerl27KiQkRCtXrtTQoUN15coVbd26VS+99FKqYSY1Sdt98Gzhg9zc3HTx4kVFRUU9UTCUpEKFCqU6P719aCk3btyQdP8MTXpiYmJSTEutvqT1hYaGKjQ0NM31JT2X7kEPXgv2IEdHx2Rh60m4ubnp/PnzioiIsMidOTNyLEvS119/rblz52rDhg2moJErVy55e3vLz8/PtE9btGih2bNna8GCBVq9erXpO6FixYoaPny46tWr98S1Pyip3/79999kN655WGr9ZonjtHDhwmrcuLE2b96srl276sCBA+rdu3e6gdOcz6gk048KSe3Tqje94/nhURoPS+3z8aBevXqpYMGCWrp0qRYvXqyFCxfKzs5ONWrU0MiRI1WpUqV0lweQPRAMAWSqyMhIBQYGSrr/fLL3338/1Xb+/v6mYJgUTB48O5GWjLSV7g/zSuv5YemdxUntYdXS/cDw22+/qW7dupo7d26yoVWJiYmaN2/eE9UrSc2bN1fhwoW1atUqvfPOOxm+6cyD27169WqqZ/OShiQ+biiUZLpBx7Vr11Kdf/Xq1cdet7mS6p8xY0ayO5aaI7U+TlrfW2+9lexuqNlF9erVdf78ee3Zs0d16tR5onVl9FiW7p91GzJkiIYMGaJLly4pJCREa9as0fr16xUWFqalS5ea2jZq1EiNGjVSTEyM/vzzT23fvl3Lli1T//79tXbt2nTPUGVUUr81b9483WCYmrQ+6xnl6+urzZs3a9iwYZKU7jBSKflntFy5cinmP/wZfbB9alKbnrTMunXrVL58eXPeRprat2+v9u3bKyoqSocOHdJvv/2mn376SX379tWmTZs4ewg8BbjGEECmWrNmjeLj41WxYkV17tw51X9cXV31+++/6/z585KkqlWrSrp/97xHyUhb6f6QrPDw8BTTExISdPz4cXPflknSUK0mTZqkuN7mr7/+UmxsbLJpTk5OMhgMunr1qmko2KPkyJFDnTt31uXLl7Vt2zatXLlSTk5OGXro/EsvvSTp/qMUHnb27FmFh4erRIkSaZ7lMoezs7NKly6ty5cvpxjCJsnsu5I+iSpVqki6/2gES6hcubLs7e0ttr60JF2jl9Ezib6+vpLun5V/VPBOujYtLRk9lh9WrFgxtW3bVvPnz1fp0qV14MABXb9+PUU7Jycn1alTR6NHj1b//v0VHx9v9ufXXC+88IJcXFz0xx9/pDjLmVnq1asnd3d3hYeHq0aNGo98DER6n9GoqCgdO3ZMuXLlMp0ZThqKnnQd44MSEhJ04MCBFNOTPh+pzXtcLi4uatiwocaPH68OHTroxo0bqdYEIPshGALIVElDlj755BN9/vnnqf7z2muvyWg0atWqVZKkxo0by93dXVu3btWGDRtSrPPBYJeRtpJUqVIlXbx4McUNYWbOnGl6llxGJD1a4OHQc+3aNY0bNy7VZZJuwjJmzBjTcLAkiYmJpgd5P+i1116Tg4ODxo0bpwsXLqhNmzYZuoV+p06dJN1/n5GRkabpCQkJmjRpkhITE9W5c2ez15eWjh07KjExUV9++WWykHP+/PlUnx1paU2bNlWpUqW0dOlS7dixI9U2hw4d0p07d8xaX6FChdSmTRsdPnxY3333nRISElK0OXfunOlHjcdVoEABSfevjcyI6tWry9fXVzdu3FDfvn1N14g9KDExURs2bNCIESPSXVdGj+XIyMhUn7MYExOjmJgYOTo6mq4bDgkJSfVMfdLZ5dy5c6dbW0Y5OjqqW7duunLlisaPH59qqI2IiDDrJiuPy97eXtOnT9d3332X5nfBg9q2bascOXJoyZIlOnv2bLJ533zzjaKjo9W2bVvTcFQvLy+VKVNGISEhplEZSZYsWZLqjzMdO3aUi4uLvv3221RvgJSYmJhqMH3Y3r17ZTQaU0xP+m6xdH8CsA6GkgLINMHBwfr3339lMBjSvRauc+fOmjVrln766ScNGTJEOXPm1DfffKM+ffpo+PDhWrFihapUqaK7d+/q9OnT2rNnj+lsW0baSlKfPn0UFBSkQYMGycfHR/nz59ehQ4d04cIF1axZM8NntSpVqiQvLy9t3rxZr7/+ury8vHTt2jXt3LlTZcqUSfXZcl26dNH+/fu1bt06tWjRQk2bNpWrq6siIiK0d+9ederUSUOGDEm2TPHixdWwYUPTA9czMoxUuv9HZN++fTVv3jy1bt1a3t7eypMnj3bt2qW///5b1atXT/bMtcfVu3dvBQYG6tdff1WHDh1Uv3593bp1S5s2bdLLL79sqt9acuTIoenTp6tv377q16+fqlWrppdeekm5c+dWeHi4QkNDdf78eQUFBaW4QUpaxowZo7Nnz2ratGlav369vLy8VLhwYUVEROjUqVMKDQ3VlClTVLJkyceuu3bt2rK3t9eUKVP0zz//mM7cDho0yKz67O3ttXz5ctONQJJuoHL58mXt3btX4eHh8vb2Tnc9GT2WL1++rPbt28tgMMjDw0PFihVTdHS0tm/fritXrqh79+6mHy/Gjx+vy5cvy8vLS+7u7sqRI4eOHDmivXv3yt3dXa+++upj7rm0DRo0SMePH9fy5cu1bds21a5dW0WLFtW1a9d09uxZHTx4UO+9955Fh7A+rGLFio98JmCSEiVKaPTo0Ro3bpw6dOigVq1aydXVVSEhITp06JBeeOEFffDBB6b2dnZ2+vzzz9W7d28NHTo02XMM9+zZowYNGmjXrl3JtlGwYEFNmzZN77zzjnx9fVWnTh29+OKLsrOzU3h4uA4dOqQbN26kez2tJA0ePFhOTk6qWrWq3N3dZTQatX//foWGhqpixYqm51cCyN4IhgAyTdLZwkddW1OiRAnVrVtXu3fv1rZt29S8eXNVqlRJa9eu1Zw5c7Rz504dOnRIefPmValSpTR06NBky2ekbZ06dfTdd9/pu+++U0BAgJycnFS3bl1NnTo11bv0PYqDg4Nmzpypr7/+Wjt37tTixYtVtGhRdenSRQMHDkz1D147Ozt98cUXql+/vvz9/bVp0ybFxcXJzc1N1atXV5MmTVLdVqdOnbR161Z5enqa/cfmg0aMGKEKFSpoyZIlWrt2re7du6dSpUpp2LBhj7wxhrly5sypH374QdOnT9fGjRu1aNEiubu7a+DAgWrevLnVg6F0/66S69at0/fff6/t27ebHqHh5uamChUqaMiQIak+SiEtzs7OWrx4sfz9/bVhwwZt3rxZd+/eVeHChVW6dGmNHj36if8QLlu2rCZOnKgFCxZo6dKlunv3riTzgmGOHDn06aefqmPHjlqxYoUOHDigP//8U/Hx8SpUqJA8PT3l5+dnuoY3LRk9lt3d3TVkyBDt27dPwcHBun79ugoUKKAyZcpo+PDhydr3799fgYGBOnz4sPbs2SM7OzsVL15cAwYMUM+ePZU/f/7H2GuP3i8zZszQunXrtGbNGm3fvl0xMTEqWLCgSpQooXfffTdDw7Ezw5tvvqnSpUtrwYIF2rx5s+7cuaNixYqpT58+GjBgQIqh3tWrV9ePP/6oqVOnmobjVqlSRYsXL1ZQUFCKYCjd/w5cv369FixYoKCgIO3fv185cuRQkSJFVLt27Uf+gCBJw4cPV1BQkI4cOaIdO3YoV65cKl68uD744AO98cYbpjPFALI3O2Nq5/4BANne9OnT9e2332r8+PGPDNsAAADpIRgCwFMoOjpa3t7eunfvnrZv3272MEgAAIDUMJQUAJ4i27dv15EjR7Rt2zZdvXpVfn5+hEIAAPDECIYA8BT55ZdftGbNGhUuXFj9+/fXW2+9ldUlAQCAZwBDSQEAAADAxvEcQwAAAACwcTYzlDQxMVEJCZwctXWJiYmaPXuW1q9fp4iICBUsWFBNmjTVsGHvycnJSZK0du0affzxRymWnTt3nurUSfsW9JGRkZoy5Svt3h2kqKgoFS/urtdff11vvtnN1CYwMFCrVvnr2LFjunbtmiZMmKg2bdomW8/GjRv19ddTFBUVpWbNmmns2E9Nt/pOSEhQ9+5vqnv3nmrVqpUldkm2Qx8BeNbxPZf90UfZG/3z+HLkcEhzns0Ew4QEo27ciMnqMpDFli5dpB9++F4ffjhGHh4v6dy5s/rvfz9VdHSMRo68/+URExMnBwcHrV4dkGxZF5f86R5Dfn5+unw5XJ9+OkGFC7spJCRYX3wxSTlzOql58/vPC7t69brKlXtJPj7t9eGHHygmJi7ZOm/evKGPP/5Io0Z9rLJly+njj0dq0aIf1amT7//Xv1j587uqTp2Gz+zxTB8BeNbxPZf90UfZG/3z+Nzc8qU5z2aCYWZJTEzUwoXz9csvAbpy5YoKFCigV15ppP79B5vuHLhx48/6738/TbHs1KnfqUaNWmmue9261dq69Tf988/fioq6qe++m6cqVaqm2T5pO9Wr19Q338wwTQ8M/FWzZn2rW7ei1LBhE40c+ZEcHe8fCgkJCRo4sI9ee62rmjZt8bi7IdsKDf1TNWrUVKNGTSVJxYoVV7Nm3jp4MCRF20KFCmd43X37DlDlyvf7pF27jlq3brWOHTti+iJp2TLlw80fdPFimJydndWixf1fjxo0aKR//z0jSTp//pxWrlymefMWZaiupw19BOBZx/dc9kcfZW/0j3VwjaGFLV++RMuWLdHAgUP0448r5ef3sbZt26Lp06cka+fg4KB1635J9k/Vql7prvvu3Vh5eb2sQYOGPLKOM2dOa/bs71Ks8+bNG/rvf8epX79BmjFjvkJD/9S6datN81esWKpChQo/k6FQkipVqqrQ0L908uQ/kqSwsAvau3e36tSpn6xdQkKCunRpp3btvDV4cD/t3r3rkeuuXLmqtm/fqsjIazIajTpwIETnz59V7dr1zK7P3b2kYmNjdfz4Ud25c0d//HFQL75YTkajURMnfqZ+/QZl+AvuaUMfAXjW8T2X/dFH2Rv9Yx2cMbQwa/6C4evbVZJ06dLFdNvFxsZqzJhRGjLkPQUH71FERIRp3tP6C4alvPFGN8XF3VWfPvfHiSckJKhNmw56++2BpjalSpXW6NFj9OKLBsXHx2nbtkD5+b2nUaM+VuvW7dNc9yeffK7//vdTtW3rLQcHB9nb22v48FGqWbO22fW5uLhozJjPNGHCZ4qJiVG9evX16qtttXq1v5ycnFSzZm2NHj1cJ0+eVOXKVTR8+CjTWPpnBX0E4FnH91z2Rx9lb/SPdRAMLaxSpapavnyJTp78Ry++WM70C0bDhk2StUv6BSMuLlYlS5bWG290V716DSxSw5Qpk1ShgqeaNfNWcPCeZPMe/AWjdOky+uOPg3r11bbZ/hcMS9m2bYvWrFml0aPHqFw5D50796+mT5+qOXNmqH//dyRJnp6V5elZ2bSMp2dl3bx5U0uWLEr3i2T+/Dm6cOGCvvxymgoXdtOhQwf09deT5epaSHXr1k9zuYfVr/+K6td/xfT60qWLWrJkoWbP/l5ff/2lSpcuo/Hjv9C4cR/rhx/madCgoY+xJ7Iv+gjAs47vueyPPsre6B/rIBhamDV/wTDHpk0bdORIqObNW5zq/Kf1FwxL+fbbqerS5XXT2PCyZV/U3bt3NWHCOL31Vl/lypUr1eU8PSsrMPDXNNcbFnZBK1b8qKO5+EAAACAASURBVNmzf1DFip6SpBdfLKeTJ//W4sXfZ+iL5GGTJo1Xr15vq0iRotq/f5969XpbDg4OatHCR/Pnz37s9WZX9BGAZx3fc9kffZS90T/WQTC0MGv+gvEoSdv65puZphvdpOZp/AXDUmJjY2Vvn/zSWnv7pNv2pv04k7//Pq4iRYqmu97767JLZd2P/5iUn39eK0lq27bD/QqNiUpIuCdJuncvXkZj4mOvO7uijwA86/iey/7oo+yN/rEObj5jYQ/+glG27Itq3LiZ+vUbpKVLF+nu3btpLufpWVnh4elfO/gohw+HKirqpvr27a6GDWupYcNa+uWXAB08GKKGDWvpr7/+SHW5h3/BaNGilekXjP379z1RTdlNgwYNtWzZEu3YsU2XLl1UcPAezZ07U7Vq1VWuXLklSfPnz9aePUG6cOG8Tp8+pQUL5mjDhnV67bU3Tes5evSwunbtpKNHD0uSSpd+XiVLltKUKV/or7/+0MWLYdqwYZ1+/TVAr7zyv2HEUVE39c8/J/TPPyckSZcvh+uff04oPDw8Ra1XrkRowYI58vP72DStSpVqWr78R507969Wr16pqlWrW2U/ZSX6CMCzju+57I8+yt7oH+vgjKGFWesXDHM0aNBIixa9lGza3LkzFRkZKT+/j1S8eIkUyzwtv2BYyrBhI+Tikl/ffvu1rl27ogIFCqpu3Qbq1+9/Q31jYm5rypQvdO3aNeXKlUulSz+vceMmmG4oJN3v53Pnzpp+WXJ0dNSXX07TnDnf6T//8dOtW9F67rnn1LfvAL32WlfTckFBO5M9qmTOnBmaM2eGWrVqrY8++iRZrZMnT1C3bj1VrFjxZPWPHz9Wffr0kJdXdfXq9bald1GWo48APOv4nsv+6KPsjf6xDjuj0fj450WfIvHxCZnyAMkJE8bp99+D9MEHo2UweOjcubP68suJKlPmBX3xxVRJ93/BqFChokqWLK24uDht375FP/wwT++++4HpwZdHjx7W+PFj9fHHn6pChftjnK9du6rIyGu6evWKRowYpg8/HKty5QxydS2U5g1jPv/8E0VERCR7jmGSK1ci1K/fW5oxY57pYPXze0/OzvnUs2dvffXVJL3wwot6993h1thVAAAAADIRD7jPRNb6BUOS1q79Sd9/P9f0OumXil693lafPv0zXOvT9AsGAAAAAOvhjCEAAAAA2ID0zhhy8xkAAAAAsHEEQwAAAACwcVxjiKdOvrw5ldsp9QeXIuNiY+7q1u04i64zf96cykkfWURczF3dtHD/AHgyri455PD/t8THk0u4G6vIqHiLrtM1fy455Mxp0XXasoS4OEXeTPuxa4/DtWBuOTjmsOg6bVXCvXhFXo99dMNHIBjiqZPbKZe6lG6X1WU8M1aeXWfxYJjTKZc+L/3moxvikT46+6NEMASyFYdcuXWzV7OsLuOZkf/7QEmWDYYOOXMq5rvBFl2nLXN651tJlg2GDo45dGfnDxZdp63K88pbkp48GDKUFAAAAABsHGcMH+KcN4fyODE8xFLuxMQq+rZlfwUEAAAAYFkEw4fkccqtikVrZXUZz4wjl4MJhgAAAEA2x1BSAAAAALBxBEMAAAAAsHEEQwAAAACwcQRDAAAAALBxBEMAAAAAsHEEQwAAAACwcQRDAAAAALBxBEMAAAAAsHEEQwAAAACwcQRDAAAAALBxBEMAAAAAsHEEQwAAAACwcQRDAAAAALBxWR4MExISNGnSJNWuXVvVqlXTkCFDFBkZmWb7+fPnq1mzZqpWrZpatGihH3/8MROrBQAAAIBnT5YHwzlz5mjr1q1auXKldu7cKUkaOXJkqm23bNmi6dOn68svv9ShQ4c0adIkTZ48Wbt3787MkgEAAADgmZLlwdDf3199+/ZVyZIllS9fPo0YMUK7du1SWFhYirbnzp1T+fLlVbVqVUlStWrV5OHhoePHj2d22QAAAADwzHDMyo1HRUXp4sWL8vT0NE0rVaqUnJ2ddfz4cbm7uydr7+Pjo59++kkHDhxQtWrVdPDgQf37779q0KDBI7fl4GCnAgWcLP4e8Gjs9+yPPsre6B8Azzq+57I/+ih7s0T/ZGkwvH37tiTJ2dk52XQXFxdFR0enaF+oUCF5e3urZ8+eSkxMlCR9+OGHMhgMj9xWQoJRN27EPLKdm1s+c0pHBpiz3zOCPrI8+ih7s3T/AHgyfMdZHv8fyv7oo+zN3P5Jb79naTDMmzevJKUIgVFRUSnCoiTNmDFDAQEBWrt2rcqWLauTJ09q4MCBypUrl7p06ZIpNQMAAADAsyZLrzF0cXFR8eLFdeTIEdO08+fPKzo6Wh4eHinaHzlyRM2aNdOLL74oOzs7lStXTs2aNdO2bdsys2wAAAAAeKZk+c1nfH19NXfuXFMgnDx5surXr68SJUqkaOvl5aXAwED9+++/kqRTp04pMDBQFStWzOSqAQAAAODZkaVDSSWpX79+ioqKUufOnRUXF6d69epp8uTJkqT169dr7NixOnTokCSpT58+unXrlnr37q3r168rf/78atmypfr165eVbwEAAAAAnmpZHgwdHBzk5+cnPz+/FPPatm2rtm3bml47Ojrqgw8+0AcffJCZJQIAAADAMy3Lh5ICAAAAALIWwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbBzBEAAAAABsHMEQAAAAAGwcwRAAAAAAbJzZwfDq1avWrAMAAAAAkEXMDoaNGjXSsGHDtGfPHmvWAwAAAADIZGYHwzJlyuiXX35R79695e3trQULFuj69evWrA0AAAAAkAnMDoY///yzli5dqnbt2uny5cv64osv1LBhQw0fPlwhISHWrBEAAAAAYEUZuvmMl5eXJk6cqF27dumjjz5S6dKlFRAQoB49esjHx0cLFy7UzZs3rVUrAAAAAMAKHuuupPny5VP37t1NZxHbt2+vixcvauLEiWrYsKFGjRql0NBQS9cKAAAAALCCJ35cRcGCBeXi4qJcuXLJaDQqLi5Oa9eula+vrwYNGqQbN25Yok4AAAAAgJU8VjCMj49XQECAunfvbhpCWrBgQY0aNUp79+7VwoULVb9+fW3dulXjxo2zdM0AAAAAAAtyzEjjs2fPasWKFVqzZo1u3Lghe3t7NWvWTF27dlWdOnVM7WrVqqVatWpp6NCh2rVrl8WLBgAAAABYjtnBsGfPntq3b5+MRqPc3Nw0aNAg+fr6qmjRomkuU7FiRf32228WKRQAAAAAYB1mB8Pg4GDVqlVLXbt2VbNmzeTg4PDIZRo3bqwiRYo8UYEAAAAAAOsyOxhu3LhRL7zwQoZWbjAYZDAYMlwUAAAAACDzmH3zmYyGQnMlJCRo0qRJql27tqpVq6YhQ4YoMjIyzfbXrl2Tn5+fatWqJS8vL7Vr106XL1+2Sm0AAAAAYAvMDoabNm1Sjx490gxhly9fVs+ePbV58+YMFTBnzhxt3bpVK1eu1M6dOyVJI0eOTLXt3bt39dZbbylHjhzatGmT9u/fry+//FJ58+bN0DYBAAAAAP9jdjBctWqVbt26lebNZooWLapbt25p5cqVGSrA399fffv2VcmSJZUvXz6NGDFCu3btUlhYWIq2a9asUVRUlMaOHStXV1fZ29urXLlycnZ2ztA2AQAAAAD/Y3YwPHHihDw9PdNtU6lSJZ04ccLsjUdFRenixYvJ1luqVCk5Ozvr+PHjKdoHBwerdOnSGjVqlGrVqqWWLVvqhx9+MHt7AAAAAICUzL75zM2bN+Xq6ppumwIFCuj69etmb/z27duSlOKMn4uLi6Kjo1O0v379uoKDg/Xhhx9qwoQJOnHihPr27StXV1e1bds23W05ONipQAEns2uD5bDfsz/6KHujfwA86/iey/7oo+zNEv1jdjAsWLCgzp49m26bs2fPysXFxeyNJ10b+HAIjIqKSnV4aN68eVW0aFH17NlT0v0zlG3bttWWLVseGQwTEoy6cSPmkTW5ueUzt3yYyZz9nhH0keXRR9mbpfsHwJPhO87y+P9Q9kcfZW/m9k96+93soaReXl7aunWrTp06ler8U6dOacuWLapevbq5q5SLi4uKFy+uI0eOmKadP39e0dHR8vDwSNH+pZdekp2dXYrpqU0DAAAAAJjH7GDYu3dvJSQkqGvXrlq0aJHOnDmjmJgYnTlzRgsXLlTXrl2VmJioPn36ZKgAX19fzZ071xQIJ0+erPr166tEiRIp2nbo0EE3btzQjz/+qISEBB0/flw///yzWrRokaFtAgAAAAD+x+xgWLlyZY0dO1a3b9/WhAkT5OPjo+rVq8vHx0cTJ07U7du39cknn6hKlSoZKqBfv35q0qSJOnfurAYNGigxMVGTJ0+WJK1fv17VqlUztXV3d9ecOXO0cuVKVa9eXUOHDtWQIUPk4+OToW0CAAAAAP7H7GsMpftn96pXr66lS5fqzz//1K1bt5QvXz5VrVpVb7zxhsqWLZvhAhwcHOTn5yc/P78U89q2bZvi2sFatWpp7dq1Gd4OAAAAACB1GQqGklS2bFn95z//sUYtAAAAAIAsYPZQUgAAAADAsynDZwwlKSEhQdevX1dcXFyq84sXL/5ERQEAAAAAMk+GguGJEyf01VdfKTg4OM1QaGdnp6NHj1qkOAAAAACA9ZkdDE+dOqXXX39dklS3bl1t27ZN5cuXV6FChXT06FFdv35dtWrV4mwhAAAAADxlzL7GcMaMGbp3756WL1+umTNnSpKaNWum+fPna8uWLerYsaNOnTqloUOHWq1YAAAAAIDlmR0M9+3bp8aNG8vDwyPFPCcnJ40bN04uLi765ptvLFogAAAAAMC6zA6G169fV+nSpU2vHR0ddefOnWSva9WqpaCgIMtWCAAAAACwKrODYYECBRQTE5Ps9aVLl5K1yZEjh6Kjoy1XHQAAAADA6swOhiVLllRYWJjptaenp3bv3q1r165JkmJiYrRlyxaVKFHC8lUCAAAAAKzG7GBYr149BQcHm84avv7667p586bat2+voUOHqk2bNrp48aI6d+5stWIBAAAAAJZndjD09fXV559/rtjYWElSo0aNNHr0aN29e1ebN29WZGSk3n77bfXo0cNqxQIAAAAALM/s5xgWKVJEPj4+yab17NlT3bp10/Xr11WoUCHZ2dlZvEAAAAAAgHWZfcbw22+/1dq1a1NMd3BwUOHChQmFAAAAAPCUMjsYzpo1S3///bc1awEAAAAAZAGzg2GRIkV4FAUAAAAAPIPMDobNmzfXnj17TDefAQAAAAA8G8wOhkOGDJGLi4veeecdhpQCAAAAwDPE7LuStmvXTvHx8Tp69KjatWunXLlyydXVNcVNZ+zs7BQYGGjxQgEAAAAA1mF2MDQajXJ0dFSxYsVSTE/vNQAAAAAgezM7GG7dutWadQAAAAAAsojZ1xgCAAAAAJ5NBEMAAAAAsHFmDyVdu3at2Stt3779YxUDAAAAAMh8ZgfDUaNGpbgD6cOMRqPs7OwIhgAAAADwFDE7GE6YMCHV6VFRUQoNDdXGjRvVokULNWrUyFK1AQAAAAAygdnBsEOHDunO79Spk/r166fu3bs/cVEAAAAAgMxjsZvP1KlTRw0aNNC0adMstUoAAAAAQCaw6F1Jn3/+eR0+fNiSqwQAAAAAWJlFg+GpU6ceeYMaAAAAAED2YvY1hmlJTEzUpUuX5O/vr507d+qVV16xRF0AAAAAgExidjAsX758umcDjUajChQooJEjR1qkMAAAAABA5jA7GNaoUSPV6fb29sqfP78qVaqkTp06ydXV1WLFAQAAAACsz+xguHjxYmvWAQAAAADIIha9+QwAAAAA4OljdjCMjIxUSEiIoqOjU50fHR2tkJAQRUZGWqw4AAAAAID1mR0MZ8yYoQEDBsjBwSH1Fdnba8CAAZozZ47FigMAAAAAWJ/ZwfD3339XvXr1lCdPnlTnOzk5qV69egoKCrJYcQAAAAAA6zM7GF66dEklS5ZMt03JkiV16dKlJy4KAAAAAJB5zA6GdnZ2io+PT7dNfHy8EhMTn7goAAAAAEDmMTsYlilTJt1hokajUUFBQSpVqpRFCgMAAAAAZA6zg6G3t7dOnz6tcePGKTY2Ntm82NhYjRs3TmfOnJGPj4/FiwQAAAAAWI/ZD7jv0aOHAgICtGzZMgUGBqpGjRoqUqSIIiIiFBISooiICJUvX149e/a0Zr0AAAAAAAszOxjmzp1bixcv1qeffqpNmzYpICDANM/e3l6tW7fWmDFjlDt3bqsUCgAAAACwDrODoSS5uLjoq6++0kcffaTQ0FBFRUXJxcVFlSpVkqurq7VqBAAAAABYUYaCYRJXV1c1bNjQ0rUAAAAAALKA2TefiYyMVEhIiKKjo1OdHx0drZCQEEVGRlqsOAAAAACA9ZkdDGfMmKEBAwbIwcEh9RXZ22vAgAGaM2eOxYoDAAAAAFif2cHw999/V7169ZQnT55U5zs5OalevXrpPusQAAAAAJD9mB0ML126pJIlS6bbpmTJkrp06dITFwUAAAAAyDxmB0M7OzvFx8en2yY+Pl6JiYlPXBQAAAAAIPOYHQzLlCmT7jBRo9GooKAglSpVyiKFAQAAAAAyh9nB0NvbW6dPn9a4ceMUGxubbF5sbKzGjRunM2fOyMfHx+JFAgAAAACsx+znGPbo0UMBAQFatmyZAgMDVaNGDRUpUkQREREKCQlRRESEypcvr549e1qzXgAAAACAhZkdDHPnzq3Fixfr008/1aZNmxQQEGCaZ29vr9atW2vMmDHKnTu3VQoFAAAAAFiH2cFQklxcXPTVV1/po48+UmhoqKKiouTi4qJKlSrJ1dXVWjUCAAAAAKwoQ8Ewiaurqxo2bJhi+qlTp7RixQp9+OGHT1wYAAAAACBzPFYwfFBcXJw2btwof39/HTp0SJIIhgAAAADwFHnsYPj333/L399fP//8s6KiomQ0GlWyZEl17tzZkvUBAAAAAKwsQ8EwNjZWAQEB8vf3119//SWj0ShJKl++vPz8/FSnTh2rFAkAAAAAsB6zguHx48e1YsUKbdiwQdHR0TIajapYsaI6duyozz77TJUqVSIUAgAAAMBTKt1guHLlSq1YsUJHjhyR0WhU4cKF1blzZ3Xs2FHlypWTJH322WeZUigAAAAAwDrSDYb/+c9/ZG9vrxYtWqhDhw5q0KCBHBwcMqs2AAAAAEAmsH9UA6PRqBMnTujvv//WtWvXLF5AQkKCJk2apNq1a6tatWoaMmSIIiMjH7nc0qVL5eHhoRkzZli8JgAAAACwJekGw6VLl6pt27YKDw/XlClT1LhxY7399tvauHGj4uLiLFLAnDlztHXrVq1cuVI7d+6UJI0cOTLdZcLCwvT999/LYDBYpAYAAAAAsGXpDiX18vKSl5eXPv74Y61bt07+/v7atWuXgoKC5OLiolatWj1xAf7+/ho0aJBKliwpSRoxYoSaN2+usLAwubu7p7rMRx99pPfee0/Lli174u0DAAAAgK0z666k+fLlU7du3dStWzf9+eefWrFihTZt2qTly5dLknbu3KkFCxaoffv2cnV1NXvjUVFRunjxojw9PU3TSpUqJWdnZx0/fjzVYLh8+XLlyZNHPj4+GQqGDg52KlDAyez2sBz2e/ZHH2Vv9A+AZx3fc9kffZS9WaJ/MvyA+ypVqqhKlSr68MMPtX79eq1atUpHjx7V5MmTNXXqVDVu3FjTpk0za123b9+WJDk7Oyeb7uLioujo6BTtL168qJkzZ8rf3z+jZSshwagbN2Ie2c7NLV+G1430mbPfM4I+sjz6KHuzdP8AeDJ8x1ke/x/K/uij7M3c/klvvz/y5jNpcXZ2VteuXbV69WqtWrVKnTt3lqOjo3777Tez15E3b15JShECo6KiUoRFSfr44481cOBAFS1a9HHLBgAAAAA8JMNnDFPj6ekpT09PjR49WgEBAWYv5+LiouLFi+vIkSN66aWXJEnnz59XdHS0PDw8UrTfvXu3jhw5oqlTp0q6HyhDQ0MVFBSkpUuXWuKtAAAAAIDNsUgwTOLk5KQuXbpkaBlfX1/NnTtXtWrVUsGCBTV58mTVr19fJUqUSNF2x44dyV6/++67ql69unr37v1EdQMAAACALXvsoaSW0q9fPzVp0kSdO3dWgwYNlJiYqMmTJ0uS1q9fr2rVqpnaPvfcc8n+yZkzp5ydnVW4cOGsKh8AAAAAnnoWPWP4OBwcHOTn5yc/P78U89q2bau2bdumuezixYutWRoAAAAA2IQsP2MIAAAAAMhaBEMAAAAAsHFpBsPjx4/r2rVrmVkLAAAAACALpBkMO3TooGXLlple9+jRQ2vXrs2UogAAAAAAmSfNYGhvb6/ExETT63379unChQuZUhQAAAAAIPOkGQyLFi2qY8eOZWYtAAAAAIAskObjKpo0aaIlS5aoVatWcnNzkyStWbNG+/btS3eFdnZ2WrhwoWWrBAAAAABYTZrBcNiwYYqLi9OOHTsUEhIiOzs7hYWFKSwsLN0V2tnZWbxIAAAAAID1pBkMnZ2dNW7cONPr8uXLa/DgwRo8eHCmFAYAAAAAyBxmP8ewRo0aKlGihDVrAQAAAABkgTTPGD5s8eLF1qwDAAAAAJBFzA6GSe7cuaPNmzfr2LFjioqKUr58+VShQgU1b95cTk5O1qgRAAAAAGBFGQqGO3bskJ+fn27evCmj0WiabmdnpwkTJmjChAlq3LixxYsEAAAAAFiP2cHwyJEjGjx4sBITE9WmTRvVrl1bbm5uunLlivbu3auAgAANHTpUy5Ytk6enpzVrBgAAAABYkNnBcNasWbKzs9OPP/6oqlWrJpvXsWNHvfnmm+revbtmz56t6dOnW7xQAAAAAIB1mH1X0v3796tly5YpQmGSKlWqyNvbW/v377dYcQAAAAAA6zM7GN66dUvFihVLt03x4sUVHR39xEUBAAAAADKP2cGwSJEi+uuvv9Jtc/jwYbm5uT1xUQAAAACAzGN2MGzYsKH27t2rOXPmKCEhIdm8xMRELViwQL///rsaNmxo8SIBAAAAANZj9s1nBg0apMDAQE2dOlXLly/Xyy+/LDc3N129elUHDhxQWFiYChcurIEDB1qzXgAAAACAhZkdDN3c3LRs2TKNHTtWu3fv1vr165PNr1evnj755BMVKVLE4kUCAAAAAKwnQw+4L1GihObPn6/Lly/r6NGjunXrlvLly6cKFSqoaNGi1qoRAAAAAGBFGQqGSYoWLUoQBAAAAIBnhNk3nwEAAAAAPJsIhgAAAABg4wiGAAAAAGDjCIYAAAAAYOMIhgAAAABg4wiGAAAAAGDjCIYAAAAAYOMe6zmGkrRjxw7NmzdP//zzjySpXLly6tevnxo0aGCx4gAAAAAA1vdYZwz9/f3Vv39/RUREqHbt2qpWrZpOnDihfv366aeffrJ0jQAAAAAAK3qsM4azZs3Sm2++qf/85z+mabdu3VLXrl01e/ZsderUyWIFAgAAAACsK90zhl988YXi4uJSTA8PD1fz5s2TTcuXL5/q1aunS5cuWbZCAAAAAIBVpRsMV69erXbt2ungwYPJppcuXVorVqxQbGysadqFCxe0efNmPf/881YpFAAAAABgHekGw4CAAJUrV07dunXT+PHjdefOHUnSsGHD9Msvv6hBgwby9fVV+/bt1bJlS4WHh2vYsGGZUjgAAAAAwDLSDYaFChXStGnTNGXKFP3yyy9q06aN9u7dK29vb61atUqvvPKK7t27J3t7e7Vq1UqrV69W06ZNM6t2AAAAAIAFmHXzmZYtW6pOnTr67LPP1KtXL3Xp0kUjR47UV199Ze36AAAAAABWZvbjKvLnz68vv/xSM2fO1I4dO9S6dWvt2LHDmrUBAAAAADJBhp9j2KhRIwUEBKhevXrq37+//Pz8dPPmTWvUBgAAAADIBI8Mhjt27FD//v3Vpk0b9e/fXzt27JCzs7M+//xzLViwQPv379err76q3377LTPqBQAAAABYWLrBcOPGjerfv78OHTqkPHny6NChQxowYIA2bNggSapbt65+/vlntWjRQkOHDtWwYcMUGRmZKYUDAAAAACwj3WA4a9YslStXTlu3bpW/v7+2bt2qsmXLas6cOaY2Tk5OGjNmjBYvXqxjx47Jx8fH6kUDAAAAACwn3WB4/vx5NWjQQM7OzpIkZ2dnvfLKKzp//nyKti+//LLWr1+vDh06WKdSAAAAAIBVpBsMS5QooYMHDyoxMdE07dChQypRokSq7XPlyiU/Pz/LVggAAAAAsKp0n2P49ttva+TIkfLx8VHFihV17NgxnT59WhMnTsys+gAAAAAAVpZuMGzbtq3y5s2r5cuX6/jx4ypevLjef/99NWvWLLPqAwAAAABYWbrBUJKaNm2qpk2bZkYtAAAAwP+xd9/RUdR7H8ffm7KppGx6b7QEAlICSBUEqSJFAelNFB/golLl0kGaoCCCNEGilFAERQFBeq8KSQgQso9PhgAAIABJREFUShohnSSkJ7vPHzk7N4GA16uSQL6vczwedmd2p2Rn5vOrQohy8KcnuBdCCCGEEEII8WKRYCiEEEIIIYQQlZwEQyGEEEIIIYSo5CQYCiGEEEIIIUQlJ8FQCCGEEEIIISo5CYZCCCGEEEIIUclJMBRCCCGEEEKISk6CoRBCCCGEEEJUchIMhRBCCCGEEKKSk2AohBBCCCGEEJWcBEMhhBBCCCGEqOQkGAohhBBCCCFEJSfBUAghhBBCCCEqOQmGQgghhBBCCFHJlXswLCoqYsGCBTRp0oR69eoxevRoUlNTy1z26NGjDBw4kMaNGxMUFETfvn25cOHCM95iIYQQQgghhHixlHswXL16NYcOHWLbtm0cO3YMgAkTJpS5bHp6OgMGDODAgQOcPn2aLl268M477xAfH/8sN1kIIYQQQgghXijlHgxDQkIYPnw4Hh4eVKlShfHjx3P8+HHi4uIeW7Zr1660a9cOKysrjIyM6Nu3L+bm5ly9erUctlwIIYQQQgghXgxG5fnlGRkZ3Lt3j9q1ayuveXp6YmlpSUREBG5ubk9d//r166SlpVG9evU//C5DQxU2NuZ/eZvFnyfHveKTc1SxyfkRQrzo5DpX8ck5qtj+jvNTrsEwKysLAEtLy1KvW1lZ8fDhw6eum5KSwpgxYxg6dCje3t5/+F1FRToePMj+w+UcHKr84TLiz/lvjvufIefo7yfnqGL7u8+PEOKvkWvc30/uQxWfnKOK7b89P0877uXalNTCwgLgsRCYkZHxWFgsKSEhgYEDB9KsWTM++uijf3QbhRBCCCGEEOJFV67B0MrKCldXV8LCwpTXYmJiePjwITVq1ChzndjYWPr160fLli2ZNm0aKpXqWW2uEEIIIYQQQryQyn3wmV69erFmzRolEC5atIjmzZvj7u7+2LK3bt2ib9++dO7cmYkTJ5bD1gohhBBCCCHEi6fcg+GIESNo06YNb775Ji1atECr1bJo0SIAfvjhB+rVq6csu3btWhISEti4cSP16tVT/vvhhx/Ka/OFEEIIIYQQ4rlXroPPABgaGjJx4sQyawC7du1K165dlX/PmzePefPmPcvNE0IIIYQQQogXXrnXGAohhBBCCCGEKF8SDIUQQgghhBCikpNgKIQQQgghhBCVnARDIYQQQgghhKjkJBgKIYQQQgghRCUnwVAIIYQQQgghKjkJhkIIIYQQQghRyUkwFEIIIYQQQohKToKhEEIIIYQQQlRyEgyFEEIIIYQQopKTYCiEEEIIIYQQlZwEQyGEEEIIIYSo5CQYCiGEEEIIIUQlJ8FQCCGEEEIIISo5CYZCCCGEEEIIUclJMBRCCCGEEEKISk6CoRBCCCGEEEJUchIMhRBCCCGEEKKSk2AohBBCCCGEEJWcBEMhhBBCCCGEqOQkGAohhBBCCCFEJSfBUAghhBBCCCEqOQmGQgghhBBCCFHJSTAUQgghhBBCiEpOgqEQQgghhBBCVHISDIUQQgghhBCikpNgKIQQQgghhBCVnARDIYQQQgghhKjkJBgKIYQQQgghRCUnwVAIIYQQQgghKjkJhkIIIYQQQghRyUkwFEIIIYQQQohKToKhEEIIIYQQQlRyEgyFEEIIIYQQopKTYCiEEEIIIYQQlZwEQyGEEEIIIYSo5CQYCiGEEEIIIUQlJ8FQCCGEEEIIISo5CYZCCCGEEEIIUclJMBRCCCGEEEKISk6CoRBCCCGEEEJUchIMhRBCCCGEEKKSk2AohBBCCCGEEJWcBEMhhBBCCCGEqOQkGAohhBBCCCFEJSfBUAghhBBCCCEqOQmGQgghhBBCCFHJSTAUQgghhBBCiEpOgqEQQgghhBBCVHISDIUQQgghhBCikpNgKIQQQgghhBCVnARDIYQQQgghhKjkJBgKIYQQQgghRCUnwVAIIYQQQgghKjkJhkIIIYQQQghRyUkwFEIIIYQQQohKToKhEEKIv+z06RMMHtyX1q1f5s03X2fLlm//q/W+++4bevbsQuvWLzNkSF/OnTvzpz/75s0bDBs2gLZtmzN69Lvcv3+/1PvLl3/Op5/O+9937gUh50gIIcTTSDAUQgjxl0REhDNp0kc0adKU9es3MXToCFavXsGuXduful5IyCbWrVvN8OHvsX79JoKCGjNx4gdERt78U589f/5sAgPrsmHDZqysrFi+/DPlvfDwUI4ePcz774/5+3f8OSLnSAghxB+RYCiEEOIv2bLlO/z9a/Hee6Pw9vahU6fX6dmzN99++80T19HpdGzaFEzv3n3p2LEL3t4+vP/+v/Dzq8bWrd/9qc+OirpD9+5v4u7uQZcu3bh79w4ABQUFzJs3i3HjJmFubvHPHYDngJwjIYQQf0SCoRBCiL/k6tXfadz45VKvNW78Mvfvx5OYmFDmOvHx90hOTipzvStXfvtTn121anXOnDmJVqvl7NlTVK1aDYD169fg71/rsfUrIzlHQggh/ogEQyGEEH9JSkoyGo1dqdf0/05JSX7iOiWXK7leyXX+m8+ePHkap06d4M03X+f+/XhGjfqAmzev88svexk5cgxffLGE3r27MXr0u0RHR/2FPX1+yTkSQgjxR4zKewOEEEKIv8LLy5ulS1cq/y4sLGTChH8xdux4Dh8+yPXrEQQHh/Djj7uYPXsaa9Y8ufmk+GfIORJCiIqv3GsMi4qKWLBgAU2aNKFevXqMHj2a1NTUJy5/7NgxOnfuTJ06dejSpQsnTpx4hlsrhBDiUXZ29qSmppR6LS0tVXnvSesAZa5Xcp3/5bO//XYDXl4+NG/ekgsXztG6dVvUajUdO3bh2rUwsrOz/sTevRjkHAkhhPgj5R4MV69ezaFDh9i2bRvHjh0DYMKECWUuGxMTw+jRoxkxYgQXLlxgxIgRjBo1itjY2Ge5yUIIIUoIDKzLuXOnS7129uwpnJ1dcHR0KnMdFxdX7O0dOHv28fXq1Hnpf/7sO3du88MP3zN27DgAdDotRUWFABQWFgCg1er+5B4+/+QcCSGE+CPlHgxDQkIYPnw4Hh4eVKlShfHjx3P8+HHi4uIeW/b777+nVq1avPHGG6jVarp27UpAQAC7du0qhy0XQggB0Lt3X8LDw1i16kuiou6yd+8etm8PoX//Qcoy4eGh9O3bk/DwUABUKhV9+w4gJGQT+/f/TFTUXVau/ILIyJv06tX3T322XlFREfPmzWL06A+wtrYBoG7devz00w/cvn2Lb7/dQNWq1bG0tPyHj0jFI+dICCHEHynXPoYZGRncu3eP2rVrK695enpiaWlJREQEbm5upZaPiIigVq1apV4LCAggIiLimWyvEEKIx/n712LevMWsWvUlW7Z8i0Zjx4gRI+nW7U1lmdzcXKKjo8jNzVVe69WrL/n5+axa9SVpaal4efkwf/4SqlWr/qc+W2/r1k04OjrSunVb5bXu3d8iMvImI0cOxdXVjX//e+Y/dBQqNjlHQggh/ohKp9OVW3uN+Ph4XnnlFQ4ePIiHh4fyeuvWrRk7dixvvPFGqeUHDRpEgwYNGDPmP5PgLlu2jEuXLrFhw4ZntdlCCCGEEEII8UIp16akFhbFk9k+fPiw1OsZGRllNiOxsLAgMzPzv1pWCCGEEEIIIcR/p1yDoZWVFa6uroSFhSmvxcTE8PDhQ2rUqPHY8jVr1iQ8PLzUa9euXaNmzZr/+LYKIYQQQgghxIuq3Aef6dWrF2vWrFEC4aJFi2jevDnu7u6PLdutWzdCQ0PZs2cPBQUF7Nmzh7CwMLp161YOWy6EEEIIIYQQL4Zy7WMIxSOUffrpp+zcuZP8/HyaNWvGrFmz0Gg0/PDDD0yfPp3Lly8ryx87dowFCxYQExODh4cHkydPpnnz5uW4B0IIIYQQQgjxfCv3YCiEEEIIIYQQonyVe1NSIYQQQgghhKgMdDodFbVerlznMRRCCCGEEEKIykKlUpX3JjyR1Bi+gCpqKYR4vmm1WoqKiuTv6xlKS0sDoLCwsJy3pOJKS0sjPT29vDdDPIWcoxfDX6nl0Gq1FBYWotVq/+atEiXl5+cDyHGu4I4fP862bdsem4KvIpBg+AJITU0lLCxMmQ9SpVKxdetWPvroI+Li4sp560RFtG7dOnbv3l0qcOh0OrRa7RNvKAYGBhgaGlbokq7nlU6no6ioqFTwPnbsGC1atADAyEgadyQkJPDdd99x/vx55bWMjAz+9a9/8c033wBSKFbe5By9OIqKitBqtaXOl0qleur1X38NK+seYmBggJGREQYG8tj5dyh5z4Di58APP/yQzZs3A8hxriD0z1WPunbtGufPn0etVgMVK8jLX85zQKvVKqVAUPwH9fnnnyvzP06dOpWePXuya9cuZZkqVaqQlpZGdnb2M99eUXHpLz4eHh7UqFEDQ0ND5T2VSoWBgcFjN5Ts7GySk5O5cOEC06ZNY8OGDaSmpj7T7X4RPHojL0mlUmFoaFgqePv4+ABw7tw5vvvuO6Kjo5/p9j4LJR867927x927d0u9P3PmTCZPngzAhQsXmD17NnPnziUiIgIoDsx+fn4kJyc/9nni76M/rnKOKg9DQ0MMDAxQqVTk5eVx8+ZN9uzZw+LFizl+/HiZtYf6a1hZoeTw4cNMnjyZkSNHcv78+Qr1IFxR6e8ZZR2rkvcMAI1Gg1qtJikpid9++42jR48+682t1J7096x/roLiZ6nU1FTy8/O5d+8ex44do2PHjrz22mscP378WW7uU0kxdAVRVFRU6g9o06ZNxMTE4Obmxpw5c5gwYQJDhw4FICsri0uXLlG7dm1q1apF3bp1+fXXXzl27BgBAQHUr18fd3d3cnJypPlOJaTT6ZRwob956/+uDAwMKCws5LXXXntsndu3b3PmzBny8/Np3bo13t7eAEyYMIGoqCjatGmDSqVi37593L59m1mzZj3T/XrW9CV9+lLy/7am9NEbhP7Y62/kZbl27Rrnzp3jzp07uLm58c477/DBBx9QWFjI1KlTcXJyokGDBn9thyqI9PR09uzZg729Pe3btwcgPDycAQMGYGVlxYoVK/D39wfAxsaGEydOAODu7k6tWrUwMzNj4cKFfP3116jValxcXDh58mS57c+LpKCggOjoaG7cuEFsbCwajYaWLVvi4OBAaGgoAwcOxNraWs5RJfCvf/2La9eukZ6eTnp6OmZmZtSoUQMfHx98fX2V62FhYSFGRkZkZWWxb98+Tp06hbW1NcOGDcPNzQ2AI0eOsHXrVqpWrYq/vz8zZ85kxIgRdO3atTx38R9XUFCAsbHxU5fR32f0IbykJ90z8vLyCAsL49q1ayQmJtK9e3ciIyP59ddfycnJYe/evbRo0YJGjRphZmb2t+7Ti6DkM5Le0qVLadq0KUFBQcr5eNSTXof/3OezsrIwMDBQjnt8fDyLFi3i+PHjFBUVMXToULp3706VKlWwsbGhZ8+evP3221haWv7Ne/m/kxrDCiApKYmePXuSkJAAwOnTpwkODqZJkyZoNBqguLRN3zzH2dkZKysrJfRpNBq8vb1p164d06dPB8DV1ZWioiIJhi+op5W66y94+lCjv2AlJSWRkJCAkZERv//+O8uXLycqKgqAy5cvM336dE6cOMGlS5eYP3++UoIVGBhITEwMbdq0YebMmQwbNoywsDAiIyP/4b0sX/qbcslS89jYWOX9R5t+6ulrXfX/6d+Pjo4mODiYGTNmsH//fiVARkRE8Nlnn3Hy5EnMzMxQq9U8fPiQLVu24ODgwKJFi9i4cSM1a9Z8djv/D9Afh5s3bzJ79mxWrFhBUlISAFZWVrz00ksYGRmxaNEiZZ3q1atz7949oPg6Z2lpSceOHSkoKGDt2rUYGRnh5OSk1EZJM+f/XWpqKoGBgQwaNIgNGzZw7do1jh49yrvvvsuBAwfw9PSkTp06co5eAPqaqLL6LuuvS+3bt2fq1KmcOXOGpk2bMm7cOLZs2cK8efM4cuQIISEhDB8+nB49ehAVFcWuXbv4+eefqVGjBrm5ucyZM4eLFy8CsHHjRpo3b864ceMYOHAgffr04fTp08TExDzT/X6WoqKiCAwMBJ7eP19/n3n0d6HVarly5QrffPMNwcHBSlchgLVr1zJz5kyOHj1KYmIiGRkZtGrViv79+9O9e3cOHDjAjBkzJBSWoWQoLNlU+tChQxw6dEh5vSz6Z6mHDx+WasWXn5/PihUraNKkCZ07d+azzz5TWvgcOnQIrVbLyZMnOXPmDH369MHNzY3+/fsTEBCAt7c3lpaWFaolhQTDCsDKyoqsrCwKCgqIi4tj2bJldOvWjVatWuHs7IyBgQGvv/66UkOj0WgwMjJSmvM5OTmRn59Pjx49MDY2ZvXq1djb26NWq5XBK8Tz54+akZTl3r17/Pbbb8TGxmJgYEBUVBTDhg2jQYMGdOnShY0bNwLFtTaHDh0iPT2dgoICtm7diouLCytXrmTp0qV4enqydOlSoPjvy9ramrp16wIQEBCAqanpC99/NSkpiY8//pj27dvTuHFjmjRpwsyZM5Xm2Y82/dT77bffOHjwIF9++SVNmjRhw4YNJCYmsmLFCo4dO4a1tTVr165l/fr1QHHrAGdnZ1avXs3EiRMZNGgQpqamGBkZ4erqypkzZ4Di0ufnmf44JScnY2pqiouLC8HBwUBx03eNRkPHjh3Jy8tjxYoVQHGT5wcPHgDFBWJarRYzMzMmTJjAqlWruHPnDq6uruTk5JCfny+h4y+wsLDA09OT3bt3s3XrVpYsWcLkyZNp2rQpM2bMIDk5GUdHRzp06CDnqIIZNmwYp0+fLvWaPow8rRliWX2XDQwM0Gq1dOrUiRYtWqBSqXB1deXatWvk5uaSmprKrl27WLNmDf379+eHH34gOTmZQ4cOMX78eEaMGMEnn3yCRqNh7969JCcnY2xszI0bN5g7dy7Dhg1j6dKlhIaGKoUFLwJ96xz98bazs8PIyIj79+8/sX9+Xl4eFy5cYP369ezevbtU2Dhw4ACffPIJ58+f59ixY0yZMoWoqCgyMjI4ceIE48aNY/Xq1cybN4+aNWtibGyMm5sbmZmZXL9+HahY/dbKkz506UPhd999x3vvvVfqelS/fn2lgMvIyIjMzMxSBSfp6elMnTqVxo0b07t3b1avXk1GRgYABw8eZO/evezatYsdO3aQkpLClClTAHjw4AGxsbHKd5uamgLFzw+FhYVKYXNFui5KMKwA1Go1RUVFREVFsWrVKuzs7Hj33XcBcHFxQavV0q1bN0xMTPjiiy8wNzfHysqKBw8eUFhYiIODAwUFBWRmZrJo0SLWr1/PjRs3sLGxISUlpdTFRvwz/tfR2vQlVmUN+lKyxqqkmJgYQkNDycrKUl47cOAAr7zyCj169GD+/PlcvnwZKK5pdnR05OLFi5w9e1Zpjuzj44OZmRnZ2dlkZmZy9+5devbsCRQ/GPTt25eIiAgKCwvx9fUt1afQ3t4e4LkvdNA/OD1JVlYWBw8eZMCAARw6dIjLly+zZs0azM3NAdi3bx99+vShbdu2rFq1Sqnxv3TpErNmzSI+Pp6vv/6aIUOG8NVXX6HValmzZg0ffPAB48ePJywsjIiICJo2bUpCQgILFixgzpw5/PTTT0oI9Pb25ubNm8CL0TdLp9Nx9OhROnfuTNeuXdm6dSsPHz7E2toatVqNTqdj0qRJbNq0ifDwcJydndHpdKSkpGBsbIyFhQXJyckEBgbSvXt3Fi9eTEFBQaUoqPinqdVqCgsLuX37thIoXFxc+OijjwA4e/YsRkZGqFQqJk6cKOfoGYiIiODChQtl3sP1BYcAffv2pXr16qXe14eRkvcPnU5HYmIi169fZ/Pmzbzzzjts3rz5sbEI9C0d9N/r7e1NYmIihYWF2NjY4OXlhbu7O6+88gpQfE9KTEzk7NmzTJ48mWHDhrFjxw7i4uLIyckhJyeH3377DSsrKzp06MDXX3/N9u3bqVev3t95uJ6ZJ/UTL9lCx9LSEhsbGyIiIrhx4wbLly/nl19+KXUuN2/ezCeffEJoaCjbt2/n008/JTExkfz8fFavXk27du1Yvnw5y5YtIykpiZCQEExNTXF3d2fXrl0EBwfzzTffKL8rjUZDQUGB0lLsRbhn/Lf+qA8//Kdw1cPDg6SkJG7evMmlS5dITEwkICCAsLAwfvrpJ2rXrs3bb7+tFN4WFhayfft2oqKiOHz4MMuWLePkyZMsX74cgPPnz9OoUSOcnZ2xs7Nj8uTJhIaGEhMTQ7du3QgICKBXr160bNmSGTNmcOvWLezt7bGwsCArK6vCBXgJhhWASqXCxcWF1atXc+DAARYuXAgUP7jqOxTHxcWxePFiduzYwe+//46NjQ2ZmZlkZWWh0WgwMzMjMjISPz8/OnfuTHBwMGlpaeTk5MgANM/A0/qgPS2A6JspPjroS2pqKtHR0WzatImZM2eSkpJCVFQUffr0oW/fvsyePZtFixZRWFhIUlISmzdvZs6cOZw5c4YtW7bQsmVL8vPzSU1NJTExkdTUVDIyMpQSYgcHB3Q6HUlJSVhbW5ORkaFso1arxdnZmcLCQvLy8nB3d6eoqEgZVtnExIQqVaooBRMVWcng/eg50D84PYm1tTW+vr44OTlhYWFR6uJ94cIFtm3bxuuvv86qVas4efKk0rwuICAAc3NzAgMDCQgIoKCggIcPH6LVatm7dy/Tp09n0aJFHD16lIsXL9KhQwdGjhxJbm4ueXl5/Pjjj0rrAF9fX6XJrn70sueVvsT0xIkTBAUF0alTJ8zNzZVabDs7O9LS0ggMDKRHjx4sXryYnJwcHBwclHBsa2tLamoqDx8+5OOPPyYpKYl9+/ZhYGBAfHy88j3iz1OpVDg6OpKcnKwECn3f94CAAOLj41Gr1WRkZFCnTh05R/8g/bXm5MmTXL9+XbnOPjpCqKGhIfn5+bz66qvY2dkp7+Xm5nLo0CHmzZvHV199pdRKxMTEKIMFJSYmUrNmTX744Qe+/PJLoHTgUalUyv3C19eX5ORksrOzMTAwwN3dvdT2+vr6Kg/Z9vb2dOnShV27drFy5Uo0Gg1NmjTB39+f0aNH89ZbbxEYGEhkZORzWWOo1WpL3Td0Oh137tzhxIkTXLx4ke3btys1dh4eHmzdupUNGzYQERHBmjVrlJr2K1eusGfPHkaOHMnixYsZP348165d4+DBg9y9exd7e3saNmwIgJmZGZ06deLKlSsYGBgwYcIE/Pz8OHnyJCdPnuSzzz4jIiICX19fioqKlBp8Q0PDSvNbe3QwHr3Y2FjOnj3LzZs3UavVpKamsnHjRsLCwhg8eDDz588nKioKX19fYmNjuXjxIhcuXGDu3LkEBwcr3T727t1Lr169MDc3x8/Pj48++ojdu3cDEBcXh5+fn/Kd9vb2mJubk5CQgJubGxMmTGDt2rUcOXKErKwsVqxYgU6nw8HBgbt37yrPfhUlIEowrCBeeuklwsPDcXV15eDBg0Dxg6uJiQn29vaEhobi5eVFly5dCA4OJjExESMjI9LS0rCyskKj0ShtmseNG4dOp+PixYvExsaSm5tbnrv2QktLS+PSpUts376d/fv3k5OT89gyJQNIyYt0eno6P//8M1u3buXcuXMMGzaMoqIiUlNTGT9+PNOnT+fatWt4eXmRk5PDv//9bzp06MDx48fZsmULsbGxbNmyBVtbW+7fv094eDiRkZGEh4djamqKWq2md+/eeHt7M3DgQDp37sy0adO4efMmpqamWFhYkJSUhKGhITVq1ODw4cPk5eVhYGDA3r17qVGjBjk5OWg0GgwMDEr1KTQwMCi3v61ffvmFUaNGKaMj6oNfWXNklQzeJW8YmZmZ7Nmzh7Vr13Lr1i3lc0oyNTXF3t5e6QdTVFTE/fv3geKpJIqKiujXrx9+fn68//77PHz4kGPHjuHo6IiHhwc2NjYA5OTkYGNjw759+zh48CDGxsb06dOHrVu30rt3bwBq1arF9OnTmT17Nq1atWLfvn0ANG7cmPv377Nt2zbWrl1LYmLi33w0nx2VSkV0dDTGxsbUrl0bgPHjx3PgwAHu3LmDh4cHOTk5xMTE8OGHH5Kfn8+OHTswMTFRzrWLiwsZGRlKE57Ro0dz69YtIiMjX+j+Ss9KzZo1iY+PV35H+v+bmpoqf8e5ublyjspQsinh/9p6RF9Tq39QHDZsGP369cPc3LxU3yj9FFUxMTGo1Wp+/vlnJkyYoHzW/v37Wb58OSqVitu3bzN16lSioqJwdnamSpUq5ObmMnr0aD766CN69OjB3r17AR57qNZvh7e3N5mZmUrhoLe3d6lQ5+HhQd26denZsycfffQR3bt3p2bNmpw6dQoLCwv69OlDQkICkyZNYujQoXTq1IklS5Y8N62ZCgoKlLBlYGCg1O4VFBTw9ddf06dPHzZs2MDKlSv54osvlL/zgIAATpw4Qe/evVm+fDmDBw/m0qVLXLhwgeTkZIyMjGjWrBkAderUoX79+pw8eRIrKyul6bWen58fcXFxGBkZYWdnx/vvv89XX32lfN/FixdxdnZGo9Hw66+/cuLECQ4ePIhKpaoU4fDq1ausWrWKKVOmsGPHDqUVVJ8+fZg9ezZTp07l1KlTaDQaJk+ejIuLC9999x0hISEEBQXh6OgIwGuvvYapqSl169Zl8ODB7Nq1C7VaTUxMTKkCEV9fX3Jzc3n48CHOzs7ExcUplTBarZaCggKlIC0rKwsHBwdMTEywtrbG3d0dnU5H586dSU1NpXHjxnTt2pU7d+6Uy7F7lIxKWkG4u7vTv39/rKysWLlyJb/99hsffvghlpaWuLm5KaWx77//PkuWLGHHjh00btyY7OxsTE1NsbGxITw8nB49emBqakrfvn25ePGi0ixI/EdZI1KlpKRgZ2dX5ntlyc3NZeXKlaxatYpq1aphY2ODTqfj119/ZeHChcrnJCcnc+4G/0qCAAAgAElEQVTcOaKioggICKBVq1ZAcWflRYsWER4eTu3atTl79iwnT54kKSkJJycnHBwcOHPmDJ9//jnW1tbcu3ePmJgY+vfvT0JCAnfv3sXS0pLt27fTq1cvPv30U7799luGDx+ORqMhICCAMWPG4ObmxocffggU9yEaOHAgGzduZPbs2bi4uJCamkphYSFDhw5lxowZLF68GBsbG44cOcKIESOUZqNBQUGlOr9PnjwZKyurZzaSlk6nUy60+rb5ycnJysipZU2zAcUDnURFRZGZmcnKlSsxNTVlzJgxPHz4kB9//JHs7Gx+++03/vWvf1GtWrVS59/IyAgvLy8+/fRTNm/eTHx8PA0bNmTy5MmoVCocHByU7/Hx8cHa2po7d+5Qt25djI2NleY8lpaW1KlTh8uXL7N48WJlnaysLGXk4fXr11OlShWio6O5desWY8eOBYofFkaNGsWePXvw8PD4pw7vM3PmzBkMDQ0JCQnBzMyMM2fOcO3aNQ4cOICjo6NSi+3h4cHIkSPZvHkz0dHRSk2TnZ0dZ86cISMjA1dXV5o3b05ycjJRUVFK342K1FfjeePv78+NGzfIy8vDzMxMqTHKzMzE3d2dmjVrcvv2bZKTk+UcPUK/T380zx/8p8CqpLKuX5mZmVy+fJnq1avj7OzM2bNnmTZtGmlpaTg6OvLmm28yePBgDAwMOHz4MFA8yNX69esZNGgQ3bt3JyUlhYULF7J27Vpmz56Ns7MzSUlJyvc1a9aMWbNmkZmZSZUqVcrcbjc3N4qKipTuAy4uLqVaItna2vLee++xbt069u/fT3R0NOnp6QQFBdGwYUM0Gg2rVq3ixx9/RKvV4ufnR7Vq1bCysvpvD2+5+uSTT7h+/TqffvopTk5O7N69mw4dOhAaGsquXbtYt24dtWvX5vvvv2f58uWlxn/w9vZW+ue//PLLXLhwgTNnztC2bVtiY2OVWj2VSoWXlxenT5/GwcEBGxsbDh8+TFBQEAC///67MhjhxYsXuX//PkVFRYSHh+Po6Mirr76Kqakpw4YNY86cOSxfvlwZ9flF/L2VdOXKFRYuXIijoyO+vr5A8TPD2LFjlbmAv/zyS1auXEm9evXw8/PDxMSE27dv4+fnh5GRkdI6r+R93cPDg8OHD1NQUICbmxs3btwgMDAQQ0NDoqOj8fT0JC0tjZ49ezJ+/Hh8fX3p2bMnK1euVGYHyMjIYPny5Rw9epS8vDzq1KnDe++9h4GBATVq1GDmzJkUFBTg4eHxhyPYPisSDCuIatWqcfToUb766isaNmzI/Pnz+b//+z8WLlxI/fr1lTmhzM3Nefvttzl79ixHjhxh0KBBADRs2LBUbYm/vz87d+6UUanK8OhF8qeffmL16tVKswD4T0n5k4YmNjIywtbWllatWrFq1SoAwsLC6NmzJ++99x6+vr5kZWUxb948EhMTcXNz4+jRoyQkJNCrVy8uXbrEsWPH+PHHH7G2tubgwYP88ssvxMfHK6POvvzyy5iYmADFg8oUFBTQsGFDLC0tsba2xs/Pj8GDB6PT6QgICGDmzJkYGxuTm5tL/fr1adq0KS1atCA9PR13d3e0Wi02Nja4uLgAYGxsTHR0NCkpKdSpU4e5c+eyc+dOoqKiGDx4MG3atFH2V9/WXn8De1JIKdnJ+89MsFtyPX1TnZLnSaVSKU0p3d3dUavVSu2dSqXi/PnzrF69muTkZDp27Mhbb72Fra0tV69eZerUqbz55pssXryYS5cuMWrUKHr06MG6detIS0tTRgktKxi6urri6urKzp07MTU1VS7cp0+fVkbc0+l0Sr8qOzs7zMzMMDc3L1XC/Nprryml+lZWVty5c4f8/HzeeecdfHx8yMjI4Pz58zg7O9O5c2flhm5gYEC/fv3o16/ff30sK7LExETu3btHSkoKVapUYcCAAQQFBXH27Fk8PT1RqVRKrWjTpk3JzMzkwIEDSgl8gwYNUKvVSukuQLdu3ejWrRtQdqGP+O/5+flx/Phx5b6hUqnYvn07kZGRDBw4EGdnZzIzM0lJSQHkHEHx/ty9e5ebN28SERFBfHw8np6edOrUCS8vL2WZp01XAxAaGsry5csJDw/Hz8+POXPmkJOTw9y5c5k6dSpWVlZ8//33DBkyhD59+gAotXa1atUiLy+P/Px8DA0NiYyMpFu3bhQVFaHRaGjTpo3SH8rFxYVLly4p3+vq6qoUtD0pGJqYmGBkZERcXBwNGzbE2tqahIQE4uLicHNzQ6vV0rp1a9zc3Dh16hQvvfQS/v7+VK1aVblum5iY8Oabb/71A14OPvjgA1auXKkMPlJQUEC/fv3YtWsXBQUFSguIVq1acfr0aaXpro+PT6n5O83NzbG0tFQKWszNzTl06BAdO3YEilui1KlTB0NDQ9566y2mT5+OjY0NaWlp/P7770yaNAko/l3u3LmTnJwcqlevzpAhQ3B2dgaKf8P6+3VlMWXKFDp16sTIkSOB4hpelUqlHP9bt26h1Wq5c+cO9+7dw8/PD41GU+oZwsLCAjs7O65evao0C42Li8Pa2hqdTke3bt0ICQnBxcWFFi1asGXLFoKCgrC1tcXDw4MxY8awfft2PvnkE3x8fJgyZQoajQZzc3Peeecd3n//fdzc3Eq1Hnvas1R5kmBYQbi5uZGYmEh8fDx169bl888/54svvqB///7Y29srJbc6nQ5fX1+WL19OdnY2VatWBWD48OHK+/r+bpUtFGq1WrKysp54c4PiUcB++eUXGjRooIz42rlzZzp37gz8JzSWDDXZ2dnKgCN6+uYcJacD0QcufUnq6tWrMTAwUEZevHLlCjNmzKBt27ZcvHiR1157TSktbNu2LQ4ODty6dYt69epha2tLZmYmqampuLq64uTkhIuLC6NGjVI6/JekLzhwd3fnypUr1K9fH3t7ex48eMDnn3+uNH1s1qwZr7/+OgD9+vXDwMBAKSHz9/dXRtJ60vH9o7D3tFLzks2sHq3hK7leWd+RmprKN998w/Xr1/H09MTS0lK5qF+/fp1ly5bRqlUrqlWrxo4dOzh9+jTr168nICCAKlWqULt2bQIDA3F0dOTo0aPK70bfrDE0NPSx7VapVDg5OWFoaKj8Tel/Xy1atOCzzz7j+PHjtGjRgjt37hAaGsrs2bOVwaRiY2OVeazUajUrVqwgJCSEu3fv0rZtW+rUqUO1atWA4iaVL7rCwkJu3rxJ586dlX7UAK+88gpffPEFR44coWvXrlhbWyvvtW3blvPnz1OlShV0Oh01a9Z86rQdL1LgKA9ubm5ERUVx4MABUlJSuHLlCgkJCbz77ru0adOGO3fuULVq1VI1PZX9HJ05c4YhQ4ZQo0YN/P39cXV1JSYmhuHDh9OvXz8GDx6s7POuXbsICQkhJyeHTp06MWTIECVwLViwgJYtWzJ27FiMjY0xMjLC2dkZR0dHcnJyMDIyIjExkbt37xIVFUV+fr5yz3F3d6egoID4+HhsbGwoLCwkIyND+S1ZWFhgYmJCXl4ejo6O5Ofnk56errxvZWVFTEwMPj4+j+1fUVERhoaGVK1aVSnA8/T0ZM2aNUoNln6wmurVqz82CM6LwMrKiv/7v/9j9uzZLFmyhNmzZwPFTaxL9v+sUqUKFhYWSqGgt7c36enpnDt3jkaNGmFqasrBgwcZNWoUlpaW9OrVizVr1pCQkEBsbCwpKSlKC58WLVqwcOFCduzYgbGxMe+++67S57Bhw4ZPDX8lR0d9WmHEi0A/lsarr74KFLfG0hdGrF69mm3btmFiYoKbm5syX7Ofnx8uLi7cu3evVC1dQEAAy5Ytw8/PD39/f44dO0ZgYCBqtZq33noLIyMjPvvsM8aOHUtQUBAjRoxQWk116dKFVq1alXr+1Ol0mJqalup/qFeRr4MSDCsIfX8k/Y/ZycmJadOmcffuXTw8PEqV4AJKSeSjKvIf2z8pOzub2bNnU7t2baV2RR9CSoYNExMTpk2bRnBwMK6ursr6qamp2NjYKMvt2rWLjRs3EhcXR/Xq1Vm5cuVjzSZtbGwoKipSmhrs3LmTzp074+TkBMCvv/5K9+7dOXr0KL/99hsxMTGEh4cTFxeHsbExeXl55ObmKp/r6uqqtDG3t7fnxo0bSnMsDw8PGjZsSHBwMGq1GgsLC86ePUtRUREDBw4kKSmJefPmkZSUhK2tLYMGDaJRo0bk5+fzwQcfKKVXelqtVmlyUZJ+dNSymmY+LRQ+Wmqek5NDu3btqF+/vrLMk0rMdTod9+/fV5qjBQcHU61aNUaOHImXlxf5+fmEhIRw6dIlevXqRVRUFJs3b2bEiBFA8SigDx48UApHfH196d+/P2FhYXh6emJmZqY8qNra2ioPToBS+6rvO/Po78fJyUkZPMbS0lJ538/Pjw8//JDVq1czY8YMtFot06ZNUx7UevXqhZWV1WODFPTq1euJx/BFp9VqycjIUH6f+t+mpaUl48ePZ/LkyY+tUzKUV9Zr27Ok0WhIS0vjs88+w8XFBX9/f7p27ar8jvUl4SVV9nPk5OSEj48PwcHBSmDOyMjgxx9/ZNGiRbRt2xZ3d3fOnTvH9u3b6dOnD05OTqxatYrU1FQmTpzImTNnyMrKYtCgQY8NMqUPhGq1msmTJxMcHMyQIUMwNzfH39+fMWPG4OHhgYWFBXfv3qVVq1a4ubkREhLCO++8A8DOnTsJCAhQzlV2djYxMTFKMDQzM+PWrVu0bNnysf3TX8P0g6ZAccull19+udRyL/q5t7S0pHbt2pw+fZozZ87w1ltvKYMyJSUl4eDggLGxMRcuXFDuW87OzhgZGbFq1SoiIyP5/fffcXFxoUmTJkBxgb6zszOHDx/G1taWDz/8EE9PT+U7GzZsqITBR/1RQeuLHgj1CgsLcXNzIzo6murVqyvNtU+ePMmpU6eYMWMGzZo1IykpiYEDByq1ubVr1+bUqVPs2bMHW1tb/P39sbOzIycnh/3799OrVy86dOhA3759geLfSO/evencuXOpwsuSLSAerZR4Xn8TEgwrCDMzM3bu3FnqNbVa/UKWvv0d9OGlsLAQIyMjzM3NmTdvXqllHg0yWq1WCU4LFiwgOzub5s2bM3ToUFq0aMG3335LvXr1OHHiBDt27GDo0KG89tpr3L59u8xQZGtrS3Z2NhMnTiQgIIDIyEhatGihhA5vb28WLVpEo0aNsLe3p0aNGqxZs0aZMP7y5ctcuXKFNm3aEB8fr/Q3A3B0dCQjI0MZOQ5gzJgxHD16lGXLlvHgwQN8fX3p0qULarWaxo0bExIS8lh4VavVpTpMPzrp/aPNup7UV++PlCw1r127Nlqtlk8++YTRo0fTqlUrZTqW48ePEx4ejo2NDf369cPT05OcnBy2bNlCSEgIb7/9Nv379+f8+fOMGTOG3bt38+DBA77++mvWr19PrVq1yMrKIjQ0VJke4tatWzRv3lzZHw8PD1xcXLh58ya1atXC2NiYxMREdDodarUaS0tLHjx4QF5eHiYmJmg0GrRaLampqaXCMxQ/DKSlpREVFUWtWrVKHa9BgwbRpEkT5TstLCyUbXj0oQme35vE30WtVpcq5S55PMqaT008eyYmJpw4caK8N+O54ubmRl5eHteuXaNhw4YYGBhgZWVFv379WLduHQcPHmTw4MF8+eWX9O3bl06dOgHFhX8DBgxg9OjR/P7777Ru3brUb0J/rdFPO5WVlUW1atWYMmWK0sUgKCgIf39/hg4dipubG3fu3KFVq1ZKszZ9zWJSUhKDBw/GyMgIa2trXn755VK/ue3btz927ROl5eTksG7dOiZNmsSGDRv45JNP+Pjjj3nllVeYNWsWXbp04d69e1hbW1NYWEhqairOzs64ubnRqVMnbt26RZUqVRg6dGipEWS7dOlCly5dnvi9TyqsrUzh72k0Gg329vbs37+ftm3bKpUoUVFRaLVaYmNjuX79Oj/++KPSZ3fIkCG8/vrr5Obm8umnn9KgQQNGjx6t1PL7+Pgwbty4x77L0NCwVCiEF/O+LndjUWHpQ0xZPzz9BfLRB8r09HQsLCwwMjLi4MGDfPPNN8TExGBoaMh3333HxYsXlblu3n77bZo2bYq1tTVeXl7cvn2bevXq8d133+Hj46NcrB9tFqW/YVtYWODh4cHo0aPp0KEDiYmJzJ49m5UrVzJr1ix8fX1p3769MlE8FDdzuH//Pu3bt+fSpUusXr2aqKgoEhMTqVq1qlJj6OzsXKpzvr5/QseOHZX+CI/SlzTrSxHLumk8Gvr+rouavtR8w4YN2Nrakpuby8cff8zPP/9Mq1atKCgoYNu2bcTGxuLp6UlqaipDhw5l165dWFpa4u7uTn5+Pl27dsXb25vWrVvTpEkT4uPj0el05OXlUaNGDaC4WZR+FN+ioiIsLS1JSUkhNzdXeWDKyspS9s3Ozo6EhASKioqUvqGJiYmkp6fj6OiIiYkJqampxMbGotFoSoU/FxcX1qxZowxy8+jx0m/TP3FMhRAVn4mJCaampqSkpCjXXH3zy+rVqyvX9OjoaHbv3k1ISAjR0dHk5uby4MEDcnNzsba25sGDB2RlZWFjY1PqGu7s7MyDBw/Q6XTKCMpubm7ExsZSs2ZNJdBZWVkRHh4OwBtvvIGXlxcHDx7EzMyMwYMH4+/vDxSPZ/Bo7bx+kDHxZEuWLKFBgwZ06tSJoKAghg4dysKFC5k+fTohISF8/vnnNGvWjFatWhEREaHMM6wf8fVp9LVcZXWl+F8LaysLQ0NDevfuzdKlS5k8eTLm5ubExcXRvHlzBg4cyNy5czE0NKRbt258/vnnykiv9vb2jBw5UumXKP5DgqEoF3l5eRQUFDx1VMsnXQwTEhK4evUqXl5eyqAh7du3Z8OGDZw7d04Z4OPXX3+lRYsWdOrUiZSUFFQqFZ07dyYsLIz8/PxSHeHd3d25ceMGUBzC9KVC+hrJkvQP/hYWFsoEth06dMDR0ZG+ffuydOlSfv75ZwYPHszcuXP58MMP8ff3V5pY9ujRg7Zt2zJ27Fh27tzJ0aNH6dChA4GBgcyZMweA6tWrKx3NS36n3v/a5POfoi81j4uLw9bWVnlQ0jfXNTU1pUOHDsrobFA8IMWhQ4fo2rUrGo1G6UsJxc10q1Spws2bN/H398fS0pLo6OhSI46lp6eTnp5OmzZtmDBhAocPH6Zjx46Eh4eTk5OjNOs0MTEhIiKCgoICjIyMsLe3JyMjQ7lB1KpVi3nz5imfXfJYm5qaPrEpjxBCQHHh071795RAqB9Ay9DQkJycHHQ6He7u7uTm5jJw4EAcHBzw9fVV7n8tWrRgyZIlbNu2jXfeeQcDAwPCwsKoVasWDg4OHDlyhJycHNLT01m4cCGRkZGYm5vTu3dv2rVrB8D8+fNL9YV/6aWXeOmll8rleLxo0tLSuH79OsOGDQOK5wFetmwZJiYmODo6MmrUKEaNGgXA4sWLycjIUFr/6KcxUalUFBUVlXnPlpq/v6ZRo0YsWbKETZs2kZeXR+fOnWnatCl2dna0bdu2vDfvuSPBUJSLoUOHEhQUxKhRo8psRhYXF0dYWBgGBgY0adJEuYGeP3+e+fPnk5ubS9u2bVm1ahW9evWiffv2ODg4KDflyMhIYmNjee2113B3d1cmaQeUAUj0U1RA6YnEvby8uHbtGvCf0TLLGnjF3NwcjUZTam6uJk2aEB0dzZQpUzh+/DizZs1iy5YtXL9+HS8vLxo2bKiEI0tLSwYOHMjAgQMBWLBggdJJueTcQ0+qMa1IpYgmJiaYmZmxf/9+zpw5w5UrV8jMzGTAgAHKMnXr1uXw4cMcPHiQhIQEbty4oUzebGtri6WlJXfu3CEgIAAorq2LjIykZcuWuLi4sHnzZqV/04ULF4iLiyM2NpY6derQpUsXtm7dyldffUVGRgYjRoxQAt2AAQNQq9VKjWrJbdLpdGg0GmlGJYT4n7m7uxMbG6tM86Ef0CIzMxNbW1tUKhX16tUjJiaGunXrKjV0J0+exNbWlkaNGtG7d2/27t3L7t27uX//Pq1bt2bu3LkEBQVhYWGBmZkZtWvX5quvvlLGJChJH0TE38/W1paNGzcC/2nJpB+oJzU1lRs3bpCbm8vdu3c5f/48b7zxBqampqUGAwRpMv9PcnJy4oMPPijvzXghyF+pKBd+fn6kp6crzfvgP000jxw5wtKlSzEzM8PQ0JCTJ08yfPhw3NzcCA4OplatWsyaNYvExEQuXrzIvXv3gOLAV1BQwP3792nQoAFt2rRh48aNzJs3D2dnZ/r06UOnTp3w8/Pj+++/Jy8vT9meatWq8euvvwLQpk0bfv75Z3bu3EmPHj1ISUnh999/LzV9AxSHIQcHh1IT/apUKnr06EGzZs2UMKsvZSzLunXrMDAw4NatW1y9epXp06eX+qzniZeXFzt37iQoKAgrKytSU1OJj49Xgt7u3bv54Ycf8PHxYfDgwVhbW5OYmEhubi42NjaYm5uXWt7Pz0+pxR09ejSbN2+mZ8+emJmZ4eTkhEajUY79+++/T3h4OA8ePFBGHNPTj1ZWluftGAshKh4fHx9CQ0NL1ditWbOG6OhoZUqp/v37s3v3bsaNG0diYiKpqanKPKUA3bt3p2HDhiQnJ+Pu7q6MFh0YGEhgYKDyuY8OTiOenZIFxPrnFTMzM65du8bmzZtxdXWle/fuvPHGG4DcX8TzSYKhKBdeXl6cPXtWGQBEf5GNjY0lODiY9u3b895773Hr1i3mz5/P1q1bGTp0KHl5ecrIaY6OjvTv318ZdMbR0REDAwPu3btH06ZNGTJkCA0aNMDQ0JCbN28yd+5cAgIC8PPz4+HDh8pIlFA8UEzJebimTJnCpk2b+Pzzz8nLy6NDhw6PBUNjY2OGDBny2L4ZGxuXGvCl5NDR+j4E+v3NysoiPDwcLy8vJk2aRL169f7eA/0MWVlZ8cYbbzBhwgQANm7cyNatW1Gr1bRo0YJt27bh4eHBv//9bwA2b95MUlIS2dnZymhe165dU4Kct7e3Mldgq1at8PLy4vz583h6elKrVi0leOtHZdPPJSWEEM+St7c3mzZtYtWqVSQkJHDz5k2MjY35+OOPefXVVykqKsLR0ZFhw4bRqFEjoHjKB1tb21Kf4+HhUSHnNRPFyppiyczMjCFDhpT5LCDE80iCoSgXPj4+/PTTT+Tk5GBlZaUEpeTkZBITE+nevTtQXGvUqVMnvv76a0aNGsXDhw9LlcL5+vqSlpZGbm4uGo0GExMTMjIyAJRmhlDc0djY2Jj8/Hw8PT1p2bIlEydOpLCwkDfffJOOHTsqQ0yr1Wqlz5+xsXGpiZrL8kcTNpc1eph++TFjxvz5g1dB+fr6cvnyZaWJ7sCBA7l79y4bNmygSZMmtGzZkn379jFz5kwePnyoDKiTkpKCr68v7dq1U/oYQnEtYMk5hry9vZVBYEqSUlkhRHny9/fH0dGRS5cu4e3tTc+ePalfv74S8vTXfwMDg1L9rIUQoqKRYCjKhbe3N5mZmWRmZuLk5KQ83Ds5OREXF1cqSHl6evLgwQPUajXOzs5cvHhRqVU6ffo0BQUFJCYm4unpiampKYmJiQAcO3aMgwcPEh0dTV5eHr169VKm/xg9ejTnzp3DxsaG2rVrY2lpyf79+5Xv1Ol0pfpsPC38STAp5uXlxe7du5XpOgB69+7NnDlzWL9+PSNGjMDMzIzIyEhat25NgwYNsLKyUoaX7tOnT6nPKxkKhRCiovLw8CAkJKS8N0MIIf4yCYaiXLi5uVFUVERqaqoyNDcUDzhiZ2fHqVOn6Nq1KwBHjx6ldu3ayhQTH330Ea6urhgbGyv9C+Pj4/H09MTR0RFjY2MKCgpo3LgxGo0GBwcHfHx8Sg0wotFo6NChQ6ltKtl/4NGwJ+Hvj1WtWhUvL69Sx6p69eqsW7euzIFfhBBCCCFExSHBUJQL/SiW2dnZj42uOWDAANavX09OTg5FRUWcPXuWsWPHYmhoSMOGDZk9ezbBwcFkZWUxY8YM9u/fT1paGkCpUan8/PyUUT7L8uionxVplM/nkZ+fHytWrCj1mkqlksEShBBCCCGeAxIMRbmxtbVl9+7dhIaGcuvWLcLCwggMDGTKlCm4ubmxdetWDAwMGDhwIEFBQcp6LVu2VAagSUhIwNTUVAl1+qGk9WHvaVM+SC2gEEIIIYQQxVQ6/ZOzEM/Y8uXL2bdvHy4uLlSvXp1q1arx0ksvlTnASElhYWGEhoZiYWHB999/j7OzM5MmTVJGthRCCCGEEEL8ORIMRYWl1WqVGkBDQ0NlAJirV68yb948VCoVDRo0oHv37spks0IIIYQQQog/T4KhKFdFRUVK4Cv5nxBCCCGEEOLZkWAohBBCCCGEEJWcDMMohBBCCCGEEJWcBEMhhBBCCCGEqOQkGAohhBBCCCFEJSfBUAghhBBCCCEqOQmGQggh/naxsbHUqFGDSZMmlfemPOaLL76gRo0anD179rH39uzZQ7du3ahXrx41atRg7ty5ALRp04Y2bdo8602t0Hbu3EmNGjXYuXPnX/qcp50PIYQQz45ReW+AEEKI58OtW7fYtGkTZ8+eJT4+nry8PGxsbAgICKBdu3a88cYbqNXq8t7M/9nly5cZN24cHh4evP3225iZmVG3bt3y3iygOGi/+uqrAJibm3P8+HEsLS0fW06n09GuXTtiYmIA2LhxI40bN36m2yqEEOL5JMFQCCHEH1q+fDlffvklWq2WevXq0b17d8zNzUlOTubcuXP8+9//ZvPmzX+59uhZ6NevH506dcLV1bXU60eOHEGn07FgwQLq169f6r0NGzY8wy18MiMjI7Kzs/npp5/o3bv3Y++fPn2amJgYjIyMKCwsLIctFEII8bySYCiEEOKpvvrqK7744gtcXFxYunRpmbVohw8f5uuvvy6HrfvzNBoNGo3msSLECQQAAAypSURBVNcTExMBcHR0fOw9z/9v715jmjzfB45/EcpUVDw1FVoPi06pGhMQEYWhMoSBcxrksBAzmWNiAB2JixNddDPTvZnbjGBGY0YUBYFYccoCWz0xBFScGkUbT0MEAlMZB09Qlf8L08auUHTib/mH6/Om5Lmv+/A8JSEX9+EZNeq1j+tFTJo0ibq6OnJzcztNDHNzc3F2dsbX15fi4uL/YIRCCCH+v5LEUAghRJdqampITU1FoVCg0+kYP358p3Fz5szBz8+v2/b+/PNP9u3bR2lpKXV1ddy7dw+lUom/vz+JiYmMGDHCKr6jo4P8/HxycnKoqqri/v37DB06lHHjxrFo0SLCwsIssUajEZ1Ox7lz5/jrr78YMGAAbm5ueHt7s3r1ahQKBfBsT1tqaqplmaVeryclJcXSjnnJJsDhw4fRaDSW/YVHjhyxuadDhw6Rk5PD5cuXaWtrQ6PRMH/+fOLi4myW1k6YMAEfHx++++47fvjhB4qLi7lz5w6bNm0iPDy82+fn6OhIeHg46enpGI1GPDw8LGWNjY0YDAZCQkJwcHDoso2LFy+Snp5ORUUFra2tKJVKZs2aRUJCQqdJ8c2bN9myZQtlZWWYTCY8PDxYvny53XHW19ej0+k4fvw4DQ0NuLi44OnpSUJCAlOmTOn2PgEqKirYsWMHly5dorGxEVdXV9RqNQEBASQlJb1QG0IIIV6cJIZCCCG6pNfrMZlMzJs3r8uk0OxF9hf+9ttv7N27l+nTp+Pl5YVCoeDq1avk5eVx9OhR9u3bh0qlssR///33pKeno9FoCA0NZeDAgdy+fZsLFy5QWFhoSQyNRiNRUVE4ODgQGBiIRqPh3r17VFdXk52dTXJysiUx/CetVktSUhIGgwGj0ciHH37IoEGDACyfXUlJSUGv1zNixAiCg4MZNGgQ586dY+vWrZSVlZGRkYGTk/Wf2qamJqKjo+nfvz/BwcE4ODgwbNiwbp+dWWRkJDqdjtzcXNavX2+5np+fj8lkIioqiry8vE7rHj16lBUrVgAQEhKCu7s7lZWVZGdnc/jwYbKyshg5cqQlvqqqiujoaJqamggICECr1XLz5k0SExN5++23O+2jsrKSpUuX0tzcjL+/P8HBwfz9998YDAZiYmJIS0tj1qxZdu+xuLiY+Ph4BgwYQGBgICqViqamJm7cuEFWVpYkhkII8RpIYiiEEKJLZ86cAWDGjBk90t6CBQuIjY21SSJLSkr45JNP2L59O1999ZXlek5ODiqVikOHDtGvXz+rOo2NjZaf8/PzaWtrIy0tjaCgIKu45uZmm7rP02q1aLVaamtrMRqNLFmyBI1G0+296PV69Ho9c+fO5dtvv6Vv376WMvOs5J49e1iyZIlVvStXrrBgwQI2b95skzS+iJEjR+Lr68vBgwdZvXq1pd+8vDzGjBnD9OnTO00M79+/z5o1a3jy5AmZmZl4e3tbynQ6HVu2bGHDhg1WS4I3btxIU1MTa9eutboPg8FAYmKiTR+PHz8mOTmZBw8esGvXLnx8fCxlDQ0NREREsG7dOo4cOWL3Hwl5eXk8ffqUzMxMq1lRsP7ehRBC9Bx5XYUQQogu3b59G8BqFu9VqFSqThMCf39/xo0bR0lJiU2Zk5MTjo6ONtc72yf4fHJm5urqSp8+Pf/nbteuXTg5ObF582abfhMSEhg8eDAHDx60qadQKPj888//VVJoFhUVRUtLC4WFhcCzZZc3btwgIiKiyzqHDx+mqamJsLAwq6QQYOnSpajVak6cOEFdXR3wbDnoiRMn0Gg0LF682Co+KCjIKukzO3bsGNXV1SxevNimXKVSERcXx+3btykrK3uh+3zjjTdsrnX2vQshhHh1MmMohBDif6ajo4Off/6Z/fv3YzQaaWlp4cmTJ5byfy73nD9/PpmZmYSFhREaGsq0adPw9PRk4MCBVnFhYWHs2rWLxMREQkJCmDlzJl5eXq/t0JiHDx9iNBoZMmQIO3fu7DTG2dmZ69ev21xXq9UvtXS0M0FBQQwZMoTc3FwWLlxITk4OCoXC7j7FS5cuAeDr62tT5uTkxLRp06itreXSpUu4u7tb4qdOndppYu7j48OpU6esrp07dw6Auro6tm3bZlOnqqoKePbqE3vLSefPn8+vv/5KVFQUoaGh+Pr64uXlZbMHVQghRM+RxFAIIUSXlEol169fp6GhoUfa++abb9i5c6flwBmVSmWZbdu/fz+1tbVW8SkpKWg0GvR6PTqdDp1Oh5OTEwEBAaxZs4bRo0cDMGXKFPbs2cOPP/5IUVERBw4cAODNN98kKSmJ9957r0fGb9bS0kJHRweNjY2kpqa+VF2lUvnK/Ts7O7Nw4UIyMjI4e/YsRUVFBAYG2k04W1tb7fZvvm6OM3921ebw4cNtrjU1NQFYZjK78uDBA7vlwcHBpKen89NPP6HX68nJyQGencq6atWqFzroSAghxMuRxFAIIUSXpk6dSnl5OeXl5URGRr5SW3fv3iUzM5Px48eTnZ1t84L2Q4cO2dRxdHQkNjaW2NhY7t69y5kzZygoKKCwsJBr165RUFBgWZrq6elJeno67e3tXLx4kd9//53du3ezatUqhg4dysyZM19p/M8zj33ixIns37//peraOzH0ZURGRpKRkUFycjJtbW1ERUXZjTfPspqXB/+T+bo5zvx59+7dTuPv3LnTZR/bt2+3Ot3135g9ezazZ8/mwYMHnD9/nmPHjpGdnU18fDz5+fmMGzfuldoXQghhTfYYCiGE6FJ4eDgKhYKioiKuXbtmN7a9vd1u+a1bt3j69Cl+fn42SWF9fT01NTV26w8bNozg4GC2bt2Kr68v1dXVXLlyxSbO2dkZLy8vPv30U9atWwc821/Xk1xcXHjrrbe4evWqZZbsf23s2LF4e3tTX1+PWq3udhZNq9UC2Cz/hGeHxlRUVADPkt3nP8+cOWO13Ness3bM77g0t9UT+vfvz4wZM0hJSSE+Ph6TySTvaBRCiNdAEkMhhBBd0mg0JCUlYTKZWLZsGRcuXOg0rri4mLi4OLttqdVqwDbRuH//Pl988QWPHz+2im9vb7ecivo8k8lEc3MzgOW00T/++INHjx7ZxJpnuzo7lOZVxcbGYjKZWLt2LS0tLTblzc3NVFZW9ni/z9u4cSNpaWmkpqZ2OxMZFBTE4MGDKSgosOwFNNu5cyc1NTXMnDkTd3d3AEaMGIGfnx81NTXs3r3bKt5gMHSaGL7zzjuMGjWKrKwsjh8/3uk4zp49y8OHD+2O9fTp0za/D/B6v08hhOjtZCmpEEIIu5YvX87jx49JS0sjIiICT09PJk+ejIuLC3fu3KGiooKqqiomT55stx2lUsm8efMoKChg4cKF+Pn50draSmlpKc7Ozmi1Wi5fvmyJf/ToETExMYwePZpJkybh7u5OW1sbpaWlXL9+ncDAQMaOHQvAjh07KC8vx9vbG41GQ//+/bl27RrFxcW4uroSHR3d488lIiKCyspKsrKymDt3Lv7+/ri5udHc3ExNTQ2nT58mPDycjRs39njfZmPHjrU8g+64uLiwadMmkpOTWbx4Me+++67lPYYlJSUolUqbsa5fv57o6Gg2b97MiRMn8PDw4ObNmxgMBubMmcPRo0et4hUKBdu2bSMuLo5ly5bh6emJVqulb9++1NfXc+HCBW7dukVJSYndV4h8/fXXNDQ04OXlhVqtRqFQUFlZSXl5OWq1mnnz5r38wxJCCGGXJIZCCCG6lZSURGhoKFlZWZw8eRK9Xk97ezuDBw/Gw8ODuLg4FixY0G07mzZtYuTIkfzyyy/s2bOHoUOHEhgYyMqVK1m5cqVVbL9+/fjss884efIkZ8+exWAw4OLiwqhRo/jyyy9ZtGiRJTYmJgZXV1fOnz9vmZFUqVTExMTw0UcfWWYre9qGDRsICAhg7969lJaW0traiqurK25ubnz88ce8//77r6XffysoKIisrCzS09MpKSnh3r17DB8+nA8++ICEhASb15KMGTOG3NxctmzZQmlpKadOnWLChAmkpaXR2NhokxgCeHh4cODAATIyMjh27Bh6vZ4+ffqgVCqZOHEiK1asYMiQIXbHGR8fj8Fg4OLFi5SVleHg4IC7uzvLly9nyZIluLq69uhzEUIIAQ4dHR0d//UghBBCCCGEEEL8d2SPoRBCCCGEEEL0cpIYCiGEEEIIIUQvJ4mhEEIIIYQQQvRykhgKIYQQQgghRC8niaEQQgghhBBC9HKSGAohhBBCCCFELyeJoRBCCCGEEEL0cpIYCiGEEEIIIUQvJ4mhEEIIIYQQQvRykhgKIYQQQgghRC/3f6/SRNyxP8JlAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ArLD9V0B6eE0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}