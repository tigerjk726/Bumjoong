{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOcbaSzu/JgMP7cITn7sMAk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tigerjk726/Bumjoong/blob/main/machine_learning_application_intensity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CpbByZRippYp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf3c0f66-df6a-45d2-d2ea-d85145a97299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')             "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/2022.10.10 typhoon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5TfSj0PfYtT",
        "outputId": "8d2b3078-af2d-4c56-f326-604199b50a4e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/2022.10.10 typhoon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('summary2.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "iVlFBZkefbk2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "fc4f886a-4090-42b4-fccd-378ecf86e87a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       DATE  MON        AAO    AMO         AO    EMI    GMT  NINO3  NINO4  \\\n",
              "0    198001    1   2468.847 -0.251 -13914.348  0.468 -0.008  0.362  0.318   \n",
              "1    198002    2   5287.235 -0.265  -7920.162  0.573  0.048  0.025  0.311   \n",
              "2    198003    3  18067.714 -0.343  -9798.327  0.417  0.005 -0.153  0.166   \n",
              "3    198004    4  23780.651 -0.064  -4271.158  0.394  0.035 -0.189  0.107   \n",
              "4    198005    5   3995.642  0.046  -8602.326  0.369  0.072 -0.155  0.201   \n",
              "..      ...  ...        ...    ...        ...    ...    ...    ...    ...   \n",
              "487  202008    8   8954.542  0.263  -1599.950 -0.229  0.320 -0.558 -0.237   \n",
              "488  202009    9   4960.132  0.135   4138.498 -0.207  0.435 -0.918 -0.463   \n",
              "489  202010   10 -10689.321  0.129    662.580 -0.377  0.416 -1.043 -0.695   \n",
              "490  202011   11 -13940.175  0.026  16778.709 -0.441  0.519 -1.136 -0.792   \n",
              "491  202012   12 -17119.479  0.039 -10766.470 -0.641  0.307 -0.805 -0.898   \n",
              "\n",
              "       PDO    PNA     QBO  FREG  INTEN  \n",
              "0    0.688 -0.787  -1.147     0    0.0  \n",
              "1    1.233  1.002   3.094     0    0.0  \n",
              "2    1.107 -0.539   5.553     0    0.0  \n",
              "3    1.255  1.457  11.231     0    0.0  \n",
              "4    1.204  0.377  18.477     0    0.0  \n",
              "..     ...    ...     ...   ...    ...  \n",
              "487 -1.413 -0.156  20.514     2   67.5  \n",
              "488 -1.137  0.402  20.357     2   90.0  \n",
              "489 -0.612 -0.943  19.270     0    0.0  \n",
              "490 -1.451 -0.402  18.811     0    0.0  \n",
              "491 -0.919  0.988  16.446     0    0.0  \n",
              "\n",
              "[492 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b8f67cf-f923-429c-a6c6-022104ab584a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DATE</th>\n",
              "      <th>MON</th>\n",
              "      <th>AAO</th>\n",
              "      <th>AMO</th>\n",
              "      <th>AO</th>\n",
              "      <th>EMI</th>\n",
              "      <th>GMT</th>\n",
              "      <th>NINO3</th>\n",
              "      <th>NINO4</th>\n",
              "      <th>PDO</th>\n",
              "      <th>PNA</th>\n",
              "      <th>QBO</th>\n",
              "      <th>FREG</th>\n",
              "      <th>INTEN</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>198001</td>\n",
              "      <td>1</td>\n",
              "      <td>2468.847</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>-13914.348</td>\n",
              "      <td>0.468</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.362</td>\n",
              "      <td>0.318</td>\n",
              "      <td>0.688</td>\n",
              "      <td>-0.787</td>\n",
              "      <td>-1.147</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>198002</td>\n",
              "      <td>2</td>\n",
              "      <td>5287.235</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>-7920.162</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.311</td>\n",
              "      <td>1.233</td>\n",
              "      <td>1.002</td>\n",
              "      <td>3.094</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>198003</td>\n",
              "      <td>3</td>\n",
              "      <td>18067.714</td>\n",
              "      <td>-0.343</td>\n",
              "      <td>-9798.327</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.153</td>\n",
              "      <td>0.166</td>\n",
              "      <td>1.107</td>\n",
              "      <td>-0.539</td>\n",
              "      <td>5.553</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>198004</td>\n",
              "      <td>4</td>\n",
              "      <td>23780.651</td>\n",
              "      <td>-0.064</td>\n",
              "      <td>-4271.158</td>\n",
              "      <td>0.394</td>\n",
              "      <td>0.035</td>\n",
              "      <td>-0.189</td>\n",
              "      <td>0.107</td>\n",
              "      <td>1.255</td>\n",
              "      <td>1.457</td>\n",
              "      <td>11.231</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198005</td>\n",
              "      <td>5</td>\n",
              "      <td>3995.642</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-8602.326</td>\n",
              "      <td>0.369</td>\n",
              "      <td>0.072</td>\n",
              "      <td>-0.155</td>\n",
              "      <td>0.201</td>\n",
              "      <td>1.204</td>\n",
              "      <td>0.377</td>\n",
              "      <td>18.477</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>202008</td>\n",
              "      <td>8</td>\n",
              "      <td>8954.542</td>\n",
              "      <td>0.263</td>\n",
              "      <td>-1599.950</td>\n",
              "      <td>-0.229</td>\n",
              "      <td>0.320</td>\n",
              "      <td>-0.558</td>\n",
              "      <td>-0.237</td>\n",
              "      <td>-1.413</td>\n",
              "      <td>-0.156</td>\n",
              "      <td>20.514</td>\n",
              "      <td>2</td>\n",
              "      <td>67.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>202009</td>\n",
              "      <td>9</td>\n",
              "      <td>4960.132</td>\n",
              "      <td>0.135</td>\n",
              "      <td>4138.498</td>\n",
              "      <td>-0.207</td>\n",
              "      <td>0.435</td>\n",
              "      <td>-0.918</td>\n",
              "      <td>-0.463</td>\n",
              "      <td>-1.137</td>\n",
              "      <td>0.402</td>\n",
              "      <td>20.357</td>\n",
              "      <td>2</td>\n",
              "      <td>90.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>202010</td>\n",
              "      <td>10</td>\n",
              "      <td>-10689.321</td>\n",
              "      <td>0.129</td>\n",
              "      <td>662.580</td>\n",
              "      <td>-0.377</td>\n",
              "      <td>0.416</td>\n",
              "      <td>-1.043</td>\n",
              "      <td>-0.695</td>\n",
              "      <td>-0.612</td>\n",
              "      <td>-0.943</td>\n",
              "      <td>19.270</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>202011</td>\n",
              "      <td>11</td>\n",
              "      <td>-13940.175</td>\n",
              "      <td>0.026</td>\n",
              "      <td>16778.709</td>\n",
              "      <td>-0.441</td>\n",
              "      <td>0.519</td>\n",
              "      <td>-1.136</td>\n",
              "      <td>-0.792</td>\n",
              "      <td>-1.451</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>18.811</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>202012</td>\n",
              "      <td>12</td>\n",
              "      <td>-17119.479</td>\n",
              "      <td>0.039</td>\n",
              "      <td>-10766.470</td>\n",
              "      <td>-0.641</td>\n",
              "      <td>0.307</td>\n",
              "      <td>-0.805</td>\n",
              "      <td>-0.898</td>\n",
              "      <td>-0.919</td>\n",
              "      <td>0.988</td>\n",
              "      <td>16.446</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>492 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b8f67cf-f923-429c-a6c6-022104ab584a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b8f67cf-f923-429c-a6c6-022104ab584a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b8f67cf-f923-429c-a6c6-022104ab584a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "glKsDQFEf1Xf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc2fc69-7ec6-4fa4-c675-f7fbb876ff32"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['DATE', 'MON', 'AAO', 'AMO', 'AO', 'EMI', 'GMT', 'NINO3', 'NINO4',\n",
              "       'PDO', 'PNA', 'QBO', 'FREG', 'INTEN'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns = ['DATE','FREG','INTEN']) # \"X\"라는 변수에 날짜, 횟수와 강도를 제외하고 지정\n",
        "y = df['FREG']\n",
        "y2 = df['INTEN']\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "twU6qwFEHhP5",
        "outputId": "d8d3c9dd-e93f-4cee-971b-905a2f02c8e1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     MON        AAO    AMO         AO    EMI    GMT  NINO3  NINO4    PDO  \\\n",
              "0      1   2468.847 -0.251 -13914.348  0.468 -0.008  0.362  0.318  0.688   \n",
              "1      2   5287.235 -0.265  -7920.162  0.573  0.048  0.025  0.311  1.233   \n",
              "2      3  18067.714 -0.343  -9798.327  0.417  0.005 -0.153  0.166  1.107   \n",
              "3      4  23780.651 -0.064  -4271.158  0.394  0.035 -0.189  0.107  1.255   \n",
              "4      5   3995.642  0.046  -8602.326  0.369  0.072 -0.155  0.201  1.204   \n",
              "..   ...        ...    ...        ...    ...    ...    ...    ...    ...   \n",
              "487    8   8954.542  0.263  -1599.950 -0.229  0.320 -0.558 -0.237 -1.413   \n",
              "488    9   4960.132  0.135   4138.498 -0.207  0.435 -0.918 -0.463 -1.137   \n",
              "489   10 -10689.321  0.129    662.580 -0.377  0.416 -1.043 -0.695 -0.612   \n",
              "490   11 -13940.175  0.026  16778.709 -0.441  0.519 -1.136 -0.792 -1.451   \n",
              "491   12 -17119.479  0.039 -10766.470 -0.641  0.307 -0.805 -0.898 -0.919   \n",
              "\n",
              "       PNA     QBO  \n",
              "0   -0.787  -1.147  \n",
              "1    1.002   3.094  \n",
              "2   -0.539   5.553  \n",
              "3    1.457  11.231  \n",
              "4    0.377  18.477  \n",
              "..     ...     ...  \n",
              "487 -0.156  20.514  \n",
              "488  0.402  20.357  \n",
              "489 -0.943  19.270  \n",
              "490 -0.402  18.811  \n",
              "491  0.988  16.446  \n",
              "\n",
              "[492 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a074b850-8011-4585-a1c8-edef244ae4a0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MON</th>\n",
              "      <th>AAO</th>\n",
              "      <th>AMO</th>\n",
              "      <th>AO</th>\n",
              "      <th>EMI</th>\n",
              "      <th>GMT</th>\n",
              "      <th>NINO3</th>\n",
              "      <th>NINO4</th>\n",
              "      <th>PDO</th>\n",
              "      <th>PNA</th>\n",
              "      <th>QBO</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2468.847</td>\n",
              "      <td>-0.251</td>\n",
              "      <td>-13914.348</td>\n",
              "      <td>0.468</td>\n",
              "      <td>-0.008</td>\n",
              "      <td>0.362</td>\n",
              "      <td>0.318</td>\n",
              "      <td>0.688</td>\n",
              "      <td>-0.787</td>\n",
              "      <td>-1.147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>5287.235</td>\n",
              "      <td>-0.265</td>\n",
              "      <td>-7920.162</td>\n",
              "      <td>0.573</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.311</td>\n",
              "      <td>1.233</td>\n",
              "      <td>1.002</td>\n",
              "      <td>3.094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>18067.714</td>\n",
              "      <td>-0.343</td>\n",
              "      <td>-9798.327</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.005</td>\n",
              "      <td>-0.153</td>\n",
              "      <td>0.166</td>\n",
              "      <td>1.107</td>\n",
              "      <td>-0.539</td>\n",
              "      <td>5.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>23780.651</td>\n",
              "      <td>-0.064</td>\n",
              "      <td>-4271.158</td>\n",
              "      <td>0.394</td>\n",
              "      <td>0.035</td>\n",
              "      <td>-0.189</td>\n",
              "      <td>0.107</td>\n",
              "      <td>1.255</td>\n",
              "      <td>1.457</td>\n",
              "      <td>11.231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>3995.642</td>\n",
              "      <td>0.046</td>\n",
              "      <td>-8602.326</td>\n",
              "      <td>0.369</td>\n",
              "      <td>0.072</td>\n",
              "      <td>-0.155</td>\n",
              "      <td>0.201</td>\n",
              "      <td>1.204</td>\n",
              "      <td>0.377</td>\n",
              "      <td>18.477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>8</td>\n",
              "      <td>8954.542</td>\n",
              "      <td>0.263</td>\n",
              "      <td>-1599.950</td>\n",
              "      <td>-0.229</td>\n",
              "      <td>0.320</td>\n",
              "      <td>-0.558</td>\n",
              "      <td>-0.237</td>\n",
              "      <td>-1.413</td>\n",
              "      <td>-0.156</td>\n",
              "      <td>20.514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>9</td>\n",
              "      <td>4960.132</td>\n",
              "      <td>0.135</td>\n",
              "      <td>4138.498</td>\n",
              "      <td>-0.207</td>\n",
              "      <td>0.435</td>\n",
              "      <td>-0.918</td>\n",
              "      <td>-0.463</td>\n",
              "      <td>-1.137</td>\n",
              "      <td>0.402</td>\n",
              "      <td>20.357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>10</td>\n",
              "      <td>-10689.321</td>\n",
              "      <td>0.129</td>\n",
              "      <td>662.580</td>\n",
              "      <td>-0.377</td>\n",
              "      <td>0.416</td>\n",
              "      <td>-1.043</td>\n",
              "      <td>-0.695</td>\n",
              "      <td>-0.612</td>\n",
              "      <td>-0.943</td>\n",
              "      <td>19.270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>11</td>\n",
              "      <td>-13940.175</td>\n",
              "      <td>0.026</td>\n",
              "      <td>16778.709</td>\n",
              "      <td>-0.441</td>\n",
              "      <td>0.519</td>\n",
              "      <td>-1.136</td>\n",
              "      <td>-0.792</td>\n",
              "      <td>-1.451</td>\n",
              "      <td>-0.402</td>\n",
              "      <td>18.811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>12</td>\n",
              "      <td>-17119.479</td>\n",
              "      <td>0.039</td>\n",
              "      <td>-10766.470</td>\n",
              "      <td>-0.641</td>\n",
              "      <td>0.307</td>\n",
              "      <td>-0.805</td>\n",
              "      <td>-0.898</td>\n",
              "      <td>-0.919</td>\n",
              "      <td>0.988</td>\n",
              "      <td>16.446</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>492 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a074b850-8011-4585-a1c8-edef244ae4a0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a074b850-8011-4585-a1c8-edef244ae4a0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a074b850-8011-4585-a1c8-edef244ae4a0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['INTEN'] = df['INTEN'].astype(int)\n",
        "y2 = df['INTEN']\n",
        "y2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cwI7DXz1WuR",
        "outputId": "baffd383-8ed3-49cf-eab4-51ab6a7c9605"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "487    67\n",
              "488    90\n",
              "489     0\n",
              "490     0\n",
              "491     0\n",
              "Name: INTEN, Length: 492, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "machine learning application"
      ],
      "metadata": {
        "id": "mfyTOpZh2Smj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,y2,test_size=0.3)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "eNB5zQbP2kJy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "#Fit the model\n",
        "model.fit(x_train, y_train)\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "mylist = []\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "# accuracy score\n",
        "acc_logreg = accuracy_score(y_test, y_pred)\n",
        "\n",
        "mylist.append(acc_logreg)\n",
        "print(cm)\n",
        "print(acc_logreg,'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9K3AH-k2Qw1",
        "outputId": "66303e0e-242f-4a29-9ba3-464669ed791e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[127   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  4   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8581081081081081 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "list1 = []\n",
        "for neighbors in range(1,5):\n",
        "    classifier = KNeighborsClassifier(n_neighbors=neighbors, metric='minkowski')\n",
        "    classifier.fit(x_train, y_train)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    list1.append(accuracy_score(y_test,y_pred))\n",
        "plt.plot(list(range(1,5)), list1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "S0nQeVDy29x9",
        "outputId": "fb27df66-60e7-4a4a-d59d-816ce6c784a0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = KNeighborsClassifier(n_neighbors=3)\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc_knn = accuracy_score(y_test, y_pred)\n",
        "mylist.append(acc_knn)\n",
        "print(cm)\n",
        "print(acc_knn,'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP35Xt253QPP",
        "outputId": "4cf0bb27-7730-4ea0-cc38-b986fbb2a335"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[126   0   0   0   0   0   0   1   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  4   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8513513513513513 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DecisionTreeClassifier\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "list1 = []\n",
        "for leaves in range(2,15):\n",
        "    classifier = DecisionTreeClassifier(max_leaf_nodes = leaves, random_state=0, criterion='entropy')\n",
        "    classifier.fit(x_train, y_train)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    list1.append(accuracy_score(y_test,y_pred))\n",
        "#print(mylist)\n",
        "plt.plot(list(range(2,15)), list1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4oBDcwbR3cF2",
        "outputId": "90fbb9f2-5eb3-4b95-b3b2-a182217f09e8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DecisionTreeClassifier(max_leaf_nodes = 5, random_state=0, criterion='entropy')\n",
        "classifier.fit(x_train, y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc_decisiontree = accuracy_score(y_test, y_pred)\n",
        "print(cm)\n",
        "print(acc_decisiontree, '%')\n",
        "mylist.append(acc_decisiontree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRrsyBWB3vyj",
        "outputId": "9c0e9c3e-51b4-40af-b08d-28d70741fef2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[127   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  4   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8581081081081081 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RANDOM FOREST CLASSIFCATION\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "list1 = []\n",
        "for estimators in range(10,30):\n",
        "    classifier = RandomForestClassifier(n_estimators = estimators, random_state=0, criterion='entropy')\n",
        "    classifier.fit(x_train, y_train)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    list1.append(accuracy_score(y_test,y_pred))\n",
        "#print(mylist)\n",
        "plt.plot(list(range(10,30)), list1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "heShbmey31ga",
        "outputId": "df46f37c-6478-4166-a321-b5beef71fc6f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 15, criterion='entropy', random_state=0)\n",
        "classifier.fit(x_train,y_train)\n",
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "acc_randomforest = accuracy_score(y_test, y_pred)\n",
        "mylist.append(acc_randomforest)\n",
        "print(cm)\n",
        "print(acc_randomforest,'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R0MMG4M3-uX",
        "outputId": "9e5e8c3e-3c42-4e4c-cbfa-f87839e6a595"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[127   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  3   0   0   0   0   0   0   0   0   0   0   0   1]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8581081081081081 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ANN (neural network )\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense, BatchNormalization, Dropout, LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
        "from keras import callbacks\n",
        "\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
        "    patience=20, # how many epochs to wait before stopping\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "# Initialising the NN\n",
        "model = Sequential()\n",
        "\n",
        "# layers\n",
        "\n",
        "model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "\n",
        "# Compiling the ANN\n",
        "opt = Adam(learning_rate=0.00009)\n",
        "model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Train the ANN\n",
        "model.fit(x_train, y_train, batch_size = 10, epochs = 150, callbacks=[early_stopping], validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgELIKES4DLo",
        "outputId": "44735b77-1b4b-4129-be9e-a04222a902d1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "28/28 [==============================] - 1s 11ms/step - loss: 0.6834 - accuracy: 0.0218 - val_loss: 0.6677 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.6602 - accuracy: 0.0000e+00 - val_loss: 0.6427 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.0000e+00 - val_loss: 0.6163 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.0000e+00 - val_loss: 0.5890 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5905 - accuracy: 0.0000e+00 - val_loss: 0.5620 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.0000e+00 - val_loss: 0.5345 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.0000e+00 - val_loss: 0.5038 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.0000e+00 - val_loss: 0.4705 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.0000e+00 - val_loss: 0.4356 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.0000e+00 - val_loss: 0.3963 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.0000e+00 - val_loss: 0.3432 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.3534 - accuracy: 0.0000e+00 - val_loss: 0.2820 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.2885 - accuracy: 0.0000e+00 - val_loss: 0.2086 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1894 - accuracy: 0.0000e+00 - val_loss: 0.1035 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.1127 - accuracy: 0.0000e+00 - val_loss: -0.0028 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 0.0500 - accuracy: 0.0000e+00 - val_loss: -0.1364 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -0.0563 - accuracy: 0.0000e+00 - val_loss: -0.2870 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -0.3150 - accuracy: 0.0000e+00 - val_loss: -0.5025 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -0.4933 - accuracy: 0.0000e+00 - val_loss: -0.7745 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -0.8517 - accuracy: 0.0000e+00 - val_loss: -1.1289 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1.0159 - accuracy: 0.0000e+00 - val_loss: -1.5395 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1.5955 - accuracy: 0.0000e+00 - val_loss: -2.0563 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/150\n",
            "28/28 [==============================] - 0s 6ms/step - loss: -1.8357 - accuracy: 0.0000e+00 - val_loss: -2.6228 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -2.5739 - accuracy: 0.0000e+00 - val_loss: -3.2620 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -3.2711 - accuracy: 0.0000e+00 - val_loss: -4.0821 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -4.0765 - accuracy: 0.0000e+00 - val_loss: -5.1321 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -4.7331 - accuracy: 0.0000e+00 - val_loss: -6.2133 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -5.6437 - accuracy: 0.0000e+00 - val_loss: -7.3923 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -6.3905 - accuracy: 0.0000e+00 - val_loss: -8.6557 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -8.6065 - accuracy: 0.0000e+00 - val_loss: -10.3667 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -9.6386 - accuracy: 0.0000e+00 - val_loss: -12.2165 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -13.4871 - accuracy: 0.0000e+00 - val_loss: -14.5193 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -14.5911 - accuracy: 0.0000e+00 - val_loss: -16.9950 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -17.4636 - accuracy: 0.0000e+00 - val_loss: -19.9829 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -21.8334 - accuracy: 0.0000e+00 - val_loss: -23.1742 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -19.3394 - accuracy: 0.0000e+00 - val_loss: -26.6719 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -26.7871 - accuracy: 0.0000e+00 - val_loss: -30.3968 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -30.2444 - accuracy: 0.0000e+00 - val_loss: -34.9046 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -30.5128 - accuracy: 0.0000e+00 - val_loss: -39.0430 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -40.5527 - accuracy: 0.0000e+00 - val_loss: -44.3222 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -43.4275 - accuracy: 0.0000e+00 - val_loss: -50.7468 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -46.0981 - accuracy: 0.0000e+00 - val_loss: -55.9659 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -36.6685 - accuracy: 0.0000e+00 - val_loss: -62.4578 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -50.4559 - accuracy: 0.0000e+00 - val_loss: -68.1187 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -66.0653 - accuracy: 0.0000e+00 - val_loss: -76.9966 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -87.8811 - accuracy: 0.0000e+00 - val_loss: -87.5397 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -95.1589 - accuracy: 0.0000e+00 - val_loss: -98.6028 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -88.1375 - accuracy: 0.0000e+00 - val_loss: -109.5813 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -96.8062 - accuracy: 0.0000e+00 - val_loss: -120.9302 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -121.4112 - accuracy: 0.0000e+00 - val_loss: -133.5081 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -97.2652 - accuracy: 0.0000e+00 - val_loss: -145.8890 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -114.7404 - accuracy: 0.0000e+00 - val_loss: -157.4511 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -144.7174 - accuracy: 0.0000e+00 - val_loss: -171.5918 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -165.2697 - accuracy: 0.0000e+00 - val_loss: -189.8792 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -200.2677 - accuracy: 0.0000e+00 - val_loss: -209.7428 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -192.2207 - accuracy: 0.0000e+00 - val_loss: -226.8085 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -214.9218 - accuracy: 0.0000e+00 - val_loss: -247.5477 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -170.9320 - accuracy: 0.0000e+00 - val_loss: -266.3795 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -230.6998 - accuracy: 0.0000e+00 - val_loss: -286.6830 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -240.4027 - accuracy: 0.0000e+00 - val_loss: -310.6882 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -278.5764 - accuracy: 0.0000e+00 - val_loss: -335.2701 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -315.4436 - accuracy: 0.0000e+00 - val_loss: -360.4712 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -305.0268 - accuracy: 0.0000e+00 - val_loss: -389.1488 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -363.0364 - accuracy: 0.0000e+00 - val_loss: -421.2540 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -444.1458 - accuracy: 0.0000e+00 - val_loss: -452.6440 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -338.5974 - accuracy: 0.0000e+00 - val_loss: -488.3881 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -422.2654 - accuracy: 0.0000e+00 - val_loss: -521.3819 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -474.2321 - accuracy: 0.0000e+00 - val_loss: -554.5114 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -507.7067 - accuracy: 0.0000e+00 - val_loss: -595.5571 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -606.5657 - accuracy: 0.0000e+00 - val_loss: -643.3211 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -618.4100 - accuracy: 0.0000e+00 - val_loss: -688.1565 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -751.5601 - accuracy: 0.0000e+00 - val_loss: -741.5972 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -723.3607 - accuracy: 0.0000e+00 - val_loss: -786.4827 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -778.4424 - accuracy: 0.0000e+00 - val_loss: -846.9832 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -704.6649 - accuracy: 0.0000e+00 - val_loss: -893.3348 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -981.0618 - accuracy: 0.0000e+00 - val_loss: -947.7961 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -910.0406 - accuracy: 0.0000e+00 - val_loss: -1009.2459 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -976.6953 - accuracy: 0.0000e+00 - val_loss: -1064.8824 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -853.5628 - accuracy: 0.0000e+00 - val_loss: -1125.5179 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1169.3049 - accuracy: 0.0000e+00 - val_loss: -1193.3444 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1329.7504 - accuracy: 0.0000e+00 - val_loss: -1269.7324 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1015.7579 - accuracy: 0.0000e+00 - val_loss: -1339.5547 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -1388.4971 - accuracy: 0.0000e+00 - val_loss: -1411.6960 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1289.7111 - accuracy: 0.0000e+00 - val_loss: -1490.2194 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1447.6002 - accuracy: 0.0000e+00 - val_loss: -1565.5731 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1239.2792 - accuracy: 0.0000e+00 - val_loss: -1631.1583 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1686.0280 - accuracy: 0.0000e+00 - val_loss: -1723.1421 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1464.7559 - accuracy: 0.0000e+00 - val_loss: -1808.9385 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1492.3761 - accuracy: 0.0000e+00 - val_loss: -1892.7941 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1809.8228 - accuracy: 0.0000e+00 - val_loss: -1989.1565 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -1902.1772 - accuracy: 0.0000e+00 - val_loss: -2096.1946 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -2272.0032 - accuracy: 0.0000e+00 - val_loss: -2192.4976 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -2038.1886 - accuracy: 0.0000e+00 - val_loss: -2314.4683 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -2325.2122 - accuracy: 0.0000e+00 - val_loss: -2421.6650 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -2290.3340 - accuracy: 0.0000e+00 - val_loss: -2540.7134 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -2523.6582 - accuracy: 0.0000e+00 - val_loss: -2667.4827 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -2522.6167 - accuracy: 0.0000e+00 - val_loss: -2790.2783 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -2674.9226 - accuracy: 0.0000e+00 - val_loss: -2932.8887 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -2905.4204 - accuracy: 0.0000e+00 - val_loss: -3087.7334 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -3032.5054 - accuracy: 0.0000e+00 - val_loss: -3206.5264 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -2568.4937 - accuracy: 0.0000e+00 - val_loss: -3346.1367 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -2992.1013 - accuracy: 0.0000e+00 - val_loss: -3493.2209 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -3427.2383 - accuracy: 0.0000e+00 - val_loss: -3639.3745 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -3564.2668 - accuracy: 0.0000e+00 - val_loss: -3816.9094 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -3609.2236 - accuracy: 0.0000e+00 - val_loss: -3984.0344 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -3322.7500 - accuracy: 0.0000e+00 - val_loss: -4128.4458 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -3948.4878 - accuracy: 0.0000e+00 - val_loss: -4304.5801 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -3496.0076 - accuracy: 0.0000e+00 - val_loss: -4467.5977 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -3551.8115 - accuracy: 0.0000e+00 - val_loss: -4621.1509 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -4359.7544 - accuracy: 0.0000e+00 - val_loss: -4817.5894 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -4935.4009 - accuracy: 0.0000e+00 - val_loss: -5030.8706 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -4097.1919 - accuracy: 0.0000e+00 - val_loss: -5239.6353 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -4633.1045 - accuracy: 0.0000e+00 - val_loss: -5419.2769 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -4620.6768 - accuracy: 0.0000e+00 - val_loss: -5630.3218 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -5696.8188 - accuracy: 0.0000e+00 - val_loss: -5854.8843 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -5284.1792 - accuracy: 0.0000e+00 - val_loss: -6082.0703 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -5508.8818 - accuracy: 0.0000e+00 - val_loss: -6294.2822 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -5816.1772 - accuracy: 0.0000e+00 - val_loss: -6541.6084 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -5780.7446 - accuracy: 0.0000e+00 - val_loss: -6766.5049 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -5529.3359 - accuracy: 0.0000e+00 - val_loss: -6991.2480 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -5724.5806 - accuracy: 0.0000e+00 - val_loss: -7206.4365 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -5591.4307 - accuracy: 0.0000e+00 - val_loss: -7429.6221 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -6618.3608 - accuracy: 0.0000e+00 - val_loss: -7687.4546 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -7654.3711 - accuracy: 0.0000e+00 - val_loss: -7963.7437 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -7240.8882 - accuracy: 0.0000e+00 - val_loss: -8270.7979 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -7843.4971 - accuracy: 0.0000e+00 - val_loss: -8575.7266 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -9091.3594 - accuracy: 0.0000e+00 - val_loss: -8894.4736 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -8371.4688 - accuracy: 0.0000e+00 - val_loss: -9180.7793 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -8615.6943 - accuracy: 0.0000e+00 - val_loss: -9517.4355 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -8166.8911 - accuracy: 0.0000e+00 - val_loss: -9789.8965 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -9774.5557 - accuracy: 0.0000e+00 - val_loss: -10130.9258 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -7826.8164 - accuracy: 0.0000e+00 - val_loss: -10428.1904 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/150\n",
            "28/28 [==============================] - 0s 5ms/step - loss: -10818.5127 - accuracy: 0.0000e+00 - val_loss: -10749.1006 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -9619.6582 - accuracy: 0.0000e+00 - val_loss: -11102.2881 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -9399.5967 - accuracy: 0.0000e+00 - val_loss: -11451.1406 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -10711.6221 - accuracy: 0.0000e+00 - val_loss: -11826.5947 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -9786.4902 - accuracy: 0.0000e+00 - val_loss: -12174.9336 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -9464.6484 - accuracy: 0.0000e+00 - val_loss: -12486.7002 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -12950.1523 - accuracy: 0.0000e+00 - val_loss: -12900.3564 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -12771.9004 - accuracy: 0.0000e+00 - val_loss: -13344.3027 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -14899.2979 - accuracy: 0.0000e+00 - val_loss: -13820.5645 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -15204.2168 - accuracy: 0.0000e+00 - val_loss: -14263.5684 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -12123.5693 - accuracy: 0.0000e+00 - val_loss: -14726.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -14835.2920 - accuracy: 0.0000e+00 - val_loss: -15149.2705 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -14331.8721 - accuracy: 0.0000e+00 - val_loss: -15654.6719 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -15064.5537 - accuracy: 0.0000e+00 - val_loss: -16113.8369 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -15638.5527 - accuracy: 0.0000e+00 - val_loss: -16568.6875 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -15653.1250 - accuracy: 0.0000e+00 - val_loss: -17052.9746 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -16021.9619 - accuracy: 0.0000e+00 - val_loss: -17494.0840 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/150\n",
            "28/28 [==============================] - 0s 4ms/step - loss: -17258.1797 - accuracy: 0.0000e+00 - val_loss: -18064.5098 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4351064bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred = (y_pred > 0.9)\n",
        "np.set_printoptions()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# confusion matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(\"Confusion Matrix\")\n",
        "print(cm)\n",
        "print()\n",
        "\n",
        "# accuracy\n",
        "ac_ann = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy\")\n",
        "print(ac_ann)\n",
        "mylist.append(ac_ann)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE6FGlfE4Ole",
        "outputId": "140e8df0-9d64-4e61-cbec-3522bace1807"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 17ms/step\n",
            "Confusion Matrix\n",
            "[[  0 127   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   4   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "\n",
            "Accuracy\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DNN\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, Dense, Input\n",
        "\n",
        "i = Input(shape=(None, 455, 11))\n",
        "\n",
        "x = Dense(16, activation='relu')(i)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(32, activation='relu')(i)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Dense(16, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "y = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "dnn_adam = Model(inputs=i, outputs=y)\n",
        "\n",
        "dnn_adam.compile(optimizer='adam', \n",
        "                   loss='binary_crossentropy',\n",
        "                   metrics=['accuracy'])\n",
        "\n",
        "dnn_adam.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X80mrY3B7iHB",
        "outputId": "125570fd-413b-439a-fd27-7d5322ad978b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, None, 455, 11)]   0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, None, 455, 32)     384       \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, None, 455, 32)     0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, None, 455, 64)     2112      \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, None, 455, 64)     0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, None, 455, 32)     2080      \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, None, 455, 32)     0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, None, 455, 16)     528       \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, None, 455, 16)     0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, None, 455, 1)      17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=25)\n",
        "\n",
        "history_adam = dnn_adam.fit(x=x_train, y=y_train,\n",
        "                             validation_data=(x_test, y_test),\n",
        "                             epochs=300,\n",
        "                             callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vf3qKXM7vc1",
        "outputId": "7d597709-7eba-4931-9d1c-9f2ebbf79582"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, None, 455, 11) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 455, 11), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 11).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, None, 455, 11) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 455, 11), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 11).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 8/11 [====================>.........] - ETA: 0s - loss: 11.9440 - accuracy: 0.6523 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, None, 455, 11) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 455, 11), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 11).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/11 [==============================] - 2s 66ms/step - loss: 11.8531 - accuracy: 0.6541 - val_loss: 3.3362 - val_accuracy: 0.8514\n",
            "Epoch 2/300\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 4.8198 - accuracy: 0.6017 - val_loss: 1.4433 - val_accuracy: 0.6689\n",
            "Epoch 3/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 6.5367 - accuracy: 0.5029 - val_loss: -0.0206 - val_accuracy: 0.3243\n",
            "Epoch 4/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: 1.5436 - accuracy: 0.4360 - val_loss: -1.1771 - val_accuracy: 0.0676\n",
            "Epoch 5/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -2.7488 - accuracy: 0.3081 - val_loss: -2.3677 - val_accuracy: 0.0068\n",
            "Epoch 6/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -2.6343 - accuracy: 0.2238 - val_loss: -3.6679 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -5.9535 - accuracy: 0.1802 - val_loss: -5.1439 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -10.2939 - accuracy: 0.1047 - val_loss: -7.0627 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -10.1380 - accuracy: 0.1076 - val_loss: -9.7502 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -16.6181 - accuracy: 0.0640 - val_loss: -13.3286 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -22.6804 - accuracy: 0.0669 - val_loss: -18.7119 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -28.9269 - accuracy: 0.0203 - val_loss: -26.1232 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -49.6486 - accuracy: 0.0174 - val_loss: -38.9755 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -88.6853 - accuracy: 0.0116 - val_loss: -61.2922 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -107.5606 - accuracy: 0.0087 - val_loss: -96.4948 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -173.5865 - accuracy: 0.0087 - val_loss: -154.5702 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -268.7391 - accuracy: 0.0087 - val_loss: -250.1805 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -374.7869 - accuracy: 0.0058 - val_loss: -394.4536 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -649.0281 - accuracy: 0.0058 - val_loss: -623.6283 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -1106.7935 - accuracy: 0.0000e+00 - val_loss: -1009.3497 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -1736.9852 - accuracy: 0.0000e+00 - val_loss: -1564.9215 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -2189.4800 - accuracy: 0.0058 - val_loss: -2425.0178 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -4212.8706 - accuracy: 0.0000e+00 - val_loss: -3772.9180 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -5574.4277 - accuracy: 0.0000e+00 - val_loss: -5732.2769 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -8556.8564 - accuracy: 0.0000e+00 - val_loss: -8427.8799 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -12357.8809 - accuracy: 0.0000e+00 - val_loss: -12158.6230 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -18572.3906 - accuracy: 0.0029 - val_loss: -17025.0332 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -22559.4238 - accuracy: 0.0000e+00 - val_loss: -23838.9180 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -37365.4531 - accuracy: 0.0029 - val_loss: -32849.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -47436.7539 - accuracy: 0.0000e+00 - val_loss: -44568.9609 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -64333.9961 - accuracy: 0.0000e+00 - val_loss: -58225.9805 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -97302.7578 - accuracy: 0.0029 - val_loss: -77567.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -117838.3047 - accuracy: 0.0000e+00 - val_loss: -100908.4922 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: -142396.0156 - accuracy: 0.0000e+00 - val_loss: -128881.4297 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -173157.2500 - accuracy: 0.0000e+00 - val_loss: -161186.5938 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -271722.6562 - accuracy: 0.0000e+00 - val_loss: -205951.3594 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -301128.4062 - accuracy: 0.0000e+00 - val_loss: -258782.6719 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -335802.6562 - accuracy: 0.0000e+00 - val_loss: -317240.9062 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -440918.5625 - accuracy: 0.0000e+00 - val_loss: -387681.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -566553.5625 - accuracy: 0.0000e+00 - val_loss: -471011.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -652356.0000 - accuracy: 0.0000e+00 - val_loss: -569679.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -767948.8125 - accuracy: 0.0000e+00 - val_loss: -683037.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -920445.5625 - accuracy: 0.0000e+00 - val_loss: -810037.7500 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -1053304.5000 - accuracy: 0.0000e+00 - val_loss: -950980.3125 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -1338846.1250 - accuracy: 0.0000e+00 - val_loss: -1122983.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -1547047.3750 - accuracy: 0.0000e+00 - val_loss: -1320165.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -1640642.6250 - accuracy: 0.0000e+00 - val_loss: -1540311.8750 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -2050893.6250 - accuracy: 0.0000e+00 - val_loss: -1785347.6250 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -2766817.0000 - accuracy: 0.0000e+00 - val_loss: -2073878.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -3050343.0000 - accuracy: 0.0000e+00 - val_loss: -2412709.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -3324160.7500 - accuracy: 0.0000e+00 - val_loss: -2754005.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -4007916.0000 - accuracy: 0.0000e+00 - val_loss: -3182800.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -3983546.7500 - accuracy: 0.0000e+00 - val_loss: -3598959.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -5018786.0000 - accuracy: 0.0000e+00 - val_loss: -4061765.2500 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -4904023.0000 - accuracy: 0.0000e+00 - val_loss: -4549329.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -6106336.5000 - accuracy: 0.0000e+00 - val_loss: -5073994.5000 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -7744905.5000 - accuracy: 0.0000e+00 - val_loss: -5712443.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -7349611.0000 - accuracy: 0.0000e+00 - val_loss: -6442328.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -9326494.0000 - accuracy: 0.0000e+00 - val_loss: -7202804.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: -8658167.0000 - accuracy: 0.0000e+00 - val_loss: -7952629.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -10810221.0000 - accuracy: 0.0000e+00 - val_loss: -8772744.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -12251911.0000 - accuracy: 0.0000e+00 - val_loss: -9719307.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -12938060.0000 - accuracy: 0.0000e+00 - val_loss: -10815365.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 64/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -13228745.0000 - accuracy: 0.0000e+00 - val_loss: -11862627.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -14186639.0000 - accuracy: 0.0000e+00 - val_loss: -12970806.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -18147998.0000 - accuracy: 0.0000e+00 - val_loss: -14182035.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -19913980.0000 - accuracy: 0.0000e+00 - val_loss: -15665851.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -22318372.0000 - accuracy: 0.0000e+00 - val_loss: -17124754.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 69/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -21610842.0000 - accuracy: 0.0029 - val_loss: -18707646.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 70/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -22098562.0000 - accuracy: 0.0000e+00 - val_loss: -20297060.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 71/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -28486090.0000 - accuracy: 0.0029 - val_loss: -22027810.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 72/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -29216108.0000 - accuracy: 0.0000e+00 - val_loss: -23866378.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 73/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -33931972.0000 - accuracy: 0.0000e+00 - val_loss: -25970736.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 74/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -39245352.0000 - accuracy: 0.0000e+00 - val_loss: -28289294.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 75/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -37222840.0000 - accuracy: 0.0000e+00 - val_loss: -30605368.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 76/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -40930112.0000 - accuracy: 0.0000e+00 - val_loss: -33056224.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 77/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -39289648.0000 - accuracy: 0.0000e+00 - val_loss: -35599020.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 78/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -48167568.0000 - accuracy: 0.0000e+00 - val_loss: -38290924.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 79/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -61139068.0000 - accuracy: 0.0000e+00 - val_loss: -41600200.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 80/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -57658548.0000 - accuracy: 0.0000e+00 - val_loss: -44605356.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 81/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -61259204.0000 - accuracy: 0.0000e+00 - val_loss: -47928896.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 82/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -63238428.0000 - accuracy: 0.0000e+00 - val_loss: -51437888.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 83/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -72315384.0000 - accuracy: 0.0000e+00 - val_loss: -55040740.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 84/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -79103912.0000 - accuracy: 0.0000e+00 - val_loss: -58953900.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 85/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -68709648.0000 - accuracy: 0.0029 - val_loss: -62698744.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 86/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -77452400.0000 - accuracy: 0.0000e+00 - val_loss: -66693280.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 87/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -91147976.0000 - accuracy: 0.0000e+00 - val_loss: -70599016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 88/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -104590408.0000 - accuracy: 0.0000e+00 - val_loss: -75533712.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 89/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -95887240.0000 - accuracy: 0.0000e+00 - val_loss: -80311696.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 90/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -102108576.0000 - accuracy: 0.0000e+00 - val_loss: -85011664.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 91/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -103239040.0000 - accuracy: 0.0000e+00 - val_loss: -90133968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 92/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -119798320.0000 - accuracy: 0.0000e+00 - val_loss: -95216928.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 93/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -123653072.0000 - accuracy: 0.0000e+00 - val_loss: -101158080.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 94/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -156168720.0000 - accuracy: 0.0000e+00 - val_loss: -107021168.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 95/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -145799696.0000 - accuracy: 0.0000e+00 - val_loss: -114103696.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 96/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -160451184.0000 - accuracy: 0.0000e+00 - val_loss: -120746400.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 97/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -160788576.0000 - accuracy: 0.0000e+00 - val_loss: -128136480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 98/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -152335008.0000 - accuracy: 0.0000e+00 - val_loss: -134687472.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 99/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -187975664.0000 - accuracy: 0.0000e+00 - val_loss: -142367808.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 100/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -197201616.0000 - accuracy: 0.0000e+00 - val_loss: -150040816.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 101/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -190048288.0000 - accuracy: 0.0000e+00 - val_loss: -157759984.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 102/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -190750528.0000 - accuracy: 0.0000e+00 - val_loss: -165677904.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 103/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -206429344.0000 - accuracy: 0.0000e+00 - val_loss: -174330176.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 104/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -233776432.0000 - accuracy: 0.0000e+00 - val_loss: -183024896.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 105/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -243529568.0000 - accuracy: 0.0000e+00 - val_loss: -191993824.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 106/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -230842384.0000 - accuracy: 0.0000e+00 - val_loss: -201299824.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 107/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -255033584.0000 - accuracy: 0.0000e+00 - val_loss: -211200640.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 108/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -296836896.0000 - accuracy: 0.0000e+00 - val_loss: -221094656.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 109/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -317934816.0000 - accuracy: 0.0000e+00 - val_loss: -232760320.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 110/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -259568480.0000 - accuracy: 0.0000e+00 - val_loss: -244449504.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 111/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -337888352.0000 - accuracy: 0.0000e+00 - val_loss: -256034208.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 112/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -341915968.0000 - accuracy: 0.0000e+00 - val_loss: -268119040.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 113/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -395176544.0000 - accuracy: 0.0000e+00 - val_loss: -281177472.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 114/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -344068320.0000 - accuracy: 0.0000e+00 - val_loss: -294551968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 115/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -368471840.0000 - accuracy: 0.0000e+00 - val_loss: -307574464.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 116/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -448613216.0000 - accuracy: 0.0000e+00 - val_loss: -321717216.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 117/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -376451904.0000 - accuracy: 0.0000e+00 - val_loss: -335281408.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 118/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -380611808.0000 - accuracy: 0.0000e+00 - val_loss: -348230304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 119/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -433848288.0000 - accuracy: 0.0000e+00 - val_loss: -361912480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 120/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -516593088.0000 - accuracy: 0.0000e+00 - val_loss: -377804736.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 121/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -514096960.0000 - accuracy: 0.0000e+00 - val_loss: -393010528.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 122/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -496713920.0000 - accuracy: 0.0000e+00 - val_loss: -410183360.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 123/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -568515200.0000 - accuracy: 0.0000e+00 - val_loss: -428123200.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 124/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -592001664.0000 - accuracy: 0.0000e+00 - val_loss: -446461024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 125/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -591561472.0000 - accuracy: 0.0000e+00 - val_loss: -463940256.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 126/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -602644928.0000 - accuracy: 0.0000e+00 - val_loss: -482786784.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 127/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -671738432.0000 - accuracy: 0.0000e+00 - val_loss: -502253280.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 128/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -643995840.0000 - accuracy: 0.0000e+00 - val_loss: -523437024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 129/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -713313984.0000 - accuracy: 0.0000e+00 - val_loss: -543407232.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 130/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -806030144.0000 - accuracy: 0.0000e+00 - val_loss: -566100736.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 131/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -746408128.0000 - accuracy: 0.0000e+00 - val_loss: -590263168.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 132/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -684407552.0000 - accuracy: 0.0000e+00 - val_loss: -611852480.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 133/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -753018816.0000 - accuracy: 0.0000e+00 - val_loss: -633712000.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 134/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -909268480.0000 - accuracy: 0.0000e+00 - val_loss: -657064768.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 135/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -908791232.0000 - accuracy: 0.0000e+00 - val_loss: -683085696.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 136/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -920682496.0000 - accuracy: 0.0000e+00 - val_loss: -709000448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 137/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -988892416.0000 - accuracy: 0.0000e+00 - val_loss: -734258112.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 138/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -960069696.0000 - accuracy: 0.0000e+00 - val_loss: -761022720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 139/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -977867776.0000 - accuracy: 0.0000e+00 - val_loss: -789485696.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 140/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -1022479360.0000 - accuracy: 0.0000e+00 - val_loss: -815266624.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 141/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -1001215296.0000 - accuracy: 0.0000e+00 - val_loss: -844157056.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 142/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -1054883840.0000 - accuracy: 0.0000e+00 - val_loss: -873061696.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 143/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -1233573376.0000 - accuracy: 0.0000e+00 - val_loss: -903304320.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 144/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -1198446208.0000 - accuracy: 0.0000e+00 - val_loss: -934841600.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 145/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -1191755904.0000 - accuracy: 0.0000e+00 - val_loss: -965372736.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 146/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -1277379584.0000 - accuracy: 0.0000e+00 - val_loss: -999243904.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 147/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -1407316480.0000 - accuracy: 0.0000e+00 - val_loss: -1031027712.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 148/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -1537277056.0000 - accuracy: 0.0000e+00 - val_loss: -1068090240.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 149/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -1486984960.0000 - accuracy: 0.0000e+00 - val_loss: -1105391104.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 150/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -1432778240.0000 - accuracy: 0.0000e+00 - val_loss: -1143143680.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 151/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -1589502464.0000 - accuracy: 0.0000e+00 - val_loss: -1181624192.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 152/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -1598699520.0000 - accuracy: 0.0000e+00 - val_loss: -1220093952.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 153/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -1598127360.0000 - accuracy: 0.0000e+00 - val_loss: -1257143040.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 154/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -1660621824.0000 - accuracy: 0.0000e+00 - val_loss: -1298473856.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 155/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -1755507456.0000 - accuracy: 0.0000e+00 - val_loss: -1337245696.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 156/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -1707521280.0000 - accuracy: 0.0000e+00 - val_loss: -1379209728.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 157/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -1837279104.0000 - accuracy: 0.0000e+00 - val_loss: -1419250304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 158/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -1773309696.0000 - accuracy: 0.0000e+00 - val_loss: -1463560192.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 159/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -2101495808.0000 - accuracy: 0.0000e+00 - val_loss: -1508166016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 160/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -1977245824.0000 - accuracy: 0.0000e+00 - val_loss: -1556506112.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 161/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -1851311360.0000 - accuracy: 0.0000e+00 - val_loss: -1601904000.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 162/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -1806366080.0000 - accuracy: 0.0000e+00 - val_loss: -1647343872.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 163/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -2464037632.0000 - accuracy: 0.0000e+00 - val_loss: -1695848448.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 164/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -2263441152.0000 - accuracy: 0.0000e+00 - val_loss: -1744831104.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 165/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -1965870976.0000 - accuracy: 0.0000e+00 - val_loss: -1792492416.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 166/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -2247669504.0000 - accuracy: 0.0000e+00 - val_loss: -1838602240.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 167/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -2395314176.0000 - accuracy: 0.0000e+00 - val_loss: -1889371392.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 168/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -2495624960.0000 - accuracy: 0.0000e+00 - val_loss: -1943182720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 169/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -2498901504.0000 - accuracy: 0.0000e+00 - val_loss: -2000528256.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 170/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -2647992320.0000 - accuracy: 0.0000e+00 - val_loss: -2054347008.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 171/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -2427414272.0000 - accuracy: 0.0000e+00 - val_loss: -2108867712.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 172/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -2897125120.0000 - accuracy: 0.0000e+00 - val_loss: -2160524800.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 173/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -2813790976.0000 - accuracy: 0.0000e+00 - val_loss: -2220723712.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 174/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -2689876224.0000 - accuracy: 0.0000e+00 - val_loss: -2278970880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 175/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -3012871424.0000 - accuracy: 0.0000e+00 - val_loss: -2340267520.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 176/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -3300815872.0000 - accuracy: 0.0000e+00 - val_loss: -2404014848.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 177/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -3455601152.0000 - accuracy: 0.0000e+00 - val_loss: -2469639680.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 178/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -3142829056.0000 - accuracy: 0.0000e+00 - val_loss: -2539986176.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 179/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: -3580436224.0000 - accuracy: 0.0000e+00 - val_loss: -2610299136.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 180/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -3261104384.0000 - accuracy: 0.0000e+00 - val_loss: -2674098944.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 181/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -3120625408.0000 - accuracy: 0.0000e+00 - val_loss: -2735833600.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 182/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -3186700032.0000 - accuracy: 0.0000e+00 - val_loss: -2798914304.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 183/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -4379222016.0000 - accuracy: 0.0000e+00 - val_loss: -2872713472.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 184/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -3536685568.0000 - accuracy: 0.0000e+00 - val_loss: -2951554816.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 185/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -3755065600.0000 - accuracy: 0.0000e+00 - val_loss: -3024130048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 186/300\n",
            "11/11 [==============================] - 0s 5ms/step - loss: -3928511232.0000 - accuracy: 0.0000e+00 - val_loss: -3096558848.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 187/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -3991264768.0000 - accuracy: 0.0000e+00 - val_loss: -3173539584.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 188/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -4487996928.0000 - accuracy: 0.0000e+00 - val_loss: -3249018880.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 189/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -4398563328.0000 - accuracy: 0.0000e+00 - val_loss: -3333308928.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 190/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -4504902656.0000 - accuracy: 0.0000e+00 - val_loss: -3414085120.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 191/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -4012532224.0000 - accuracy: 0.0000e+00 - val_loss: -3491584512.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 192/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -4764569088.0000 - accuracy: 0.0000e+00 - val_loss: -3574605568.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 193/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -4662655488.0000 - accuracy: 0.0000e+00 - val_loss: -3657425920.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 194/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -4362321408.0000 - accuracy: 0.0000e+00 - val_loss: -3743172352.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 195/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -4622490112.0000 - accuracy: 0.0000e+00 - val_loss: -3827266048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 196/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -5034231808.0000 - accuracy: 0.0000e+00 - val_loss: -3910940928.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 197/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -4578634240.0000 - accuracy: 0.0000e+00 - val_loss: -3996077056.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 198/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -5392043520.0000 - accuracy: 0.0000e+00 - val_loss: -4086868736.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 199/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -4901579776.0000 - accuracy: 0.0000e+00 - val_loss: -4169340416.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 200/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -6217284608.0000 - accuracy: 0.0000e+00 - val_loss: -4270687488.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 201/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -5057857536.0000 - accuracy: 0.0000e+00 - val_loss: -4365264896.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 202/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -5530094592.0000 - accuracy: 0.0000e+00 - val_loss: -4463889920.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 203/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -5546219520.0000 - accuracy: 0.0000e+00 - val_loss: -4560869376.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 204/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -5008977408.0000 - accuracy: 0.0000e+00 - val_loss: -4652029952.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 205/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -6824164864.0000 - accuracy: 0.0000e+00 - val_loss: -4748270080.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 206/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -5856328192.0000 - accuracy: 0.0000e+00 - val_loss: -4854776832.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 207/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -6359986176.0000 - accuracy: 0.0000e+00 - val_loss: -4957797376.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 208/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -6627076608.0000 - accuracy: 0.0000e+00 - val_loss: -5065290752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 209/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -5702571008.0000 - accuracy: 0.0000e+00 - val_loss: -5163294208.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 210/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -6455165440.0000 - accuracy: 0.0000e+00 - val_loss: -5273600512.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 211/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -6497028096.0000 - accuracy: 0.0000e+00 - val_loss: -5382174720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 212/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -6810205696.0000 - accuracy: 0.0000e+00 - val_loss: -5489762816.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 213/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -7468282880.0000 - accuracy: 0.0000e+00 - val_loss: -5606124544.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 214/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -7066244096.0000 - accuracy: 0.0000e+00 - val_loss: -5728621568.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 215/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -7153878528.0000 - accuracy: 0.0000e+00 - val_loss: -5838789632.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 216/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -7621905920.0000 - accuracy: 0.0000e+00 - val_loss: -5960115712.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 217/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -8056952320.0000 - accuracy: 0.0000e+00 - val_loss: -6093296640.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 218/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -7202450432.0000 - accuracy: 0.0000e+00 - val_loss: -6215448064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 219/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -7888914432.0000 - accuracy: 0.0000e+00 - val_loss: -6332934144.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 220/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -7941155840.0000 - accuracy: 0.0000e+00 - val_loss: -6461059584.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 221/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -9630531584.0000 - accuracy: 0.0000e+00 - val_loss: -6598435840.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 222/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -9180554240.0000 - accuracy: 0.0000e+00 - val_loss: -6737633792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 223/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -9014833152.0000 - accuracy: 0.0000e+00 - val_loss: -6873789440.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 224/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -8514189312.0000 - accuracy: 0.0000e+00 - val_loss: -7007091200.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 225/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -9578338304.0000 - accuracy: 0.0000e+00 - val_loss: -7145225728.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 226/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -9668570112.0000 - accuracy: 0.0000e+00 - val_loss: -7281572352.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 227/300\n",
            "11/11 [==============================] - 0s 10ms/step - loss: -8753101824.0000 - accuracy: 0.0000e+00 - val_loss: -7422365184.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 228/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -8784330752.0000 - accuracy: 0.0000e+00 - val_loss: -7552802816.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 229/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -11810372608.0000 - accuracy: 0.0000e+00 - val_loss: -7714840576.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 230/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -8303337984.0000 - accuracy: 0.0000e+00 - val_loss: -7855952896.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 231/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -9929390080.0000 - accuracy: 0.0000e+00 - val_loss: -7988265472.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 232/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -9678159872.0000 - accuracy: 0.0000e+00 - val_loss: -8146704896.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 233/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -12125314048.0000 - accuracy: 0.0000e+00 - val_loss: -8310866432.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 234/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -10511437824.0000 - accuracy: 0.0000e+00 - val_loss: -8465523200.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 235/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -10152051712.0000 - accuracy: 0.0000e+00 - val_loss: -8609496064.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 236/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -11244651520.0000 - accuracy: 0.0000e+00 - val_loss: -8764267520.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 237/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -12211237888.0000 - accuracy: 0.0000e+00 - val_loss: -8929040384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 238/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -13040196608.0000 - accuracy: 0.0000e+00 - val_loss: -9099177984.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 239/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -11368744960.0000 - accuracy: 0.0000e+00 - val_loss: -9261985792.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 240/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: -12414310400.0000 - accuracy: 0.0000e+00 - val_loss: -9431755776.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 241/300\n",
            "11/11 [==============================] - 0s 9ms/step - loss: -13487162368.0000 - accuracy: 0.0000e+00 - val_loss: -9615083520.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 242/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -11348199424.0000 - accuracy: 0.0000e+00 - val_loss: -9797587968.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 243/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -14435143680.0000 - accuracy: 0.0000e+00 - val_loss: -9985331200.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 244/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -12968182784.0000 - accuracy: 0.0000e+00 - val_loss: -10162470912.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 245/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -13484537856.0000 - accuracy: 0.0000e+00 - val_loss: -10339243008.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 246/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -14747858944.0000 - accuracy: 0.0000e+00 - val_loss: -10525612032.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 247/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -13501392896.0000 - accuracy: 0.0000e+00 - val_loss: -10730515456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 248/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -13602807808.0000 - accuracy: 0.0000e+00 - val_loss: -10903887872.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 249/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -16056990720.0000 - accuracy: 0.0000e+00 - val_loss: -11101072384.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 250/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -13111532544.0000 - accuracy: 0.0000e+00 - val_loss: -11291646976.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 251/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -14730133504.0000 - accuracy: 0.0000e+00 - val_loss: -11478762496.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 252/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -11973020672.0000 - accuracy: 0.0000e+00 - val_loss: -11658776576.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 253/300\n",
            "11/11 [==============================] - 0s 11ms/step - loss: -16338222080.0000 - accuracy: 0.0000e+00 - val_loss: -11845249024.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 254/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -15483385856.0000 - accuracy: 0.0000e+00 - val_loss: -12034750464.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 255/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -14904299520.0000 - accuracy: 0.0000e+00 - val_loss: -12255963136.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 256/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -16431765504.0000 - accuracy: 0.0000e+00 - val_loss: -12445384704.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 257/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -14797201408.0000 - accuracy: 0.0000e+00 - val_loss: -12647894016.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 258/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -16908551168.0000 - accuracy: 0.0000e+00 - val_loss: -12853215232.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 259/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -16897208320.0000 - accuracy: 0.0000e+00 - val_loss: -13074197504.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 260/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -17154538496.0000 - accuracy: 0.0000e+00 - val_loss: -13280676864.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 261/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -16896738304.0000 - accuracy: 0.0000e+00 - val_loss: -13509678080.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 262/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -16100590592.0000 - accuracy: 0.0000e+00 - val_loss: -13703185408.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 263/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -17402023936.0000 - accuracy: 0.0000e+00 - val_loss: -13916933120.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 264/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -17240635392.0000 - accuracy: 0.0000e+00 - val_loss: -14127899648.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 265/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -17312245760.0000 - accuracy: 0.0000e+00 - val_loss: -14348315648.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 266/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -19316049920.0000 - accuracy: 0.0000e+00 - val_loss: -14567948288.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 267/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -19797174272.0000 - accuracy: 0.0000e+00 - val_loss: -14795487232.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 268/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -20728918016.0000 - accuracy: 0.0000e+00 - val_loss: -15044995072.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 269/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -16314693632.0000 - accuracy: 0.0000e+00 - val_loss: -15271205888.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 270/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -17988667392.0000 - accuracy: 0.0000e+00 - val_loss: -15480591360.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 271/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -22012930048.0000 - accuracy: 0.0000e+00 - val_loss: -15709698048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 272/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -22344699904.0000 - accuracy: 0.0000e+00 - val_loss: -15980516352.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 273/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -21883922432.0000 - accuracy: 0.0000e+00 - val_loss: -16251941888.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 274/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -20856895488.0000 - accuracy: 0.0000e+00 - val_loss: -16500744192.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 275/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -23277514752.0000 - accuracy: 0.0000e+00 - val_loss: -16747926528.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 276/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -22182361088.0000 - accuracy: 0.0000e+00 - val_loss: -17025048576.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 277/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -19393183744.0000 - accuracy: 0.0000e+00 - val_loss: -17271293952.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -26478233600.0000 - accuracy: 0.0000e+00 - val_loss: -17543536640.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -21274984448.0000 - accuracy: 0.0000e+00 - val_loss: -17819592704.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -24803207168.0000 - accuracy: 0.0000e+00 - val_loss: -18088505344.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -23201724416.0000 - accuracy: 0.0000e+00 - val_loss: -18361114624.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -22948847616.0000 - accuracy: 0.0000e+00 - val_loss: -18657230848.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -24810000384.0000 - accuracy: 0.0000e+00 - val_loss: -18933782528.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 284/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -24488126464.0000 - accuracy: 0.0000e+00 - val_loss: -19190474752.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -22837909504.0000 - accuracy: 0.0000e+00 - val_loss: -19469948928.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -26958141440.0000 - accuracy: 0.0000e+00 - val_loss: -19742988288.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -25855168512.0000 - accuracy: 0.0000e+00 - val_loss: -20035618816.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -25711601664.0000 - accuracy: 0.0000e+00 - val_loss: -20331530240.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -29548224512.0000 - accuracy: 0.0000e+00 - val_loss: -20643016704.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -25492723712.0000 - accuracy: 0.0000e+00 - val_loss: -20943069184.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -28670476288.0000 - accuracy: 0.0000e+00 - val_loss: -21254076416.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 292/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -24568088576.0000 - accuracy: 0.0000e+00 - val_loss: -21535348736.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -24603863040.0000 - accuracy: 0.0000e+00 - val_loss: -21805320192.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -28740706304.0000 - accuracy: 0.0000e+00 - val_loss: -22117890048.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 295/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -27404277760.0000 - accuracy: 0.0000e+00 - val_loss: -22419785728.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 296/300\n",
            "11/11 [==============================] - 0s 8ms/step - loss: -29746239488.0000 - accuracy: 0.0000e+00 - val_loss: -22742302720.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/300\n",
            "11/11 [==============================] - 0s 6ms/step - loss: -33575352320.0000 - accuracy: 0.0000e+00 - val_loss: -23084943360.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -28298442752.0000 - accuracy: 0.0000e+00 - val_loss: -23394707456.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -27862224896.0000 - accuracy: 0.0000e+00 - val_loss: -23700498432.0000 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/300\n",
            "11/11 [==============================] - 0s 7ms/step - loss: -31756298240.0000 - accuracy: 0.0000e+00 - val_loss: -24021686272.0000 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred = dnn_adam.predict(x_test)\n",
        "y_pred = (y_pred > 0.9)\n",
        "np.set_printoptions()\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "# confusion matrix\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "print(\"Confusion Matrix\")\n",
        "print(cm)\n",
        "print()\n",
        "\n",
        "# accuracy\n",
        "ac_dnn = accuracy_score(y_test,y_pred)\n",
        "print(\"Accuracy\")\n",
        "print(ac_dnn)\n",
        "mylist.append(ac_dnn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5myo79Qq70-T",
        "outputId": "2534fe19-4a79-45ad-bffb-cd9a966152e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, None, 455, 11) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 455, 11), dtype=tf.float32, name='input_2'), name='input_2', description=\"created by layer 'input_2'\"), but it was called on an input with incompatible shape (None, 11).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step\n",
            "Confusion Matrix\n",
            "[[  0 127   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   4   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "\n",
            "Accuracy\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "list1 = []\n",
        "for estimators in range(10,30,1):\n",
        "    classifier = XGBClassifier(n_estimators = estimators, max_depth=12, subsample=0.7)\n",
        "    classifier.fit(x_train, y_train)\n",
        "    y_pred = classifier.predict(x_test)\n",
        "    list1.append(accuracy_score(y_test,y_pred))\n",
        "#print(mylist)\n",
        "plt.plot(list(range(10,30,1)), list1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "0lfW_8c04q7w",
        "outputId": "668fc071-19ba-4ea4-8638-f3ce341fd320"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "classifier = XGBClassifier(n_estimators = 15, max_depth=12, subsample=0.7)\n",
        "classifier.fit(x_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLGoO-g45JKR",
        "outputId": "311d3b70-58c0-4b7d-f70c-c83f37159f05"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(max_depth=12, n_estimators=15, objective='multi:softprob',\n",
              "              subsample=0.7)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ac_xgboost = accuracy_score(y_test, y_pred)\n",
        "mylist.append(ac_xgboost)\n",
        "print(cm)\n",
        "print(ac_xgboost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k256gbxX5Lnu",
        "outputId": "a1afd02d-a460-4663-9710-b010eef2e52d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[127   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  4   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8581081081081081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# catboost\n",
        "!pip install catboost\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "classifier = CatBoostClassifier()\n",
        "classifier.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBcsCzaQ5PNr",
        "outputId": "0fd7e6f7-7461-461d-beb8-315ff85f4c21"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.1-cp37-none-manylinux1_x86_64.whl (76.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.8 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.7.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.6)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost) (4.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.1.0)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.1\n",
            "Learning rate set to 0.074936\n",
            "0:\tlearn: 3.0255109\ttotal: 99.9ms\tremaining: 1m 39s\n",
            "1:\tlearn: 2.6920631\ttotal: 144ms\tremaining: 1m 11s\n",
            "2:\tlearn: 2.4550685\ttotal: 186ms\tremaining: 1m 1s\n",
            "3:\tlearn: 2.2904610\ttotal: 227ms\tremaining: 56.5s\n",
            "4:\tlearn: 2.1293887\ttotal: 269ms\tremaining: 53.5s\n",
            "5:\tlearn: 2.0158895\ttotal: 317ms\tremaining: 52.6s\n",
            "6:\tlearn: 1.8858329\ttotal: 362ms\tremaining: 51.4s\n",
            "7:\tlearn: 1.7776244\ttotal: 404ms\tremaining: 50.1s\n",
            "8:\tlearn: 1.6780458\ttotal: 449ms\tremaining: 49.5s\n",
            "9:\tlearn: 1.6115143\ttotal: 495ms\tremaining: 49s\n",
            "10:\tlearn: 1.5550562\ttotal: 542ms\tremaining: 48.8s\n",
            "11:\tlearn: 1.4987853\ttotal: 590ms\tremaining: 48.6s\n",
            "12:\tlearn: 1.4614513\ttotal: 633ms\tremaining: 48.1s\n",
            "13:\tlearn: 1.4042493\ttotal: 680ms\tremaining: 47.9s\n",
            "14:\tlearn: 1.3652640\ttotal: 722ms\tremaining: 47.4s\n",
            "15:\tlearn: 1.3273643\ttotal: 771ms\tremaining: 47.4s\n",
            "16:\tlearn: 1.2855964\ttotal: 812ms\tremaining: 46.9s\n",
            "17:\tlearn: 1.2504509\ttotal: 853ms\tremaining: 46.5s\n",
            "18:\tlearn: 1.2228524\ttotal: 894ms\tremaining: 46.2s\n",
            "19:\tlearn: 1.1971353\ttotal: 940ms\tremaining: 46s\n",
            "20:\tlearn: 1.1715342\ttotal: 986ms\tremaining: 46s\n",
            "21:\tlearn: 1.1468711\ttotal: 1.03s\tremaining: 45.7s\n",
            "22:\tlearn: 1.1223710\ttotal: 1.08s\tremaining: 46s\n",
            "23:\tlearn: 1.1021782\ttotal: 1.13s\tremaining: 45.9s\n",
            "24:\tlearn: 1.0845498\ttotal: 1.17s\tremaining: 45.7s\n",
            "25:\tlearn: 1.0672330\ttotal: 1.22s\tremaining: 45.8s\n",
            "26:\tlearn: 1.0489184\ttotal: 1.27s\tremaining: 45.7s\n",
            "27:\tlearn: 1.0344284\ttotal: 1.31s\tremaining: 45.5s\n",
            "28:\tlearn: 1.0163798\ttotal: 1.36s\tremaining: 45.5s\n",
            "29:\tlearn: 1.0037302\ttotal: 1.4s\tremaining: 45.3s\n",
            "30:\tlearn: 0.9895326\ttotal: 1.45s\tremaining: 45.3s\n",
            "31:\tlearn: 0.9765276\ttotal: 1.49s\tremaining: 45.2s\n",
            "32:\tlearn: 0.9611610\ttotal: 1.53s\tremaining: 45s\n",
            "33:\tlearn: 0.9464789\ttotal: 1.58s\tremaining: 44.9s\n",
            "34:\tlearn: 0.9355591\ttotal: 1.62s\tremaining: 44.8s\n",
            "35:\tlearn: 0.9244360\ttotal: 1.68s\tremaining: 44.9s\n",
            "36:\tlearn: 0.9151177\ttotal: 1.72s\tremaining: 44.8s\n",
            "37:\tlearn: 0.9037883\ttotal: 1.76s\tremaining: 44.7s\n",
            "38:\tlearn: 0.8941942\ttotal: 1.81s\tremaining: 44.5s\n",
            "39:\tlearn: 0.8856336\ttotal: 1.85s\tremaining: 44.5s\n",
            "40:\tlearn: 0.8760995\ttotal: 1.9s\tremaining: 44.4s\n",
            "41:\tlearn: 0.8673634\ttotal: 1.94s\tremaining: 44.3s\n",
            "42:\tlearn: 0.8566195\ttotal: 1.98s\tremaining: 44.2s\n",
            "43:\tlearn: 0.8483337\ttotal: 2.03s\tremaining: 44.1s\n",
            "44:\tlearn: 0.8408070\ttotal: 2.09s\tremaining: 44.3s\n",
            "45:\tlearn: 0.8336593\ttotal: 2.13s\tremaining: 44.3s\n",
            "46:\tlearn: 0.8273525\ttotal: 2.18s\tremaining: 44.1s\n",
            "47:\tlearn: 0.8205548\ttotal: 2.22s\tremaining: 44s\n",
            "48:\tlearn: 0.8129779\ttotal: 2.27s\tremaining: 44s\n",
            "49:\tlearn: 0.8055128\ttotal: 2.31s\tremaining: 43.8s\n",
            "50:\tlearn: 0.7982217\ttotal: 2.35s\tremaining: 43.8s\n",
            "51:\tlearn: 0.7908688\ttotal: 2.4s\tremaining: 43.7s\n",
            "52:\tlearn: 0.7795363\ttotal: 2.45s\tremaining: 43.7s\n",
            "53:\tlearn: 0.7707705\ttotal: 2.5s\tremaining: 43.9s\n",
            "54:\tlearn: 0.7645957\ttotal: 2.62s\tremaining: 44.9s\n",
            "55:\tlearn: 0.7587847\ttotal: 2.66s\tremaining: 44.8s\n",
            "56:\tlearn: 0.7460637\ttotal: 2.7s\tremaining: 44.7s\n",
            "57:\tlearn: 0.7377413\ttotal: 2.75s\tremaining: 44.7s\n",
            "58:\tlearn: 0.7323057\ttotal: 2.79s\tremaining: 44.5s\n",
            "59:\tlearn: 0.7273710\ttotal: 2.84s\tremaining: 44.5s\n",
            "60:\tlearn: 0.7215716\ttotal: 2.88s\tremaining: 44.4s\n",
            "61:\tlearn: 0.7153231\ttotal: 2.92s\tremaining: 44.2s\n",
            "62:\tlearn: 0.7101000\ttotal: 2.97s\tremaining: 44.2s\n",
            "63:\tlearn: 0.7044205\ttotal: 3.02s\tremaining: 44.2s\n",
            "64:\tlearn: 0.6985800\ttotal: 3.09s\tremaining: 44.4s\n",
            "65:\tlearn: 0.6900025\ttotal: 3.13s\tremaining: 44.3s\n",
            "66:\tlearn: 0.6819854\ttotal: 3.17s\tremaining: 44.2s\n",
            "67:\tlearn: 0.6732915\ttotal: 3.21s\tremaining: 44.1s\n",
            "68:\tlearn: 0.6652412\ttotal: 3.26s\tremaining: 43.9s\n",
            "69:\tlearn: 0.6603897\ttotal: 3.3s\tremaining: 43.9s\n",
            "70:\tlearn: 0.6537998\ttotal: 3.35s\tremaining: 43.8s\n",
            "71:\tlearn: 0.6451377\ttotal: 3.39s\tremaining: 43.7s\n",
            "72:\tlearn: 0.6392982\ttotal: 3.44s\tremaining: 43.6s\n",
            "73:\tlearn: 0.6345089\ttotal: 3.48s\tremaining: 43.5s\n",
            "74:\tlearn: 0.6294305\ttotal: 3.53s\tremaining: 43.6s\n",
            "75:\tlearn: 0.6247944\ttotal: 3.58s\tremaining: 43.6s\n",
            "76:\tlearn: 0.6203383\ttotal: 3.64s\tremaining: 43.6s\n",
            "77:\tlearn: 0.6160704\ttotal: 3.68s\tremaining: 43.5s\n",
            "78:\tlearn: 0.6118082\ttotal: 3.72s\tremaining: 43.4s\n",
            "79:\tlearn: 0.6066806\ttotal: 3.77s\tremaining: 43.4s\n",
            "80:\tlearn: 0.6004400\ttotal: 3.81s\tremaining: 43.3s\n",
            "81:\tlearn: 0.5958042\ttotal: 3.87s\tremaining: 43.3s\n",
            "82:\tlearn: 0.5886393\ttotal: 3.92s\tremaining: 43.3s\n",
            "83:\tlearn: 0.5841761\ttotal: 3.97s\tremaining: 43.2s\n",
            "84:\tlearn: 0.5790933\ttotal: 4.01s\tremaining: 43.2s\n",
            "85:\tlearn: 0.5725793\ttotal: 4.06s\tremaining: 43.1s\n",
            "86:\tlearn: 0.5690520\ttotal: 4.11s\tremaining: 43.1s\n",
            "87:\tlearn: 0.5645809\ttotal: 4.15s\tremaining: 43s\n",
            "88:\tlearn: 0.5606435\ttotal: 4.2s\tremaining: 43s\n",
            "89:\tlearn: 0.5570937\ttotal: 4.24s\tremaining: 42.9s\n",
            "90:\tlearn: 0.5500224\ttotal: 4.28s\tremaining: 42.8s\n",
            "91:\tlearn: 0.5464361\ttotal: 4.33s\tremaining: 42.8s\n",
            "92:\tlearn: 0.5425708\ttotal: 4.37s\tremaining: 42.6s\n",
            "93:\tlearn: 0.5380773\ttotal: 4.42s\tremaining: 42.6s\n",
            "94:\tlearn: 0.5328537\ttotal: 4.46s\tremaining: 42.5s\n",
            "95:\tlearn: 0.5300529\ttotal: 4.5s\tremaining: 42.4s\n",
            "96:\tlearn: 0.5264777\ttotal: 4.55s\tremaining: 42.4s\n",
            "97:\tlearn: 0.5227841\ttotal: 4.59s\tremaining: 42.3s\n",
            "98:\tlearn: 0.5201811\ttotal: 4.64s\tremaining: 42.3s\n",
            "99:\tlearn: 0.5155169\ttotal: 4.69s\tremaining: 42.2s\n",
            "100:\tlearn: 0.5117317\ttotal: 4.73s\tremaining: 42.1s\n",
            "101:\tlearn: 0.5058808\ttotal: 4.78s\tremaining: 42.1s\n",
            "102:\tlearn: 0.5013960\ttotal: 4.82s\tremaining: 42s\n",
            "103:\tlearn: 0.4976837\ttotal: 4.88s\tremaining: 42s\n",
            "104:\tlearn: 0.4942166\ttotal: 4.93s\tremaining: 42s\n",
            "105:\tlearn: 0.4910934\ttotal: 4.97s\tremaining: 41.9s\n",
            "106:\tlearn: 0.4880775\ttotal: 5.02s\tremaining: 41.9s\n",
            "107:\tlearn: 0.4842334\ttotal: 5.07s\tremaining: 41.9s\n",
            "108:\tlearn: 0.4809617\ttotal: 5.12s\tremaining: 41.9s\n",
            "109:\tlearn: 0.4761317\ttotal: 5.17s\tremaining: 41.8s\n",
            "110:\tlearn: 0.4745038\ttotal: 5.21s\tremaining: 41.7s\n",
            "111:\tlearn: 0.4719012\ttotal: 5.25s\tremaining: 41.6s\n",
            "112:\tlearn: 0.4702851\ttotal: 5.29s\tremaining: 41.6s\n",
            "113:\tlearn: 0.4674233\ttotal: 5.34s\tremaining: 41.5s\n",
            "114:\tlearn: 0.4648039\ttotal: 5.39s\tremaining: 41.5s\n",
            "115:\tlearn: 0.4626568\ttotal: 5.43s\tremaining: 41.4s\n",
            "116:\tlearn: 0.4600186\ttotal: 5.47s\tremaining: 41.3s\n",
            "117:\tlearn: 0.4559885\ttotal: 5.52s\tremaining: 41.2s\n",
            "118:\tlearn: 0.4519378\ttotal: 5.57s\tremaining: 41.2s\n",
            "119:\tlearn: 0.4496895\ttotal: 5.61s\tremaining: 41.1s\n",
            "120:\tlearn: 0.4460521\ttotal: 5.65s\tremaining: 41s\n",
            "121:\tlearn: 0.4427277\ttotal: 5.69s\tremaining: 41s\n",
            "122:\tlearn: 0.4404136\ttotal: 5.74s\tremaining: 40.9s\n",
            "123:\tlearn: 0.4378722\ttotal: 5.79s\tremaining: 40.9s\n",
            "124:\tlearn: 0.4357140\ttotal: 5.83s\tremaining: 40.8s\n",
            "125:\tlearn: 0.4313715\ttotal: 5.88s\tremaining: 40.8s\n",
            "126:\tlearn: 0.4291594\ttotal: 5.93s\tremaining: 40.8s\n",
            "127:\tlearn: 0.4265830\ttotal: 5.97s\tremaining: 40.7s\n",
            "128:\tlearn: 0.4237929\ttotal: 6.03s\tremaining: 40.7s\n",
            "129:\tlearn: 0.4211295\ttotal: 6.07s\tremaining: 40.6s\n",
            "130:\tlearn: 0.4184012\ttotal: 6.12s\tremaining: 40.6s\n",
            "131:\tlearn: 0.4164647\ttotal: 6.16s\tremaining: 40.5s\n",
            "132:\tlearn: 0.4137204\ttotal: 6.21s\tremaining: 40.5s\n",
            "133:\tlearn: 0.4097423\ttotal: 6.25s\tremaining: 40.4s\n",
            "134:\tlearn: 0.4068700\ttotal: 6.31s\tremaining: 40.4s\n",
            "135:\tlearn: 0.4045390\ttotal: 6.36s\tremaining: 40.4s\n",
            "136:\tlearn: 0.4022787\ttotal: 6.41s\tremaining: 40.4s\n",
            "137:\tlearn: 0.3997898\ttotal: 6.45s\tremaining: 40.3s\n",
            "138:\tlearn: 0.3965067\ttotal: 6.5s\tremaining: 40.2s\n",
            "139:\tlearn: 0.3938914\ttotal: 6.54s\tremaining: 40.2s\n",
            "140:\tlearn: 0.3910282\ttotal: 6.58s\tremaining: 40.1s\n",
            "141:\tlearn: 0.3880955\ttotal: 6.63s\tremaining: 40s\n",
            "142:\tlearn: 0.3851687\ttotal: 6.67s\tremaining: 40s\n",
            "143:\tlearn: 0.3828498\ttotal: 6.71s\tremaining: 39.9s\n",
            "144:\tlearn: 0.3805945\ttotal: 6.76s\tremaining: 39.8s\n",
            "145:\tlearn: 0.3786458\ttotal: 6.8s\tremaining: 39.8s\n",
            "146:\tlearn: 0.3775566\ttotal: 6.84s\tremaining: 39.7s\n",
            "147:\tlearn: 0.3766252\ttotal: 6.9s\tremaining: 39.7s\n",
            "148:\tlearn: 0.3742101\ttotal: 6.95s\tremaining: 39.7s\n",
            "149:\tlearn: 0.3727915\ttotal: 6.99s\tremaining: 39.6s\n",
            "150:\tlearn: 0.3714174\ttotal: 7.03s\tremaining: 39.5s\n",
            "151:\tlearn: 0.3694039\ttotal: 7.08s\tremaining: 39.5s\n",
            "152:\tlearn: 0.3667076\ttotal: 7.12s\tremaining: 39.4s\n",
            "153:\tlearn: 0.3648099\ttotal: 7.17s\tremaining: 39.4s\n",
            "154:\tlearn: 0.3624663\ttotal: 7.21s\tremaining: 39.3s\n",
            "155:\tlearn: 0.3595882\ttotal: 7.25s\tremaining: 39.2s\n",
            "156:\tlearn: 0.3576425\ttotal: 7.29s\tremaining: 39.1s\n",
            "157:\tlearn: 0.3557613\ttotal: 7.34s\tremaining: 39.1s\n",
            "158:\tlearn: 0.3531935\ttotal: 7.39s\tremaining: 39.1s\n",
            "159:\tlearn: 0.3521033\ttotal: 7.46s\tremaining: 39.2s\n",
            "160:\tlearn: 0.3509558\ttotal: 7.5s\tremaining: 39.1s\n",
            "161:\tlearn: 0.3488664\ttotal: 7.55s\tremaining: 39.1s\n",
            "162:\tlearn: 0.3475740\ttotal: 7.59s\tremaining: 39s\n",
            "163:\tlearn: 0.3456687\ttotal: 7.63s\tremaining: 38.9s\n",
            "164:\tlearn: 0.3435312\ttotal: 7.68s\tremaining: 38.8s\n",
            "165:\tlearn: 0.3417745\ttotal: 7.72s\tremaining: 38.8s\n",
            "166:\tlearn: 0.3396796\ttotal: 7.77s\tremaining: 38.8s\n",
            "167:\tlearn: 0.3374614\ttotal: 7.81s\tremaining: 38.7s\n",
            "168:\tlearn: 0.3349522\ttotal: 7.86s\tremaining: 38.6s\n",
            "169:\tlearn: 0.3320819\ttotal: 7.9s\tremaining: 38.6s\n",
            "170:\tlearn: 0.3306977\ttotal: 7.95s\tremaining: 38.6s\n",
            "171:\tlearn: 0.3284818\ttotal: 8s\tremaining: 38.5s\n",
            "172:\tlearn: 0.3263367\ttotal: 8.05s\tremaining: 38.5s\n",
            "173:\tlearn: 0.3246663\ttotal: 8.09s\tremaining: 38.4s\n",
            "174:\tlearn: 0.3222821\ttotal: 8.13s\tremaining: 38.3s\n",
            "175:\tlearn: 0.3210868\ttotal: 8.18s\tremaining: 38.3s\n",
            "176:\tlearn: 0.3188994\ttotal: 8.22s\tremaining: 38.2s\n",
            "177:\tlearn: 0.3171093\ttotal: 8.27s\tremaining: 38.2s\n",
            "178:\tlearn: 0.3158122\ttotal: 8.31s\tremaining: 38.1s\n",
            "179:\tlearn: 0.3135040\ttotal: 8.35s\tremaining: 38.1s\n",
            "180:\tlearn: 0.3123579\ttotal: 8.4s\tremaining: 38s\n",
            "181:\tlearn: 0.3106240\ttotal: 8.45s\tremaining: 38s\n",
            "182:\tlearn: 0.3089582\ttotal: 8.49s\tremaining: 37.9s\n",
            "183:\tlearn: 0.3076284\ttotal: 8.53s\tremaining: 37.8s\n",
            "184:\tlearn: 0.3060140\ttotal: 8.58s\tremaining: 37.8s\n",
            "185:\tlearn: 0.3039284\ttotal: 8.62s\tremaining: 37.7s\n",
            "186:\tlearn: 0.3019603\ttotal: 8.67s\tremaining: 37.7s\n",
            "187:\tlearn: 0.3007069\ttotal: 8.71s\tremaining: 37.6s\n",
            "188:\tlearn: 0.2991239\ttotal: 8.75s\tremaining: 37.6s\n",
            "189:\tlearn: 0.2979228\ttotal: 8.8s\tremaining: 37.5s\n",
            "190:\tlearn: 0.2963155\ttotal: 8.84s\tremaining: 37.5s\n",
            "191:\tlearn: 0.2948031\ttotal: 8.89s\tremaining: 37.4s\n",
            "192:\tlearn: 0.2933630\ttotal: 8.95s\tremaining: 37.4s\n",
            "193:\tlearn: 0.2911561\ttotal: 9s\tremaining: 37.4s\n",
            "194:\tlearn: 0.2899555\ttotal: 9.04s\tremaining: 37.3s\n",
            "195:\tlearn: 0.2889757\ttotal: 9.09s\tremaining: 37.3s\n",
            "196:\tlearn: 0.2869990\ttotal: 9.13s\tremaining: 37.2s\n",
            "197:\tlearn: 0.2857827\ttotal: 9.18s\tremaining: 37.2s\n",
            "198:\tlearn: 0.2846459\ttotal: 9.22s\tremaining: 37.1s\n",
            "199:\tlearn: 0.2837405\ttotal: 9.27s\tremaining: 37.1s\n",
            "200:\tlearn: 0.2814645\ttotal: 9.31s\tremaining: 37s\n",
            "201:\tlearn: 0.2801063\ttotal: 9.36s\tremaining: 37s\n",
            "202:\tlearn: 0.2783466\ttotal: 9.4s\tremaining: 36.9s\n",
            "203:\tlearn: 0.2764932\ttotal: 9.44s\tremaining: 36.8s\n",
            "204:\tlearn: 0.2748812\ttotal: 9.48s\tremaining: 36.8s\n",
            "205:\tlearn: 0.2734186\ttotal: 9.53s\tremaining: 36.7s\n",
            "206:\tlearn: 0.2721019\ttotal: 9.58s\tremaining: 36.7s\n",
            "207:\tlearn: 0.2708331\ttotal: 9.62s\tremaining: 36.6s\n",
            "208:\tlearn: 0.2695635\ttotal: 9.66s\tremaining: 36.6s\n",
            "209:\tlearn: 0.2675978\ttotal: 9.7s\tremaining: 36.5s\n",
            "210:\tlearn: 0.2664010\ttotal: 9.75s\tremaining: 36.5s\n",
            "211:\tlearn: 0.2645575\ttotal: 9.8s\tremaining: 36.4s\n",
            "212:\tlearn: 0.2628418\ttotal: 9.84s\tremaining: 36.4s\n",
            "213:\tlearn: 0.2623587\ttotal: 9.88s\tremaining: 36.3s\n",
            "214:\tlearn: 0.2607290\ttotal: 9.94s\tremaining: 36.3s\n",
            "215:\tlearn: 0.2597688\ttotal: 9.98s\tremaining: 36.2s\n",
            "216:\tlearn: 0.2581473\ttotal: 10s\tremaining: 36.2s\n",
            "217:\tlearn: 0.2571593\ttotal: 10.1s\tremaining: 36.1s\n",
            "218:\tlearn: 0.2556966\ttotal: 10.1s\tremaining: 36.1s\n",
            "219:\tlearn: 0.2540233\ttotal: 10.2s\tremaining: 36s\n",
            "220:\tlearn: 0.2527730\ttotal: 10.2s\tremaining: 35.9s\n",
            "221:\tlearn: 0.2512889\ttotal: 10.2s\tremaining: 35.9s\n",
            "222:\tlearn: 0.2498743\ttotal: 10.3s\tremaining: 35.8s\n",
            "223:\tlearn: 0.2482869\ttotal: 10.3s\tremaining: 35.8s\n",
            "224:\tlearn: 0.2467539\ttotal: 10.4s\tremaining: 35.7s\n",
            "225:\tlearn: 0.2453923\ttotal: 10.4s\tremaining: 35.7s\n",
            "226:\tlearn: 0.2445145\ttotal: 10.5s\tremaining: 35.6s\n",
            "227:\tlearn: 0.2439405\ttotal: 10.5s\tremaining: 35.6s\n",
            "228:\tlearn: 0.2430598\ttotal: 10.5s\tremaining: 35.5s\n",
            "229:\tlearn: 0.2426631\ttotal: 10.6s\tremaining: 35.5s\n",
            "230:\tlearn: 0.2409825\ttotal: 10.6s\tremaining: 35.4s\n",
            "231:\tlearn: 0.2399985\ttotal: 10.7s\tremaining: 35.4s\n",
            "232:\tlearn: 0.2389253\ttotal: 10.7s\tremaining: 35.3s\n",
            "233:\tlearn: 0.2378489\ttotal: 10.8s\tremaining: 35.3s\n",
            "234:\tlearn: 0.2364766\ttotal: 10.8s\tremaining: 35.2s\n",
            "235:\tlearn: 0.2356307\ttotal: 10.9s\tremaining: 35.1s\n",
            "236:\tlearn: 0.2343531\ttotal: 10.9s\tremaining: 35.1s\n",
            "237:\tlearn: 0.2334169\ttotal: 11s\tremaining: 35.1s\n",
            "238:\tlearn: 0.2327506\ttotal: 11s\tremaining: 35s\n",
            "239:\tlearn: 0.2317844\ttotal: 11s\tremaining: 35s\n",
            "240:\tlearn: 0.2301426\ttotal: 11.1s\tremaining: 34.9s\n",
            "241:\tlearn: 0.2289642\ttotal: 11.1s\tremaining: 34.9s\n",
            "242:\tlearn: 0.2284129\ttotal: 11.2s\tremaining: 34.8s\n",
            "243:\tlearn: 0.2268482\ttotal: 11.2s\tremaining: 34.8s\n",
            "244:\tlearn: 0.2256701\ttotal: 11.3s\tremaining: 34.7s\n",
            "245:\tlearn: 0.2243677\ttotal: 11.3s\tremaining: 34.7s\n",
            "246:\tlearn: 0.2234435\ttotal: 11.4s\tremaining: 34.6s\n",
            "247:\tlearn: 0.2221707\ttotal: 11.4s\tremaining: 34.6s\n",
            "248:\tlearn: 0.2207569\ttotal: 11.4s\tremaining: 34.5s\n",
            "249:\tlearn: 0.2196086\ttotal: 11.5s\tremaining: 34.5s\n",
            "250:\tlearn: 0.2181846\ttotal: 11.5s\tremaining: 34.4s\n",
            "251:\tlearn: 0.2167525\ttotal: 11.6s\tremaining: 34.4s\n",
            "252:\tlearn: 0.2154787\ttotal: 11.6s\tremaining: 34.3s\n",
            "253:\tlearn: 0.2138564\ttotal: 11.7s\tremaining: 34.3s\n",
            "254:\tlearn: 0.2126744\ttotal: 11.7s\tremaining: 34.2s\n",
            "255:\tlearn: 0.2119175\ttotal: 11.7s\tremaining: 34.1s\n",
            "256:\tlearn: 0.2106111\ttotal: 11.8s\tremaining: 34.1s\n",
            "257:\tlearn: 0.2100579\ttotal: 11.8s\tremaining: 34s\n",
            "258:\tlearn: 0.2086949\ttotal: 11.9s\tremaining: 34s\n",
            "259:\tlearn: 0.2073814\ttotal: 11.9s\tremaining: 34s\n",
            "260:\tlearn: 0.2067703\ttotal: 12s\tremaining: 33.9s\n",
            "261:\tlearn: 0.2049917\ttotal: 12s\tremaining: 33.9s\n",
            "262:\tlearn: 0.2037804\ttotal: 12.1s\tremaining: 33.8s\n",
            "263:\tlearn: 0.2024756\ttotal: 12.1s\tremaining: 33.8s\n",
            "264:\tlearn: 0.2012773\ttotal: 12.2s\tremaining: 33.7s\n",
            "265:\tlearn: 0.2002106\ttotal: 12.2s\tremaining: 33.7s\n",
            "266:\tlearn: 0.1990432\ttotal: 12.3s\tremaining: 33.6s\n",
            "267:\tlearn: 0.1979576\ttotal: 12.3s\tremaining: 33.6s\n",
            "268:\tlearn: 0.1972068\ttotal: 12.4s\tremaining: 33.6s\n",
            "269:\tlearn: 0.1963251\ttotal: 12.4s\tremaining: 33.5s\n",
            "270:\tlearn: 0.1955932\ttotal: 12.4s\tremaining: 33.5s\n",
            "271:\tlearn: 0.1945598\ttotal: 12.5s\tremaining: 33.4s\n",
            "272:\tlearn: 0.1938767\ttotal: 12.5s\tremaining: 33.4s\n",
            "273:\tlearn: 0.1930665\ttotal: 12.6s\tremaining: 33.3s\n",
            "274:\tlearn: 0.1923242\ttotal: 12.6s\tremaining: 33.2s\n",
            "275:\tlearn: 0.1912720\ttotal: 12.7s\tremaining: 33.2s\n",
            "276:\tlearn: 0.1907407\ttotal: 12.7s\tremaining: 33.2s\n",
            "277:\tlearn: 0.1896883\ttotal: 12.7s\tremaining: 33.1s\n",
            "278:\tlearn: 0.1889027\ttotal: 12.8s\tremaining: 33.1s\n",
            "279:\tlearn: 0.1882160\ttotal: 12.8s\tremaining: 33s\n",
            "280:\tlearn: 0.1870042\ttotal: 12.9s\tremaining: 33s\n",
            "281:\tlearn: 0.1864797\ttotal: 12.9s\tremaining: 33s\n",
            "282:\tlearn: 0.1854159\ttotal: 13s\tremaining: 32.9s\n",
            "283:\tlearn: 0.1846939\ttotal: 13s\tremaining: 32.8s\n",
            "284:\tlearn: 0.1842478\ttotal: 13.1s\tremaining: 32.8s\n",
            "285:\tlearn: 0.1832294\ttotal: 13.1s\tremaining: 32.7s\n",
            "286:\tlearn: 0.1823442\ttotal: 13.2s\tremaining: 32.7s\n",
            "287:\tlearn: 0.1813941\ttotal: 13.2s\tremaining: 32.7s\n",
            "288:\tlearn: 0.1805429\ttotal: 13.3s\tremaining: 32.6s\n",
            "289:\tlearn: 0.1798350\ttotal: 13.3s\tremaining: 32.6s\n",
            "290:\tlearn: 0.1789433\ttotal: 13.3s\tremaining: 32.5s\n",
            "291:\tlearn: 0.1781851\ttotal: 13.4s\tremaining: 32.5s\n",
            "292:\tlearn: 0.1774447\ttotal: 13.4s\tremaining: 32.4s\n",
            "293:\tlearn: 0.1765194\ttotal: 13.5s\tremaining: 32.4s\n",
            "294:\tlearn: 0.1756543\ttotal: 13.5s\tremaining: 32.3s\n",
            "295:\tlearn: 0.1751189\ttotal: 13.6s\tremaining: 32.2s\n",
            "296:\tlearn: 0.1743209\ttotal: 13.6s\tremaining: 32.2s\n",
            "297:\tlearn: 0.1734890\ttotal: 13.6s\tremaining: 32.2s\n",
            "298:\tlearn: 0.1730126\ttotal: 13.7s\tremaining: 32.1s\n",
            "299:\tlearn: 0.1722369\ttotal: 13.7s\tremaining: 32s\n",
            "300:\tlearn: 0.1709343\ttotal: 13.8s\tremaining: 32s\n",
            "301:\tlearn: 0.1705389\ttotal: 13.8s\tremaining: 31.9s\n",
            "302:\tlearn: 0.1698504\ttotal: 13.9s\tremaining: 31.9s\n",
            "303:\tlearn: 0.1695504\ttotal: 13.9s\tremaining: 31.8s\n",
            "304:\tlearn: 0.1685219\ttotal: 14s\tremaining: 31.8s\n",
            "305:\tlearn: 0.1676623\ttotal: 14s\tremaining: 31.8s\n",
            "306:\tlearn: 0.1671425\ttotal: 14.1s\tremaining: 31.7s\n",
            "307:\tlearn: 0.1665812\ttotal: 14.1s\tremaining: 31.7s\n",
            "308:\tlearn: 0.1660102\ttotal: 14.1s\tremaining: 31.6s\n",
            "309:\tlearn: 0.1651513\ttotal: 14.2s\tremaining: 31.6s\n",
            "310:\tlearn: 0.1645874\ttotal: 14.2s\tremaining: 31.5s\n",
            "311:\tlearn: 0.1638571\ttotal: 14.3s\tremaining: 31.5s\n",
            "312:\tlearn: 0.1630008\ttotal: 14.3s\tremaining: 31.4s\n",
            "313:\tlearn: 0.1620270\ttotal: 14.4s\tremaining: 31.4s\n",
            "314:\tlearn: 0.1612985\ttotal: 14.4s\tremaining: 31.3s\n",
            "315:\tlearn: 0.1607558\ttotal: 14.5s\tremaining: 31.3s\n",
            "316:\tlearn: 0.1602230\ttotal: 14.5s\tremaining: 31.2s\n",
            "317:\tlearn: 0.1596002\ttotal: 14.5s\tremaining: 31.2s\n",
            "318:\tlearn: 0.1586414\ttotal: 14.6s\tremaining: 31.1s\n",
            "319:\tlearn: 0.1582808\ttotal: 14.6s\tremaining: 31.1s\n",
            "320:\tlearn: 0.1571447\ttotal: 14.7s\tremaining: 31s\n",
            "321:\tlearn: 0.1562996\ttotal: 14.7s\tremaining: 31s\n",
            "322:\tlearn: 0.1555862\ttotal: 14.8s\tremaining: 30.9s\n",
            "323:\tlearn: 0.1550679\ttotal: 14.8s\tremaining: 30.9s\n",
            "324:\tlearn: 0.1546044\ttotal: 14.9s\tremaining: 30.8s\n",
            "325:\tlearn: 0.1540318\ttotal: 14.9s\tremaining: 30.8s\n",
            "326:\tlearn: 0.1531712\ttotal: 14.9s\tremaining: 30.8s\n",
            "327:\tlearn: 0.1527247\ttotal: 15s\tremaining: 30.7s\n",
            "328:\tlearn: 0.1518835\ttotal: 15s\tremaining: 30.7s\n",
            "329:\tlearn: 0.1514382\ttotal: 15.1s\tremaining: 30.6s\n",
            "330:\tlearn: 0.1506413\ttotal: 15.1s\tremaining: 30.6s\n",
            "331:\tlearn: 0.1496866\ttotal: 15.2s\tremaining: 30.5s\n",
            "332:\tlearn: 0.1490491\ttotal: 15.2s\tremaining: 30.5s\n",
            "333:\tlearn: 0.1486095\ttotal: 15.3s\tremaining: 30.4s\n",
            "334:\tlearn: 0.1482633\ttotal: 15.3s\tremaining: 30.4s\n",
            "335:\tlearn: 0.1478639\ttotal: 15.3s\tremaining: 30.3s\n",
            "336:\tlearn: 0.1473235\ttotal: 15.4s\tremaining: 30.3s\n",
            "337:\tlearn: 0.1468935\ttotal: 15.4s\tremaining: 30.2s\n",
            "338:\tlearn: 0.1463241\ttotal: 15.5s\tremaining: 30.2s\n",
            "339:\tlearn: 0.1457327\ttotal: 15.5s\tremaining: 30.1s\n",
            "340:\tlearn: 0.1453089\ttotal: 15.6s\tremaining: 30.1s\n",
            "341:\tlearn: 0.1445547\ttotal: 15.6s\tremaining: 30s\n",
            "342:\tlearn: 0.1438914\ttotal: 15.7s\tremaining: 30s\n",
            "343:\tlearn: 0.1432088\ttotal: 15.7s\tremaining: 29.9s\n",
            "344:\tlearn: 0.1425484\ttotal: 15.8s\tremaining: 29.9s\n",
            "345:\tlearn: 0.1421240\ttotal: 15.8s\tremaining: 29.8s\n",
            "346:\tlearn: 0.1416788\ttotal: 15.8s\tremaining: 29.8s\n",
            "347:\tlearn: 0.1412900\ttotal: 15.9s\tremaining: 29.8s\n",
            "348:\tlearn: 0.1406590\ttotal: 15.9s\tremaining: 29.7s\n",
            "349:\tlearn: 0.1400916\ttotal: 16s\tremaining: 29.7s\n",
            "350:\tlearn: 0.1394428\ttotal: 16s\tremaining: 29.6s\n",
            "351:\tlearn: 0.1385389\ttotal: 16.1s\tremaining: 29.6s\n",
            "352:\tlearn: 0.1379660\ttotal: 16.1s\tremaining: 29.5s\n",
            "353:\tlearn: 0.1372936\ttotal: 16.2s\tremaining: 29.5s\n",
            "354:\tlearn: 0.1368591\ttotal: 16.2s\tremaining: 29.5s\n",
            "355:\tlearn: 0.1364489\ttotal: 16.3s\tremaining: 29.4s\n",
            "356:\tlearn: 0.1358560\ttotal: 16.3s\tremaining: 29.4s\n",
            "357:\tlearn: 0.1350291\ttotal: 16.3s\tremaining: 29.3s\n",
            "358:\tlearn: 0.1347064\ttotal: 16.4s\tremaining: 29.3s\n",
            "359:\tlearn: 0.1338268\ttotal: 16.4s\tremaining: 29.2s\n",
            "360:\tlearn: 0.1333157\ttotal: 16.5s\tremaining: 29.2s\n",
            "361:\tlearn: 0.1328216\ttotal: 16.5s\tremaining: 29.1s\n",
            "362:\tlearn: 0.1323711\ttotal: 16.6s\tremaining: 29.1s\n",
            "363:\tlearn: 0.1319076\ttotal: 16.6s\tremaining: 29s\n",
            "364:\tlearn: 0.1309066\ttotal: 16.6s\tremaining: 29s\n",
            "365:\tlearn: 0.1304238\ttotal: 16.7s\tremaining: 28.9s\n",
            "366:\tlearn: 0.1299506\ttotal: 16.7s\tremaining: 28.9s\n",
            "367:\tlearn: 0.1291720\ttotal: 16.8s\tremaining: 28.8s\n",
            "368:\tlearn: 0.1287984\ttotal: 16.8s\tremaining: 28.8s\n",
            "369:\tlearn: 0.1282734\ttotal: 16.9s\tremaining: 28.7s\n",
            "370:\tlearn: 0.1278608\ttotal: 16.9s\tremaining: 28.7s\n",
            "371:\tlearn: 0.1273728\ttotal: 17s\tremaining: 28.6s\n",
            "372:\tlearn: 0.1270889\ttotal: 17s\tremaining: 28.6s\n",
            "373:\tlearn: 0.1265360\ttotal: 17s\tremaining: 28.5s\n",
            "374:\tlearn: 0.1258942\ttotal: 17.1s\tremaining: 28.5s\n",
            "375:\tlearn: 0.1255671\ttotal: 17.1s\tremaining: 28.4s\n",
            "376:\tlearn: 0.1252268\ttotal: 17.2s\tremaining: 28.4s\n",
            "377:\tlearn: 0.1248353\ttotal: 17.2s\tremaining: 28.3s\n",
            "378:\tlearn: 0.1244735\ttotal: 17.3s\tremaining: 28.3s\n",
            "379:\tlearn: 0.1239329\ttotal: 17.3s\tremaining: 28.2s\n",
            "380:\tlearn: 0.1234866\ttotal: 17.3s\tremaining: 28.2s\n",
            "381:\tlearn: 0.1229905\ttotal: 17.4s\tremaining: 28.2s\n",
            "382:\tlearn: 0.1225748\ttotal: 17.5s\tremaining: 28.1s\n",
            "383:\tlearn: 0.1222299\ttotal: 17.5s\tremaining: 28.1s\n",
            "384:\tlearn: 0.1217848\ttotal: 17.6s\tremaining: 28s\n",
            "385:\tlearn: 0.1213771\ttotal: 17.6s\tremaining: 28s\n",
            "386:\tlearn: 0.1210871\ttotal: 17.6s\tremaining: 27.9s\n",
            "387:\tlearn: 0.1207452\ttotal: 17.7s\tremaining: 27.9s\n",
            "388:\tlearn: 0.1203481\ttotal: 17.7s\tremaining: 27.8s\n",
            "389:\tlearn: 0.1196863\ttotal: 17.8s\tremaining: 27.8s\n",
            "390:\tlearn: 0.1193569\ttotal: 17.8s\tremaining: 27.8s\n",
            "391:\tlearn: 0.1188918\ttotal: 17.9s\tremaining: 27.7s\n",
            "392:\tlearn: 0.1183145\ttotal: 17.9s\tremaining: 27.7s\n",
            "393:\tlearn: 0.1181353\ttotal: 18s\tremaining: 27.6s\n",
            "394:\tlearn: 0.1176876\ttotal: 18s\tremaining: 27.6s\n",
            "395:\tlearn: 0.1171773\ttotal: 18.1s\tremaining: 27.5s\n",
            "396:\tlearn: 0.1168921\ttotal: 18.1s\tremaining: 27.5s\n",
            "397:\tlearn: 0.1166040\ttotal: 18.1s\tremaining: 27.5s\n",
            "398:\tlearn: 0.1161050\ttotal: 18.2s\tremaining: 27.4s\n",
            "399:\tlearn: 0.1158568\ttotal: 18.2s\tremaining: 27.3s\n",
            "400:\tlearn: 0.1153084\ttotal: 18.3s\tremaining: 27.3s\n",
            "401:\tlearn: 0.1150025\ttotal: 18.3s\tremaining: 27.3s\n",
            "402:\tlearn: 0.1146681\ttotal: 18.4s\tremaining: 27.2s\n",
            "403:\tlearn: 0.1143385\ttotal: 18.4s\tremaining: 27.2s\n",
            "404:\tlearn: 0.1138094\ttotal: 18.5s\tremaining: 27.1s\n",
            "405:\tlearn: 0.1136330\ttotal: 18.5s\tremaining: 27.1s\n",
            "406:\tlearn: 0.1134343\ttotal: 18.5s\tremaining: 27s\n",
            "407:\tlearn: 0.1130904\ttotal: 18.6s\tremaining: 27s\n",
            "408:\tlearn: 0.1128759\ttotal: 18.6s\tremaining: 26.9s\n",
            "409:\tlearn: 0.1125014\ttotal: 18.7s\tremaining: 26.9s\n",
            "410:\tlearn: 0.1123002\ttotal: 18.7s\tremaining: 26.8s\n",
            "411:\tlearn: 0.1118878\ttotal: 18.8s\tremaining: 26.8s\n",
            "412:\tlearn: 0.1115216\ttotal: 18.8s\tremaining: 26.7s\n",
            "413:\tlearn: 0.1109661\ttotal: 18.9s\tremaining: 26.7s\n",
            "414:\tlearn: 0.1105717\ttotal: 18.9s\tremaining: 26.7s\n",
            "415:\tlearn: 0.1102835\ttotal: 19s\tremaining: 26.6s\n",
            "416:\tlearn: 0.1099502\ttotal: 19s\tremaining: 26.6s\n",
            "417:\tlearn: 0.1095999\ttotal: 19s\tremaining: 26.5s\n",
            "418:\tlearn: 0.1093191\ttotal: 19.1s\tremaining: 26.5s\n",
            "419:\tlearn: 0.1089670\ttotal: 19.1s\tremaining: 26.4s\n",
            "420:\tlearn: 0.1085508\ttotal: 19.2s\tremaining: 26.4s\n",
            "421:\tlearn: 0.1080537\ttotal: 19.2s\tremaining: 26.3s\n",
            "422:\tlearn: 0.1075193\ttotal: 19.3s\tremaining: 26.3s\n",
            "423:\tlearn: 0.1072646\ttotal: 19.3s\tremaining: 26.2s\n",
            "424:\tlearn: 0.1069861\ttotal: 19.4s\tremaining: 26.2s\n",
            "425:\tlearn: 0.1066630\ttotal: 19.4s\tremaining: 26.1s\n",
            "426:\tlearn: 0.1061352\ttotal: 19.4s\tremaining: 26.1s\n",
            "427:\tlearn: 0.1057181\ttotal: 19.5s\tremaining: 26s\n",
            "428:\tlearn: 0.1051288\ttotal: 19.5s\tremaining: 26s\n",
            "429:\tlearn: 0.1048587\ttotal: 19.6s\tremaining: 25.9s\n",
            "430:\tlearn: 0.1046743\ttotal: 19.6s\tremaining: 25.9s\n",
            "431:\tlearn: 0.1044114\ttotal: 19.7s\tremaining: 25.9s\n",
            "432:\tlearn: 0.1041669\ttotal: 19.7s\tremaining: 25.8s\n",
            "433:\tlearn: 0.1038037\ttotal: 19.7s\tremaining: 25.8s\n",
            "434:\tlearn: 0.1034322\ttotal: 19.8s\tremaining: 25.7s\n",
            "435:\tlearn: 0.1030602\ttotal: 19.8s\tremaining: 25.7s\n",
            "436:\tlearn: 0.1027079\ttotal: 19.9s\tremaining: 25.6s\n",
            "437:\tlearn: 0.1024819\ttotal: 19.9s\tremaining: 25.6s\n",
            "438:\tlearn: 0.1021750\ttotal: 20s\tremaining: 25.5s\n",
            "439:\tlearn: 0.1018676\ttotal: 20s\tremaining: 25.5s\n",
            "440:\tlearn: 0.1016750\ttotal: 20.1s\tremaining: 25.4s\n",
            "441:\tlearn: 0.1013503\ttotal: 20.1s\tremaining: 25.4s\n",
            "442:\tlearn: 0.1010399\ttotal: 20.2s\tremaining: 25.3s\n",
            "443:\tlearn: 0.1008440\ttotal: 20.2s\tremaining: 25.3s\n",
            "444:\tlearn: 0.1004621\ttotal: 20.2s\tremaining: 25.2s\n",
            "445:\tlearn: 0.0999806\ttotal: 20.3s\tremaining: 25.2s\n",
            "446:\tlearn: 0.0994697\ttotal: 20.3s\tremaining: 25.1s\n",
            "447:\tlearn: 0.0992858\ttotal: 20.4s\tremaining: 25.1s\n",
            "448:\tlearn: 0.0990995\ttotal: 20.4s\tremaining: 25s\n",
            "449:\tlearn: 0.0988377\ttotal: 20.5s\tremaining: 25s\n",
            "450:\tlearn: 0.0985787\ttotal: 20.5s\tremaining: 24.9s\n",
            "451:\tlearn: 0.0981705\ttotal: 20.5s\tremaining: 24.9s\n",
            "452:\tlearn: 0.0979106\ttotal: 20.6s\tremaining: 24.9s\n",
            "453:\tlearn: 0.0975855\ttotal: 20.6s\tremaining: 24.8s\n",
            "454:\tlearn: 0.0973512\ttotal: 20.7s\tremaining: 24.8s\n",
            "455:\tlearn: 0.0970587\ttotal: 20.7s\tremaining: 24.7s\n",
            "456:\tlearn: 0.0967319\ttotal: 20.8s\tremaining: 24.7s\n",
            "457:\tlearn: 0.0964890\ttotal: 20.8s\tremaining: 24.6s\n",
            "458:\tlearn: 0.0962530\ttotal: 20.8s\tremaining: 24.6s\n",
            "459:\tlearn: 0.0958639\ttotal: 20.9s\tremaining: 24.5s\n",
            "460:\tlearn: 0.0955265\ttotal: 20.9s\tremaining: 24.5s\n",
            "461:\tlearn: 0.0951542\ttotal: 21s\tremaining: 24.5s\n",
            "462:\tlearn: 0.0949766\ttotal: 21s\tremaining: 24.4s\n",
            "463:\tlearn: 0.0946719\ttotal: 21.1s\tremaining: 24.4s\n",
            "464:\tlearn: 0.0943624\ttotal: 21.1s\tremaining: 24.3s\n",
            "465:\tlearn: 0.0940350\ttotal: 21.2s\tremaining: 24.3s\n",
            "466:\tlearn: 0.0937466\ttotal: 21.2s\tremaining: 24.2s\n",
            "467:\tlearn: 0.0933423\ttotal: 21.3s\tremaining: 24.2s\n",
            "468:\tlearn: 0.0930499\ttotal: 21.3s\tremaining: 24.1s\n",
            "469:\tlearn: 0.0929975\ttotal: 21.3s\tremaining: 24s\n",
            "470:\tlearn: 0.0926839\ttotal: 21.4s\tremaining: 24s\n",
            "471:\tlearn: 0.0924608\ttotal: 21.4s\tremaining: 23.9s\n",
            "472:\tlearn: 0.0921609\ttotal: 21.5s\tremaining: 23.9s\n",
            "473:\tlearn: 0.0919208\ttotal: 21.5s\tremaining: 23.9s\n",
            "474:\tlearn: 0.0916130\ttotal: 21.5s\tremaining: 23.8s\n",
            "475:\tlearn: 0.0912237\ttotal: 21.6s\tremaining: 23.8s\n",
            "476:\tlearn: 0.0910653\ttotal: 21.6s\tremaining: 23.7s\n",
            "477:\tlearn: 0.0906491\ttotal: 21.7s\tremaining: 23.7s\n",
            "478:\tlearn: 0.0903810\ttotal: 21.7s\tremaining: 23.6s\n",
            "479:\tlearn: 0.0902206\ttotal: 21.8s\tremaining: 23.6s\n",
            "480:\tlearn: 0.0898552\ttotal: 21.8s\tremaining: 23.5s\n",
            "481:\tlearn: 0.0895303\ttotal: 21.8s\tremaining: 23.5s\n",
            "482:\tlearn: 0.0893327\ttotal: 21.9s\tremaining: 23.4s\n",
            "483:\tlearn: 0.0890818\ttotal: 21.9s\tremaining: 23.4s\n",
            "484:\tlearn: 0.0887095\ttotal: 22s\tremaining: 23.3s\n",
            "485:\tlearn: 0.0883829\ttotal: 22s\tremaining: 23.3s\n",
            "486:\tlearn: 0.0880208\ttotal: 22.1s\tremaining: 23.3s\n",
            "487:\tlearn: 0.0877237\ttotal: 22.1s\tremaining: 23.2s\n",
            "488:\tlearn: 0.0875083\ttotal: 22.2s\tremaining: 23.2s\n",
            "489:\tlearn: 0.0871610\ttotal: 22.2s\tremaining: 23.1s\n",
            "490:\tlearn: 0.0869296\ttotal: 22.2s\tremaining: 23.1s\n",
            "491:\tlearn: 0.0866031\ttotal: 22.3s\tremaining: 23s\n",
            "492:\tlearn: 0.0863032\ttotal: 22.3s\tremaining: 23s\n",
            "493:\tlearn: 0.0860613\ttotal: 22.4s\tremaining: 22.9s\n",
            "494:\tlearn: 0.0858888\ttotal: 22.4s\tremaining: 22.9s\n",
            "495:\tlearn: 0.0856556\ttotal: 22.5s\tremaining: 22.8s\n",
            "496:\tlearn: 0.0853890\ttotal: 22.5s\tremaining: 22.8s\n",
            "497:\tlearn: 0.0851695\ttotal: 22.6s\tremaining: 22.7s\n",
            "498:\tlearn: 0.0850000\ttotal: 22.6s\tremaining: 22.7s\n",
            "499:\tlearn: 0.0847224\ttotal: 22.6s\tremaining: 22.6s\n",
            "500:\tlearn: 0.0843565\ttotal: 22.7s\tremaining: 22.6s\n",
            "501:\tlearn: 0.0841062\ttotal: 22.7s\tremaining: 22.5s\n",
            "502:\tlearn: 0.0838869\ttotal: 22.8s\tremaining: 22.5s\n",
            "503:\tlearn: 0.0836327\ttotal: 22.8s\tremaining: 22.4s\n",
            "504:\tlearn: 0.0835372\ttotal: 22.9s\tremaining: 22.4s\n",
            "505:\tlearn: 0.0833745\ttotal: 22.9s\tremaining: 22.4s\n",
            "506:\tlearn: 0.0830076\ttotal: 22.9s\tremaining: 22.3s\n",
            "507:\tlearn: 0.0827962\ttotal: 23s\tremaining: 22.3s\n",
            "508:\tlearn: 0.0824704\ttotal: 23s\tremaining: 22.2s\n",
            "509:\tlearn: 0.0822005\ttotal: 23.1s\tremaining: 22.2s\n",
            "510:\tlearn: 0.0820125\ttotal: 23.1s\tremaining: 22.1s\n",
            "511:\tlearn: 0.0819239\ttotal: 23.2s\tremaining: 22.1s\n",
            "512:\tlearn: 0.0817526\ttotal: 23.2s\tremaining: 22s\n",
            "513:\tlearn: 0.0815514\ttotal: 23.3s\tremaining: 22s\n",
            "514:\tlearn: 0.0814319\ttotal: 23.3s\tremaining: 21.9s\n",
            "515:\tlearn: 0.0811390\ttotal: 23.3s\tremaining: 21.9s\n",
            "516:\tlearn: 0.0808856\ttotal: 23.4s\tremaining: 21.8s\n",
            "517:\tlearn: 0.0805270\ttotal: 23.4s\tremaining: 21.8s\n",
            "518:\tlearn: 0.0802120\ttotal: 23.5s\tremaining: 21.8s\n",
            "519:\tlearn: 0.0799367\ttotal: 23.5s\tremaining: 21.7s\n",
            "520:\tlearn: 0.0797243\ttotal: 23.6s\tremaining: 21.7s\n",
            "521:\tlearn: 0.0794291\ttotal: 23.6s\tremaining: 21.6s\n",
            "522:\tlearn: 0.0791721\ttotal: 23.6s\tremaining: 21.6s\n",
            "523:\tlearn: 0.0788731\ttotal: 23.7s\tremaining: 21.5s\n",
            "524:\tlearn: 0.0786926\ttotal: 23.7s\tremaining: 21.5s\n",
            "525:\tlearn: 0.0785634\ttotal: 23.8s\tremaining: 21.4s\n",
            "526:\tlearn: 0.0783437\ttotal: 23.8s\tremaining: 21.4s\n",
            "527:\tlearn: 0.0783041\ttotal: 23.9s\tremaining: 21.3s\n",
            "528:\tlearn: 0.0781419\ttotal: 23.9s\tremaining: 21.3s\n",
            "529:\tlearn: 0.0779031\ttotal: 24s\tremaining: 21.3s\n",
            "530:\tlearn: 0.0777844\ttotal: 24s\tremaining: 21.2s\n",
            "531:\tlearn: 0.0776661\ttotal: 24.1s\tremaining: 21.2s\n",
            "532:\tlearn: 0.0774623\ttotal: 24.1s\tremaining: 21.1s\n",
            "533:\tlearn: 0.0773510\ttotal: 24.1s\tremaining: 21.1s\n",
            "534:\tlearn: 0.0770256\ttotal: 24.2s\tremaining: 21s\n",
            "535:\tlearn: 0.0768348\ttotal: 24.2s\tremaining: 21s\n",
            "536:\tlearn: 0.0766357\ttotal: 24.3s\tremaining: 20.9s\n",
            "537:\tlearn: 0.0764570\ttotal: 24.3s\tremaining: 20.9s\n",
            "538:\tlearn: 0.0762386\ttotal: 24.4s\tremaining: 20.8s\n",
            "539:\tlearn: 0.0759626\ttotal: 24.4s\tremaining: 20.8s\n",
            "540:\tlearn: 0.0757775\ttotal: 24.4s\tremaining: 20.7s\n",
            "541:\tlearn: 0.0754744\ttotal: 24.5s\tremaining: 20.7s\n",
            "542:\tlearn: 0.0752897\ttotal: 24.5s\tremaining: 20.6s\n",
            "543:\tlearn: 0.0751146\ttotal: 24.6s\tremaining: 20.6s\n",
            "544:\tlearn: 0.0748958\ttotal: 24.6s\tremaining: 20.6s\n",
            "545:\tlearn: 0.0746526\ttotal: 24.7s\tremaining: 20.5s\n",
            "546:\tlearn: 0.0744717\ttotal: 24.7s\tremaining: 20.5s\n",
            "547:\tlearn: 0.0742105\ttotal: 24.8s\tremaining: 20.4s\n",
            "548:\tlearn: 0.0740565\ttotal: 24.8s\tremaining: 20.4s\n",
            "549:\tlearn: 0.0738951\ttotal: 24.8s\tremaining: 20.3s\n",
            "550:\tlearn: 0.0737810\ttotal: 24.9s\tremaining: 20.3s\n",
            "551:\tlearn: 0.0735050\ttotal: 24.9s\tremaining: 20.2s\n",
            "552:\tlearn: 0.0733479\ttotal: 25s\tremaining: 20.2s\n",
            "553:\tlearn: 0.0730484\ttotal: 25s\tremaining: 20.1s\n",
            "554:\tlearn: 0.0727168\ttotal: 25.1s\tremaining: 20.1s\n",
            "555:\tlearn: 0.0724585\ttotal: 25.1s\tremaining: 20.1s\n",
            "556:\tlearn: 0.0722272\ttotal: 25.2s\tremaining: 20s\n",
            "557:\tlearn: 0.0720193\ttotal: 25.2s\tremaining: 20s\n",
            "558:\tlearn: 0.0718772\ttotal: 25.2s\tremaining: 19.9s\n",
            "559:\tlearn: 0.0717403\ttotal: 25.3s\tremaining: 19.9s\n",
            "560:\tlearn: 0.0716480\ttotal: 25.3s\tremaining: 19.8s\n",
            "561:\tlearn: 0.0714226\ttotal: 25.4s\tremaining: 19.8s\n",
            "562:\tlearn: 0.0713141\ttotal: 25.4s\tremaining: 19.7s\n",
            "563:\tlearn: 0.0711056\ttotal: 25.5s\tremaining: 19.7s\n",
            "564:\tlearn: 0.0709003\ttotal: 25.5s\tremaining: 19.6s\n",
            "565:\tlearn: 0.0707603\ttotal: 25.6s\tremaining: 19.6s\n",
            "566:\tlearn: 0.0706066\ttotal: 25.6s\tremaining: 19.6s\n",
            "567:\tlearn: 0.0704296\ttotal: 25.6s\tremaining: 19.5s\n",
            "568:\tlearn: 0.0703736\ttotal: 25.7s\tremaining: 19.5s\n",
            "569:\tlearn: 0.0701868\ttotal: 25.7s\tremaining: 19.4s\n",
            "570:\tlearn: 0.0699837\ttotal: 25.8s\tremaining: 19.4s\n",
            "571:\tlearn: 0.0697119\ttotal: 25.8s\tremaining: 19.3s\n",
            "572:\tlearn: 0.0695789\ttotal: 25.9s\tremaining: 19.3s\n",
            "573:\tlearn: 0.0693327\ttotal: 25.9s\tremaining: 19.2s\n",
            "574:\tlearn: 0.0692161\ttotal: 26s\tremaining: 19.2s\n",
            "575:\tlearn: 0.0690682\ttotal: 26s\tremaining: 19.2s\n",
            "576:\tlearn: 0.0689054\ttotal: 26.1s\tremaining: 19.1s\n",
            "577:\tlearn: 0.0687073\ttotal: 26.1s\tremaining: 19.1s\n",
            "578:\tlearn: 0.0685667\ttotal: 26.2s\tremaining: 19s\n",
            "579:\tlearn: 0.0683984\ttotal: 26.2s\tremaining: 19s\n",
            "580:\tlearn: 0.0682299\ttotal: 26.2s\tremaining: 18.9s\n",
            "581:\tlearn: 0.0680132\ttotal: 26.3s\tremaining: 18.9s\n",
            "582:\tlearn: 0.0679045\ttotal: 26.3s\tremaining: 18.8s\n",
            "583:\tlearn: 0.0677102\ttotal: 26.4s\tremaining: 18.8s\n",
            "584:\tlearn: 0.0675124\ttotal: 26.4s\tremaining: 18.7s\n",
            "585:\tlearn: 0.0673492\ttotal: 26.5s\tremaining: 18.7s\n",
            "586:\tlearn: 0.0672155\ttotal: 26.5s\tremaining: 18.6s\n",
            "587:\tlearn: 0.0669976\ttotal: 26.6s\tremaining: 18.6s\n",
            "588:\tlearn: 0.0668782\ttotal: 26.6s\tremaining: 18.6s\n",
            "589:\tlearn: 0.0667561\ttotal: 26.6s\tremaining: 18.5s\n",
            "590:\tlearn: 0.0665931\ttotal: 26.7s\tremaining: 18.5s\n",
            "591:\tlearn: 0.0664636\ttotal: 26.7s\tremaining: 18.4s\n",
            "592:\tlearn: 0.0663122\ttotal: 26.8s\tremaining: 18.4s\n",
            "593:\tlearn: 0.0661400\ttotal: 26.8s\tremaining: 18.3s\n",
            "594:\tlearn: 0.0659338\ttotal: 26.9s\tremaining: 18.3s\n",
            "595:\tlearn: 0.0658283\ttotal: 26.9s\tremaining: 18.2s\n",
            "596:\tlearn: 0.0656705\ttotal: 27s\tremaining: 18.2s\n",
            "597:\tlearn: 0.0654953\ttotal: 27s\tremaining: 18.2s\n",
            "598:\tlearn: 0.0654351\ttotal: 27.1s\tremaining: 18.1s\n",
            "599:\tlearn: 0.0653672\ttotal: 27.1s\tremaining: 18.1s\n",
            "600:\tlearn: 0.0651854\ttotal: 27.2s\tremaining: 18s\n",
            "601:\tlearn: 0.0650100\ttotal: 27.2s\tremaining: 18s\n",
            "602:\tlearn: 0.0649092\ttotal: 27.2s\tremaining: 17.9s\n",
            "603:\tlearn: 0.0647729\ttotal: 27.3s\tremaining: 17.9s\n",
            "604:\tlearn: 0.0645890\ttotal: 27.4s\tremaining: 17.9s\n",
            "605:\tlearn: 0.0645225\ttotal: 27.4s\tremaining: 17.8s\n",
            "606:\tlearn: 0.0643361\ttotal: 27.4s\tremaining: 17.8s\n",
            "607:\tlearn: 0.0641392\ttotal: 27.5s\tremaining: 17.7s\n",
            "608:\tlearn: 0.0639601\ttotal: 27.5s\tremaining: 17.7s\n",
            "609:\tlearn: 0.0637872\ttotal: 27.6s\tremaining: 17.6s\n",
            "610:\tlearn: 0.0635217\ttotal: 27.6s\tremaining: 17.6s\n",
            "611:\tlearn: 0.0633637\ttotal: 27.7s\tremaining: 17.5s\n",
            "612:\tlearn: 0.0631902\ttotal: 27.7s\tremaining: 17.5s\n",
            "613:\tlearn: 0.0630056\ttotal: 27.8s\tremaining: 17.4s\n",
            "614:\tlearn: 0.0628387\ttotal: 27.8s\tremaining: 17.4s\n",
            "615:\tlearn: 0.0626811\ttotal: 27.8s\tremaining: 17.4s\n",
            "616:\tlearn: 0.0625557\ttotal: 27.9s\tremaining: 17.3s\n",
            "617:\tlearn: 0.0623719\ttotal: 27.9s\tremaining: 17.3s\n",
            "618:\tlearn: 0.0622305\ttotal: 28s\tremaining: 17.2s\n",
            "619:\tlearn: 0.0621475\ttotal: 28s\tremaining: 17.2s\n",
            "620:\tlearn: 0.0619416\ttotal: 28.1s\tremaining: 17.1s\n",
            "621:\tlearn: 0.0617705\ttotal: 28.1s\tremaining: 17.1s\n",
            "622:\tlearn: 0.0617086\ttotal: 28.2s\tremaining: 17.1s\n",
            "623:\tlearn: 0.0615526\ttotal: 28.2s\tremaining: 17s\n",
            "624:\tlearn: 0.0613335\ttotal: 28.3s\tremaining: 17s\n",
            "625:\tlearn: 0.0612121\ttotal: 28.3s\tremaining: 16.9s\n",
            "626:\tlearn: 0.0610350\ttotal: 28.4s\tremaining: 16.9s\n",
            "627:\tlearn: 0.0609064\ttotal: 28.4s\tremaining: 16.8s\n",
            "628:\tlearn: 0.0607513\ttotal: 28.4s\tremaining: 16.8s\n",
            "629:\tlearn: 0.0606431\ttotal: 28.5s\tremaining: 16.7s\n",
            "630:\tlearn: 0.0604174\ttotal: 28.6s\tremaining: 16.7s\n",
            "631:\tlearn: 0.0603115\ttotal: 28.7s\tremaining: 16.7s\n",
            "632:\tlearn: 0.0602022\ttotal: 28.8s\tremaining: 16.7s\n",
            "633:\tlearn: 0.0600658\ttotal: 28.9s\tremaining: 16.7s\n",
            "634:\tlearn: 0.0599428\ttotal: 28.9s\tremaining: 16.6s\n",
            "635:\tlearn: 0.0597836\ttotal: 29s\tremaining: 16.6s\n",
            "636:\tlearn: 0.0595917\ttotal: 29.1s\tremaining: 16.6s\n",
            "637:\tlearn: 0.0595409\ttotal: 29.2s\tremaining: 16.5s\n",
            "638:\tlearn: 0.0593812\ttotal: 29.2s\tremaining: 16.5s\n",
            "639:\tlearn: 0.0592791\ttotal: 29.3s\tremaining: 16.5s\n",
            "640:\tlearn: 0.0591062\ttotal: 29.4s\tremaining: 16.5s\n",
            "641:\tlearn: 0.0589318\ttotal: 29.5s\tremaining: 16.4s\n",
            "642:\tlearn: 0.0587905\ttotal: 29.6s\tremaining: 16.4s\n",
            "643:\tlearn: 0.0586481\ttotal: 29.7s\tremaining: 16.4s\n",
            "644:\tlearn: 0.0585089\ttotal: 29.7s\tremaining: 16.4s\n",
            "645:\tlearn: 0.0583854\ttotal: 29.8s\tremaining: 16.3s\n",
            "646:\tlearn: 0.0582396\ttotal: 29.9s\tremaining: 16.3s\n",
            "647:\tlearn: 0.0580254\ttotal: 30s\tremaining: 16.3s\n",
            "648:\tlearn: 0.0578785\ttotal: 30.1s\tremaining: 16.3s\n",
            "649:\tlearn: 0.0577533\ttotal: 30.1s\tremaining: 16.2s\n",
            "650:\tlearn: 0.0575906\ttotal: 30.2s\tremaining: 16.2s\n",
            "651:\tlearn: 0.0574461\ttotal: 30.3s\tremaining: 16.2s\n",
            "652:\tlearn: 0.0572983\ttotal: 30.4s\tremaining: 16.1s\n",
            "653:\tlearn: 0.0572117\ttotal: 30.5s\tremaining: 16.1s\n",
            "654:\tlearn: 0.0571348\ttotal: 30.6s\tremaining: 16.1s\n",
            "655:\tlearn: 0.0569618\ttotal: 30.7s\tremaining: 16.1s\n",
            "656:\tlearn: 0.0568741\ttotal: 30.7s\tremaining: 16s\n",
            "657:\tlearn: 0.0566985\ttotal: 30.8s\tremaining: 16s\n",
            "658:\tlearn: 0.0565677\ttotal: 30.9s\tremaining: 16s\n",
            "659:\tlearn: 0.0564543\ttotal: 31s\tremaining: 16s\n",
            "660:\tlearn: 0.0563330\ttotal: 31.1s\tremaining: 15.9s\n",
            "661:\tlearn: 0.0561824\ttotal: 31.2s\tremaining: 15.9s\n",
            "662:\tlearn: 0.0560380\ttotal: 31.2s\tremaining: 15.9s\n",
            "663:\tlearn: 0.0559295\ttotal: 31.3s\tremaining: 15.8s\n",
            "664:\tlearn: 0.0557635\ttotal: 31.4s\tremaining: 15.8s\n",
            "665:\tlearn: 0.0556195\ttotal: 31.5s\tremaining: 15.8s\n",
            "666:\tlearn: 0.0554844\ttotal: 31.6s\tremaining: 15.8s\n",
            "667:\tlearn: 0.0553677\ttotal: 31.6s\tremaining: 15.7s\n",
            "668:\tlearn: 0.0553061\ttotal: 31.7s\tremaining: 15.7s\n",
            "669:\tlearn: 0.0552321\ttotal: 31.8s\tremaining: 15.7s\n",
            "670:\tlearn: 0.0551153\ttotal: 31.9s\tremaining: 15.6s\n",
            "671:\tlearn: 0.0549970\ttotal: 31.9s\tremaining: 15.6s\n",
            "672:\tlearn: 0.0548663\ttotal: 32s\tremaining: 15.5s\n",
            "673:\tlearn: 0.0547059\ttotal: 32.1s\tremaining: 15.5s\n",
            "674:\tlearn: 0.0545865\ttotal: 32.2s\tremaining: 15.5s\n",
            "675:\tlearn: 0.0544659\ttotal: 32.3s\tremaining: 15.5s\n",
            "676:\tlearn: 0.0543264\ttotal: 32.3s\tremaining: 15.4s\n",
            "677:\tlearn: 0.0542029\ttotal: 32.4s\tremaining: 15.4s\n",
            "678:\tlearn: 0.0540474\ttotal: 32.5s\tremaining: 15.4s\n",
            "679:\tlearn: 0.0539218\ttotal: 32.6s\tremaining: 15.3s\n",
            "680:\tlearn: 0.0538092\ttotal: 32.7s\tremaining: 15.3s\n",
            "681:\tlearn: 0.0537316\ttotal: 32.7s\tremaining: 15.3s\n",
            "682:\tlearn: 0.0536305\ttotal: 32.8s\tremaining: 15.2s\n",
            "683:\tlearn: 0.0535026\ttotal: 32.9s\tremaining: 15.2s\n",
            "684:\tlearn: 0.0534079\ttotal: 33s\tremaining: 15.2s\n",
            "685:\tlearn: 0.0532997\ttotal: 33s\tremaining: 15.1s\n",
            "686:\tlearn: 0.0530969\ttotal: 33.1s\tremaining: 15.1s\n",
            "687:\tlearn: 0.0530333\ttotal: 33.1s\tremaining: 15s\n",
            "688:\tlearn: 0.0529551\ttotal: 33.2s\tremaining: 15s\n",
            "689:\tlearn: 0.0528200\ttotal: 33.2s\tremaining: 14.9s\n",
            "690:\tlearn: 0.0526899\ttotal: 33.2s\tremaining: 14.9s\n",
            "691:\tlearn: 0.0526346\ttotal: 33.3s\tremaining: 14.8s\n",
            "692:\tlearn: 0.0525599\ttotal: 33.3s\tremaining: 14.8s\n",
            "693:\tlearn: 0.0525121\ttotal: 33.4s\tremaining: 14.7s\n",
            "694:\tlearn: 0.0523492\ttotal: 33.4s\tremaining: 14.7s\n",
            "695:\tlearn: 0.0522745\ttotal: 33.5s\tremaining: 14.6s\n",
            "696:\tlearn: 0.0522360\ttotal: 33.5s\tremaining: 14.6s\n",
            "697:\tlearn: 0.0521269\ttotal: 33.6s\tremaining: 14.5s\n",
            "698:\tlearn: 0.0520336\ttotal: 33.6s\tremaining: 14.5s\n",
            "699:\tlearn: 0.0519093\ttotal: 33.7s\tremaining: 14.4s\n",
            "700:\tlearn: 0.0518191\ttotal: 33.7s\tremaining: 14.4s\n",
            "701:\tlearn: 0.0517529\ttotal: 33.7s\tremaining: 14.3s\n",
            "702:\tlearn: 0.0516654\ttotal: 33.8s\tremaining: 14.3s\n",
            "703:\tlearn: 0.0515315\ttotal: 33.8s\tremaining: 14.2s\n",
            "704:\tlearn: 0.0514138\ttotal: 33.9s\tremaining: 14.2s\n",
            "705:\tlearn: 0.0513043\ttotal: 33.9s\tremaining: 14.1s\n",
            "706:\tlearn: 0.0511587\ttotal: 34s\tremaining: 14.1s\n",
            "707:\tlearn: 0.0510241\ttotal: 34s\tremaining: 14s\n",
            "708:\tlearn: 0.0509271\ttotal: 34s\tremaining: 14s\n",
            "709:\tlearn: 0.0507952\ttotal: 34.1s\tremaining: 13.9s\n",
            "710:\tlearn: 0.0507298\ttotal: 34.1s\tremaining: 13.9s\n",
            "711:\tlearn: 0.0506362\ttotal: 34.2s\tremaining: 13.8s\n",
            "712:\tlearn: 0.0504094\ttotal: 34.2s\tremaining: 13.8s\n",
            "713:\tlearn: 0.0502426\ttotal: 34.3s\tremaining: 13.7s\n",
            "714:\tlearn: 0.0501734\ttotal: 34.3s\tremaining: 13.7s\n",
            "715:\tlearn: 0.0501227\ttotal: 34.4s\tremaining: 13.6s\n",
            "716:\tlearn: 0.0500498\ttotal: 34.4s\tremaining: 13.6s\n",
            "717:\tlearn: 0.0499850\ttotal: 34.5s\tremaining: 13.5s\n",
            "718:\tlearn: 0.0498642\ttotal: 34.5s\tremaining: 13.5s\n",
            "719:\tlearn: 0.0497549\ttotal: 34.6s\tremaining: 13.4s\n",
            "720:\tlearn: 0.0496389\ttotal: 34.6s\tremaining: 13.4s\n",
            "721:\tlearn: 0.0495800\ttotal: 34.6s\tremaining: 13.3s\n",
            "722:\tlearn: 0.0494849\ttotal: 34.7s\tremaining: 13.3s\n",
            "723:\tlearn: 0.0493930\ttotal: 34.7s\tremaining: 13.2s\n",
            "724:\tlearn: 0.0492967\ttotal: 34.8s\tremaining: 13.2s\n",
            "725:\tlearn: 0.0492176\ttotal: 34.8s\tremaining: 13.1s\n",
            "726:\tlearn: 0.0491127\ttotal: 34.8s\tremaining: 13.1s\n",
            "727:\tlearn: 0.0490397\ttotal: 34.9s\tremaining: 13s\n",
            "728:\tlearn: 0.0489678\ttotal: 34.9s\tremaining: 13s\n",
            "729:\tlearn: 0.0488261\ttotal: 35s\tremaining: 12.9s\n",
            "730:\tlearn: 0.0487297\ttotal: 35s\tremaining: 12.9s\n",
            "731:\tlearn: 0.0486091\ttotal: 35.1s\tremaining: 12.8s\n",
            "732:\tlearn: 0.0484751\ttotal: 35.1s\tremaining: 12.8s\n",
            "733:\tlearn: 0.0483776\ttotal: 35.2s\tremaining: 12.7s\n",
            "734:\tlearn: 0.0482735\ttotal: 35.2s\tremaining: 12.7s\n",
            "735:\tlearn: 0.0482146\ttotal: 35.2s\tremaining: 12.6s\n",
            "736:\tlearn: 0.0480818\ttotal: 35.3s\tremaining: 12.6s\n",
            "737:\tlearn: 0.0479802\ttotal: 35.3s\tremaining: 12.5s\n",
            "738:\tlearn: 0.0479263\ttotal: 35.4s\tremaining: 12.5s\n",
            "739:\tlearn: 0.0478395\ttotal: 35.4s\tremaining: 12.4s\n",
            "740:\tlearn: 0.0478187\ttotal: 35.5s\tremaining: 12.4s\n",
            "741:\tlearn: 0.0477737\ttotal: 35.5s\tremaining: 12.3s\n",
            "742:\tlearn: 0.0476697\ttotal: 35.6s\tremaining: 12.3s\n",
            "743:\tlearn: 0.0475882\ttotal: 35.6s\tremaining: 12.3s\n",
            "744:\tlearn: 0.0474714\ttotal: 35.6s\tremaining: 12.2s\n",
            "745:\tlearn: 0.0474021\ttotal: 35.7s\tremaining: 12.2s\n",
            "746:\tlearn: 0.0473002\ttotal: 35.7s\tremaining: 12.1s\n",
            "747:\tlearn: 0.0472272\ttotal: 35.8s\tremaining: 12.1s\n",
            "748:\tlearn: 0.0471483\ttotal: 35.8s\tremaining: 12s\n",
            "749:\tlearn: 0.0470549\ttotal: 35.9s\tremaining: 12s\n",
            "750:\tlearn: 0.0469825\ttotal: 35.9s\tremaining: 11.9s\n",
            "751:\tlearn: 0.0468987\ttotal: 35.9s\tremaining: 11.9s\n",
            "752:\tlearn: 0.0467897\ttotal: 36s\tremaining: 11.8s\n",
            "753:\tlearn: 0.0467121\ttotal: 36s\tremaining: 11.8s\n",
            "754:\tlearn: 0.0466640\ttotal: 36.1s\tremaining: 11.7s\n",
            "755:\tlearn: 0.0465640\ttotal: 36.1s\tremaining: 11.7s\n",
            "756:\tlearn: 0.0465158\ttotal: 36.2s\tremaining: 11.6s\n",
            "757:\tlearn: 0.0464271\ttotal: 36.2s\tremaining: 11.6s\n",
            "758:\tlearn: 0.0463729\ttotal: 36.3s\tremaining: 11.5s\n",
            "759:\tlearn: 0.0462608\ttotal: 36.3s\tremaining: 11.5s\n",
            "760:\tlearn: 0.0461817\ttotal: 36.4s\tremaining: 11.4s\n",
            "761:\tlearn: 0.0460656\ttotal: 36.4s\tremaining: 11.4s\n",
            "762:\tlearn: 0.0459899\ttotal: 36.4s\tremaining: 11.3s\n",
            "763:\tlearn: 0.0458811\ttotal: 36.5s\tremaining: 11.3s\n",
            "764:\tlearn: 0.0458139\ttotal: 36.5s\tremaining: 11.2s\n",
            "765:\tlearn: 0.0457612\ttotal: 36.6s\tremaining: 11.2s\n",
            "766:\tlearn: 0.0456385\ttotal: 36.6s\tremaining: 11.1s\n",
            "767:\tlearn: 0.0455622\ttotal: 36.7s\tremaining: 11.1s\n",
            "768:\tlearn: 0.0454698\ttotal: 36.7s\tremaining: 11s\n",
            "769:\tlearn: 0.0453556\ttotal: 36.7s\tremaining: 11s\n",
            "770:\tlearn: 0.0452612\ttotal: 36.8s\tremaining: 10.9s\n",
            "771:\tlearn: 0.0451110\ttotal: 36.8s\tremaining: 10.9s\n",
            "772:\tlearn: 0.0450576\ttotal: 36.9s\tremaining: 10.8s\n",
            "773:\tlearn: 0.0449542\ttotal: 36.9s\tremaining: 10.8s\n",
            "774:\tlearn: 0.0448816\ttotal: 37s\tremaining: 10.7s\n",
            "775:\tlearn: 0.0448033\ttotal: 37s\tremaining: 10.7s\n",
            "776:\tlearn: 0.0447534\ttotal: 37s\tremaining: 10.6s\n",
            "777:\tlearn: 0.0446508\ttotal: 37.1s\tremaining: 10.6s\n",
            "778:\tlearn: 0.0446043\ttotal: 37.1s\tremaining: 10.5s\n",
            "779:\tlearn: 0.0445124\ttotal: 37.2s\tremaining: 10.5s\n",
            "780:\tlearn: 0.0444453\ttotal: 37.2s\tremaining: 10.4s\n",
            "781:\tlearn: 0.0443729\ttotal: 37.3s\tremaining: 10.4s\n",
            "782:\tlearn: 0.0443214\ttotal: 37.3s\tremaining: 10.3s\n",
            "783:\tlearn: 0.0442113\ttotal: 37.4s\tremaining: 10.3s\n",
            "784:\tlearn: 0.0441576\ttotal: 37.4s\tremaining: 10.2s\n",
            "785:\tlearn: 0.0441008\ttotal: 37.5s\tremaining: 10.2s\n",
            "786:\tlearn: 0.0440635\ttotal: 37.5s\tremaining: 10.2s\n",
            "787:\tlearn: 0.0439513\ttotal: 37.5s\tremaining: 10.1s\n",
            "788:\tlearn: 0.0438761\ttotal: 37.6s\tremaining: 10.1s\n",
            "789:\tlearn: 0.0438067\ttotal: 37.6s\tremaining: 10s\n",
            "790:\tlearn: 0.0437443\ttotal: 37.7s\tremaining: 9.96s\n",
            "791:\tlearn: 0.0436823\ttotal: 37.7s\tremaining: 9.91s\n",
            "792:\tlearn: 0.0435764\ttotal: 37.8s\tremaining: 9.86s\n",
            "793:\tlearn: 0.0434480\ttotal: 37.8s\tremaining: 9.81s\n",
            "794:\tlearn: 0.0434201\ttotal: 37.9s\tremaining: 9.76s\n",
            "795:\tlearn: 0.0433227\ttotal: 37.9s\tremaining: 9.72s\n",
            "796:\tlearn: 0.0432788\ttotal: 38s\tremaining: 9.67s\n",
            "797:\tlearn: 0.0432262\ttotal: 38s\tremaining: 9.62s\n",
            "798:\tlearn: 0.0431715\ttotal: 38s\tremaining: 9.57s\n",
            "799:\tlearn: 0.0430623\ttotal: 38.1s\tremaining: 9.52s\n",
            "800:\tlearn: 0.0429716\ttotal: 38.1s\tremaining: 9.47s\n",
            "801:\tlearn: 0.0429383\ttotal: 38.2s\tremaining: 9.43s\n",
            "802:\tlearn: 0.0428419\ttotal: 38.2s\tremaining: 9.38s\n",
            "803:\tlearn: 0.0427913\ttotal: 38.3s\tremaining: 9.33s\n",
            "804:\tlearn: 0.0426971\ttotal: 38.3s\tremaining: 9.28s\n",
            "805:\tlearn: 0.0426603\ttotal: 38.4s\tremaining: 9.23s\n",
            "806:\tlearn: 0.0426049\ttotal: 38.4s\tremaining: 9.19s\n",
            "807:\tlearn: 0.0425169\ttotal: 38.5s\tremaining: 9.14s\n",
            "808:\tlearn: 0.0424480\ttotal: 38.5s\tremaining: 9.09s\n",
            "809:\tlearn: 0.0423536\ttotal: 38.5s\tremaining: 9.04s\n",
            "810:\tlearn: 0.0423049\ttotal: 38.6s\tremaining: 8.99s\n",
            "811:\tlearn: 0.0422296\ttotal: 38.6s\tremaining: 8.94s\n",
            "812:\tlearn: 0.0421557\ttotal: 38.7s\tremaining: 8.89s\n",
            "813:\tlearn: 0.0420803\ttotal: 38.7s\tremaining: 8.85s\n",
            "814:\tlearn: 0.0419921\ttotal: 38.8s\tremaining: 8.8s\n",
            "815:\tlearn: 0.0419376\ttotal: 38.8s\tremaining: 8.75s\n",
            "816:\tlearn: 0.0418414\ttotal: 38.9s\tremaining: 8.7s\n",
            "817:\tlearn: 0.0417879\ttotal: 38.9s\tremaining: 8.65s\n",
            "818:\tlearn: 0.0417169\ttotal: 38.9s\tremaining: 8.6s\n",
            "819:\tlearn: 0.0416215\ttotal: 39s\tremaining: 8.56s\n",
            "820:\tlearn: 0.0415341\ttotal: 39s\tremaining: 8.51s\n",
            "821:\tlearn: 0.0414613\ttotal: 39.1s\tremaining: 8.46s\n",
            "822:\tlearn: 0.0414126\ttotal: 39.1s\tremaining: 8.41s\n",
            "823:\tlearn: 0.0413303\ttotal: 39.2s\tremaining: 8.36s\n",
            "824:\tlearn: 0.0412854\ttotal: 39.2s\tremaining: 8.31s\n",
            "825:\tlearn: 0.0411901\ttotal: 39.3s\tremaining: 8.27s\n",
            "826:\tlearn: 0.0411214\ttotal: 39.3s\tremaining: 8.22s\n",
            "827:\tlearn: 0.0410855\ttotal: 39.3s\tremaining: 8.17s\n",
            "828:\tlearn: 0.0410302\ttotal: 39.4s\tremaining: 8.13s\n",
            "829:\tlearn: 0.0409937\ttotal: 39.4s\tremaining: 8.08s\n",
            "830:\tlearn: 0.0409301\ttotal: 39.5s\tremaining: 8.03s\n",
            "831:\tlearn: 0.0408894\ttotal: 39.5s\tremaining: 7.98s\n",
            "832:\tlearn: 0.0408072\ttotal: 39.6s\tremaining: 7.93s\n",
            "833:\tlearn: 0.0407294\ttotal: 39.6s\tremaining: 7.88s\n",
            "834:\tlearn: 0.0406616\ttotal: 39.6s\tremaining: 7.83s\n",
            "835:\tlearn: 0.0406153\ttotal: 39.7s\tremaining: 7.79s\n",
            "836:\tlearn: 0.0405751\ttotal: 39.7s\tremaining: 7.74s\n",
            "837:\tlearn: 0.0405263\ttotal: 39.8s\tremaining: 7.69s\n",
            "838:\tlearn: 0.0404781\ttotal: 39.8s\tremaining: 7.64s\n",
            "839:\tlearn: 0.0404107\ttotal: 39.9s\tremaining: 7.59s\n",
            "840:\tlearn: 0.0403731\ttotal: 39.9s\tremaining: 7.54s\n",
            "841:\tlearn: 0.0402866\ttotal: 40s\tremaining: 7.5s\n",
            "842:\tlearn: 0.0401936\ttotal: 40s\tremaining: 7.45s\n",
            "843:\tlearn: 0.0401420\ttotal: 40s\tremaining: 7.4s\n",
            "844:\tlearn: 0.0400817\ttotal: 40.1s\tremaining: 7.35s\n",
            "845:\tlearn: 0.0400218\ttotal: 40.1s\tremaining: 7.3s\n",
            "846:\tlearn: 0.0399730\ttotal: 40.2s\tremaining: 7.26s\n",
            "847:\tlearn: 0.0398786\ttotal: 40.2s\tremaining: 7.21s\n",
            "848:\tlearn: 0.0398174\ttotal: 40.3s\tremaining: 7.16s\n",
            "849:\tlearn: 0.0397900\ttotal: 40.3s\tremaining: 7.11s\n",
            "850:\tlearn: 0.0397384\ttotal: 40.4s\tremaining: 7.07s\n",
            "851:\tlearn: 0.0396616\ttotal: 40.4s\tremaining: 7.02s\n",
            "852:\tlearn: 0.0395927\ttotal: 40.4s\tremaining: 6.97s\n",
            "853:\tlearn: 0.0395105\ttotal: 40.5s\tremaining: 6.92s\n",
            "854:\tlearn: 0.0394389\ttotal: 40.5s\tremaining: 6.87s\n",
            "855:\tlearn: 0.0393638\ttotal: 40.6s\tremaining: 6.83s\n",
            "856:\tlearn: 0.0392576\ttotal: 40.6s\tremaining: 6.78s\n",
            "857:\tlearn: 0.0392089\ttotal: 40.7s\tremaining: 6.73s\n",
            "858:\tlearn: 0.0391366\ttotal: 40.7s\tremaining: 6.68s\n",
            "859:\tlearn: 0.0390855\ttotal: 40.7s\tremaining: 6.63s\n",
            "860:\tlearn: 0.0390330\ttotal: 40.8s\tremaining: 6.59s\n",
            "861:\tlearn: 0.0389771\ttotal: 40.8s\tremaining: 6.54s\n",
            "862:\tlearn: 0.0388896\ttotal: 40.9s\tremaining: 6.49s\n",
            "863:\tlearn: 0.0388209\ttotal: 40.9s\tremaining: 6.44s\n",
            "864:\tlearn: 0.0387761\ttotal: 41s\tremaining: 6.39s\n",
            "865:\tlearn: 0.0387145\ttotal: 41s\tremaining: 6.35s\n",
            "866:\tlearn: 0.0386056\ttotal: 41.1s\tremaining: 6.3s\n",
            "867:\tlearn: 0.0385453\ttotal: 41.1s\tremaining: 6.25s\n",
            "868:\tlearn: 0.0384574\ttotal: 41.1s\tremaining: 6.2s\n",
            "869:\tlearn: 0.0383790\ttotal: 41.2s\tremaining: 6.15s\n",
            "870:\tlearn: 0.0383002\ttotal: 41.2s\tremaining: 6.11s\n",
            "871:\tlearn: 0.0382559\ttotal: 41.3s\tremaining: 6.06s\n",
            "872:\tlearn: 0.0381965\ttotal: 41.3s\tremaining: 6.01s\n",
            "873:\tlearn: 0.0381436\ttotal: 41.4s\tremaining: 5.96s\n",
            "874:\tlearn: 0.0380763\ttotal: 41.4s\tremaining: 5.92s\n",
            "875:\tlearn: 0.0380155\ttotal: 41.5s\tremaining: 5.87s\n",
            "876:\tlearn: 0.0379290\ttotal: 41.5s\tremaining: 5.82s\n",
            "877:\tlearn: 0.0378581\ttotal: 41.6s\tremaining: 5.77s\n",
            "878:\tlearn: 0.0377956\ttotal: 41.6s\tremaining: 5.73s\n",
            "879:\tlearn: 0.0377602\ttotal: 41.6s\tremaining: 5.68s\n",
            "880:\tlearn: 0.0376795\ttotal: 41.7s\tremaining: 5.63s\n",
            "881:\tlearn: 0.0376330\ttotal: 41.7s\tremaining: 5.58s\n",
            "882:\tlearn: 0.0375910\ttotal: 41.8s\tremaining: 5.53s\n",
            "883:\tlearn: 0.0375245\ttotal: 41.8s\tremaining: 5.49s\n",
            "884:\tlearn: 0.0374587\ttotal: 41.9s\tremaining: 5.44s\n",
            "885:\tlearn: 0.0373694\ttotal: 41.9s\tremaining: 5.39s\n",
            "886:\tlearn: 0.0372921\ttotal: 41.9s\tremaining: 5.34s\n",
            "887:\tlearn: 0.0372494\ttotal: 42s\tremaining: 5.29s\n",
            "888:\tlearn: 0.0372145\ttotal: 42s\tremaining: 5.25s\n",
            "889:\tlearn: 0.0371588\ttotal: 42.1s\tremaining: 5.2s\n",
            "890:\tlearn: 0.0370999\ttotal: 42.1s\tremaining: 5.15s\n",
            "891:\tlearn: 0.0370360\ttotal: 42.2s\tremaining: 5.11s\n",
            "892:\tlearn: 0.0369640\ttotal: 42.2s\tremaining: 5.06s\n",
            "893:\tlearn: 0.0368981\ttotal: 42.3s\tremaining: 5.01s\n",
            "894:\tlearn: 0.0368535\ttotal: 42.3s\tremaining: 4.96s\n",
            "895:\tlearn: 0.0367911\ttotal: 42.4s\tremaining: 4.92s\n",
            "896:\tlearn: 0.0367229\ttotal: 42.4s\tremaining: 4.87s\n",
            "897:\tlearn: 0.0366818\ttotal: 42.4s\tremaining: 4.82s\n",
            "898:\tlearn: 0.0366082\ttotal: 42.5s\tremaining: 4.77s\n",
            "899:\tlearn: 0.0365279\ttotal: 42.5s\tremaining: 4.73s\n",
            "900:\tlearn: 0.0364624\ttotal: 42.6s\tremaining: 4.68s\n",
            "901:\tlearn: 0.0364073\ttotal: 42.6s\tremaining: 4.63s\n",
            "902:\tlearn: 0.0363691\ttotal: 42.7s\tremaining: 4.58s\n",
            "903:\tlearn: 0.0362842\ttotal: 42.7s\tremaining: 4.54s\n",
            "904:\tlearn: 0.0362004\ttotal: 42.8s\tremaining: 4.49s\n",
            "905:\tlearn: 0.0361319\ttotal: 42.8s\tremaining: 4.44s\n",
            "906:\tlearn: 0.0360820\ttotal: 42.8s\tremaining: 4.39s\n",
            "907:\tlearn: 0.0360337\ttotal: 42.9s\tremaining: 4.34s\n",
            "908:\tlearn: 0.0359944\ttotal: 42.9s\tremaining: 4.3s\n",
            "909:\tlearn: 0.0359514\ttotal: 43s\tremaining: 4.25s\n",
            "910:\tlearn: 0.0358705\ttotal: 43s\tremaining: 4.2s\n",
            "911:\tlearn: 0.0358100\ttotal: 43.1s\tremaining: 4.16s\n",
            "912:\tlearn: 0.0357683\ttotal: 43.1s\tremaining: 4.11s\n",
            "913:\tlearn: 0.0357417\ttotal: 43.2s\tremaining: 4.06s\n",
            "914:\tlearn: 0.0356771\ttotal: 43.2s\tremaining: 4.01s\n",
            "915:\tlearn: 0.0356113\ttotal: 43.2s\tremaining: 3.96s\n",
            "916:\tlearn: 0.0355681\ttotal: 43.3s\tremaining: 3.92s\n",
            "917:\tlearn: 0.0355117\ttotal: 43.3s\tremaining: 3.87s\n",
            "918:\tlearn: 0.0354834\ttotal: 43.4s\tremaining: 3.82s\n",
            "919:\tlearn: 0.0354539\ttotal: 43.4s\tremaining: 3.78s\n",
            "920:\tlearn: 0.0353759\ttotal: 43.5s\tremaining: 3.73s\n",
            "921:\tlearn: 0.0352971\ttotal: 43.5s\tremaining: 3.68s\n",
            "922:\tlearn: 0.0352446\ttotal: 43.6s\tremaining: 3.63s\n",
            "923:\tlearn: 0.0352252\ttotal: 43.6s\tremaining: 3.59s\n",
            "924:\tlearn: 0.0351454\ttotal: 43.6s\tremaining: 3.54s\n",
            "925:\tlearn: 0.0350945\ttotal: 43.7s\tremaining: 3.49s\n",
            "926:\tlearn: 0.0350380\ttotal: 43.7s\tremaining: 3.44s\n",
            "927:\tlearn: 0.0349891\ttotal: 43.8s\tremaining: 3.4s\n",
            "928:\tlearn: 0.0349307\ttotal: 43.8s\tremaining: 3.35s\n",
            "929:\tlearn: 0.0348920\ttotal: 43.9s\tremaining: 3.3s\n",
            "930:\tlearn: 0.0348406\ttotal: 43.9s\tremaining: 3.25s\n",
            "931:\tlearn: 0.0348223\ttotal: 44s\tremaining: 3.21s\n",
            "932:\tlearn: 0.0347543\ttotal: 44s\tremaining: 3.16s\n",
            "933:\tlearn: 0.0347031\ttotal: 44.1s\tremaining: 3.11s\n",
            "934:\tlearn: 0.0346251\ttotal: 44.1s\tremaining: 3.06s\n",
            "935:\tlearn: 0.0345847\ttotal: 44.1s\tremaining: 3.02s\n",
            "936:\tlearn: 0.0345464\ttotal: 44.2s\tremaining: 2.97s\n",
            "937:\tlearn: 0.0344935\ttotal: 44.2s\tremaining: 2.92s\n",
            "938:\tlearn: 0.0344351\ttotal: 44.3s\tremaining: 2.88s\n",
            "939:\tlearn: 0.0344032\ttotal: 44.3s\tremaining: 2.83s\n",
            "940:\tlearn: 0.0343591\ttotal: 44.4s\tremaining: 2.78s\n",
            "941:\tlearn: 0.0343234\ttotal: 44.4s\tremaining: 2.73s\n",
            "942:\tlearn: 0.0342668\ttotal: 44.5s\tremaining: 2.69s\n",
            "943:\tlearn: 0.0342281\ttotal: 44.5s\tremaining: 2.64s\n",
            "944:\tlearn: 0.0341892\ttotal: 44.6s\tremaining: 2.59s\n",
            "945:\tlearn: 0.0341647\ttotal: 44.6s\tremaining: 2.55s\n",
            "946:\tlearn: 0.0341107\ttotal: 44.7s\tremaining: 2.5s\n",
            "947:\tlearn: 0.0340653\ttotal: 44.7s\tremaining: 2.45s\n",
            "948:\tlearn: 0.0340186\ttotal: 44.8s\tremaining: 2.4s\n",
            "949:\tlearn: 0.0339770\ttotal: 44.8s\tremaining: 2.36s\n",
            "950:\tlearn: 0.0339236\ttotal: 44.8s\tremaining: 2.31s\n",
            "951:\tlearn: 0.0338652\ttotal: 44.9s\tremaining: 2.26s\n",
            "952:\tlearn: 0.0338093\ttotal: 44.9s\tremaining: 2.22s\n",
            "953:\tlearn: 0.0337541\ttotal: 45s\tremaining: 2.17s\n",
            "954:\tlearn: 0.0337179\ttotal: 45s\tremaining: 2.12s\n",
            "955:\tlearn: 0.0336801\ttotal: 45.1s\tremaining: 2.07s\n",
            "956:\tlearn: 0.0336261\ttotal: 45.1s\tremaining: 2.03s\n",
            "957:\tlearn: 0.0335761\ttotal: 45.2s\tremaining: 1.98s\n",
            "958:\tlearn: 0.0335379\ttotal: 45.2s\tremaining: 1.93s\n",
            "959:\tlearn: 0.0334831\ttotal: 45.3s\tremaining: 1.89s\n",
            "960:\tlearn: 0.0334472\ttotal: 45.3s\tremaining: 1.84s\n",
            "961:\tlearn: 0.0333829\ttotal: 45.4s\tremaining: 1.79s\n",
            "962:\tlearn: 0.0333301\ttotal: 45.4s\tremaining: 1.74s\n",
            "963:\tlearn: 0.0332930\ttotal: 45.5s\tremaining: 1.7s\n",
            "964:\tlearn: 0.0332505\ttotal: 45.5s\tremaining: 1.65s\n",
            "965:\tlearn: 0.0332285\ttotal: 45.6s\tremaining: 1.6s\n",
            "966:\tlearn: 0.0331633\ttotal: 45.6s\tremaining: 1.56s\n",
            "967:\tlearn: 0.0331285\ttotal: 45.6s\tremaining: 1.51s\n",
            "968:\tlearn: 0.0330980\ttotal: 45.7s\tremaining: 1.46s\n",
            "969:\tlearn: 0.0330365\ttotal: 45.7s\tremaining: 1.41s\n",
            "970:\tlearn: 0.0329990\ttotal: 45.8s\tremaining: 1.37s\n",
            "971:\tlearn: 0.0329613\ttotal: 45.8s\tremaining: 1.32s\n",
            "972:\tlearn: 0.0329220\ttotal: 45.9s\tremaining: 1.27s\n",
            "973:\tlearn: 0.0328613\ttotal: 45.9s\tremaining: 1.23s\n",
            "974:\tlearn: 0.0328321\ttotal: 45.9s\tremaining: 1.18s\n",
            "975:\tlearn: 0.0328102\ttotal: 46s\tremaining: 1.13s\n",
            "976:\tlearn: 0.0327421\ttotal: 46s\tremaining: 1.08s\n",
            "977:\tlearn: 0.0326908\ttotal: 46.1s\tremaining: 1.04s\n",
            "978:\tlearn: 0.0326577\ttotal: 46.1s\tremaining: 989ms\n",
            "979:\tlearn: 0.0326443\ttotal: 46.2s\tremaining: 942ms\n",
            "980:\tlearn: 0.0325861\ttotal: 46.2s\tremaining: 895ms\n",
            "981:\tlearn: 0.0325299\ttotal: 46.3s\tremaining: 848ms\n",
            "982:\tlearn: 0.0324953\ttotal: 46.3s\tremaining: 801ms\n",
            "983:\tlearn: 0.0324508\ttotal: 46.4s\tremaining: 754ms\n",
            "984:\tlearn: 0.0323919\ttotal: 46.4s\tremaining: 707ms\n",
            "985:\tlearn: 0.0323293\ttotal: 46.4s\tremaining: 659ms\n",
            "986:\tlearn: 0.0322967\ttotal: 46.5s\tremaining: 612ms\n",
            "987:\tlearn: 0.0322669\ttotal: 46.5s\tremaining: 565ms\n",
            "988:\tlearn: 0.0322237\ttotal: 46.5s\tremaining: 518ms\n",
            "989:\tlearn: 0.0321914\ttotal: 46.6s\tremaining: 471ms\n",
            "990:\tlearn: 0.0321552\ttotal: 46.6s\tremaining: 424ms\n",
            "991:\tlearn: 0.0321024\ttotal: 46.7s\tremaining: 377ms\n",
            "992:\tlearn: 0.0320692\ttotal: 46.7s\tremaining: 329ms\n",
            "993:\tlearn: 0.0320147\ttotal: 46.8s\tremaining: 282ms\n",
            "994:\tlearn: 0.0319644\ttotal: 46.8s\tremaining: 235ms\n",
            "995:\tlearn: 0.0319228\ttotal: 46.9s\tremaining: 188ms\n",
            "996:\tlearn: 0.0318724\ttotal: 46.9s\tremaining: 141ms\n",
            "997:\tlearn: 0.0318494\ttotal: 46.9s\tremaining: 94.1ms\n",
            "998:\tlearn: 0.0318193\ttotal: 47s\tremaining: 47ms\n",
            "999:\tlearn: 0.0317514\ttotal: 47s\tremaining: 0us\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f435afe5c10>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(x_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ac_catboost = accuracy_score(y_test, y_pred)\n",
        "mylist.append(ac_catboost)\n",
        "print(cm)\n",
        "print(ac_catboost)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQnqm4lq5Sbg",
        "outputId": "1eb40bf3-6ddf-48c9-9026-a50c473e3258"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[127   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  4   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  2   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
            "0.8581081081081081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = pd.DataFrame({\n",
        "    'Model': ['KNN', 'Logistic Regression', \n",
        "              'Random Forest', 'ANN', 'DNN',  \n",
        "              'Decision Tree','xgboost','catboost'],\n",
        "    'Score': [acc_knn, acc_logreg, \n",
        "              acc_randomforest, ac_ann, ac_dnn, acc_decisiontree,ac_xgboost,ac_catboost\n",
        "              ]})\n",
        "models.sort_values(by='Score', ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "27YU93DQ58w-",
        "outputId": "3f9db823-e891-4593-b83a-7954aad46703"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Model     Score\n",
              "1  Logistic Regression  0.858108\n",
              "2        Random Forest  0.858108\n",
              "5        Decision Tree  0.858108\n",
              "6              xgboost  0.858108\n",
              "7             catboost  0.858108\n",
              "0                  KNN  0.851351\n",
              "3                  ANN  0.000000\n",
              "4                  DNN  0.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fead7aff-6574-485f-be9e-100bd0c78515\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.858108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.858108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.858108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>xgboost</td>\n",
              "      <td>0.858108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>catboost</td>\n",
              "      <td>0.858108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.851351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ANN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DNN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fead7aff-6574-485f-be9e-100bd0c78515')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fead7aff-6574-485f-be9e-100bd0c78515 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fead7aff-6574-485f-be9e-100bd0c78515');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns \n",
        "plt.rcParams['figure.figsize']=15,6 \n",
        "sns.set_style(\"darkgrid\")\n",
        "ax = sns.barplot(x=models.Model, y=models.Score, palette = \"rocket\", saturation =1.5)\n",
        "plt.xlabel(\"Classifier Models\", fontsize = 20 )\n",
        "plt.ylabel(\"% of Accuracy\", fontsize = 20)\n",
        "plt.title(\"Accuracy of different Classifier Models\", fontsize = 20)\n",
        "plt.xticks(fontsize = 12, horizontalalignment = 'center', rotation = 8)\n",
        "plt.yticks(fontsize = 13)\n",
        "for p in ax.patches:\n",
        "    width, height = p.get_width(), p.get_height()\n",
        "    x, y = p.get_xy() \n",
        "    ax.annotate(f'{height:.2%}', (x + width/2, y + height*1.02), ha='center', fontsize = 'x-large')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "d8onA3pt6Rbj",
        "outputId": "4b6b31d9-b0ab-4f2f-ea2f-d51755f28393"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ArLD9V0B6eE0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}